{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to AutoNN An AutoML (Automated machine learning) / No-Code ML Framework for beginners. Installation pip install nocode - autonn To upgrade the package pip install -- upgrade nocodenn - autonn How to use? Open Terminal after installing the package Use the following command to launch the GUI autonn","title":"Installation & Intro"},{"location":"#welcome-to-autonn","text":"An AutoML (Automated machine learning) / No-Code ML Framework for beginners.","title":"Welcome to AutoNN"},{"location":"#installation","text":"pip install nocode - autonn","title":"Installation"},{"location":"#to-upgrade-the-package","text":"pip install -- upgrade nocodenn - autonn","title":"To upgrade the package"},{"location":"#how-to-use","text":"Open Terminal after installing the package Use the following command to launch the GUI autonn","title":"How to use?"},{"location":"about/","text":"About This project is a result of our internship at C-DAC Center for Development of Advanced Computing, Pune under the supervision of Dr. Anil Kumar Gupta . Core Team Anish Konar : Designed the ANN models generator, and feature engineering for tabular dataset. Maintainer . Rajarshi Banerjee : Designed the GUI, automated CNN model generation, and image dataset augmentation. Maintainer . Sagnik Nayak : Automated data preprocessing, data cleaning, and feature engineering for tabular dataset. Maintainer . Other contributors Arjun Ghosh Souptik Das","title":"About"},{"location":"about/#about","text":"This project is a result of our internship at C-DAC Center for Development of Advanced Computing, Pune under the supervision of Dr. Anil Kumar Gupta .","title":"About"},{"location":"about/#core-team","text":"Anish Konar : Designed the ANN models generator, and feature engineering for tabular dataset. Maintainer . Rajarshi Banerjee : Designed the GUI, automated CNN model generation, and image dataset augmentation. Maintainer . Sagnik Nayak : Automated data preprocessing, data cleaning, and feature engineering for tabular dataset. Maintainer .","title":"Core Team"},{"location":"about/#other-contributors","text":"Arjun Ghosh Souptik Das","title":"Other contributors"},{"location":"documentation/cnn1/","text":"AutoNN.CNN.cnn_generator.CNN class CNN ( in_channels : int , numClasses : int , config : Optional [ list [ tuple ]] = None ): Parameters : in_channels : The number of channels in an image numClass : Total number of classes in a classification problem config : Generated configuration by AutoNN's CreateCNN.create_config() method required to create a CNN model Methods: summary() : Parameters : input_shape : Shape of the image torch.tensor [C, H, W] where, C = number of channels H = height of the image W = width of the image border : bool datatype , default = True | It prints lines between layers while displaying the summary of a model if set to True save() classes : List of classes image_shape : Tuple[int, int] (H,W) | dimension of the images path : Optional | path to the directory where the model is intended to be stored Note For the very first time path should be included, otherwise it will throw an InvalidPathError exception. filename : str | name of the model load() Parameters : PATH : Path to the trained model.pth . printmodel : bool datatype , default = False | print the model if set to True loadmodel : bool datatype , default = True | loads all the stored weights if set to True predict() paths : Union[list | tuple] | list of unknown images for testing or prediction","title":"class CNN"},{"location":"documentation/cnn1/#autonncnncnn_generatorcnn","text":"class CNN ( in_channels : int , numClasses : int , config : Optional [ list [ tuple ]] = None ): Parameters : in_channels : The number of channels in an image numClass : Total number of classes in a classification problem config : Generated configuration by AutoNN's CreateCNN.create_config() method required to create a CNN model","title":"AutoNN.CNN.cnn_generator.CNN"},{"location":"documentation/cnn1/#methods","text":"summary() : Parameters : input_shape : Shape of the image torch.tensor [C, H, W] where, C = number of channels H = height of the image W = width of the image border : bool datatype , default = True | It prints lines between layers while displaying the summary of a model if set to True save() classes : List of classes image_shape : Tuple[int, int] (H,W) | dimension of the images path : Optional | path to the directory where the model is intended to be stored Note For the very first time path should be included, otherwise it will throw an InvalidPathError exception. filename : str | name of the model load() Parameters : PATH : Path to the trained model.pth . printmodel : bool datatype , default = False | print the model if set to True loadmodel : bool datatype , default = True | loads all the stored weights if set to True predict() paths : Union[list | tuple] | list of unknown images for testing or prediction","title":"Methods:"},{"location":"documentation/cnn2/","text":"AutoNN.CNN.cnn_generator.CreateCNN class CreateCNN ( _size : int = 10 ): Parameters : _size : int | default = 10 | Maximum number of CNN models to be generated Methods: create_config() : This function will create configuration based on which CNN models will be generated. Parameters : min : int | minimum number of layers the gnerated CNN model can have max : int | maximum number of layers the gnerated CNN model can have Example >>> print ( CreateCNN . create_config ( 3 , 10 )) >>> [( 'conv' , 64 , 64 ), ( 'pool' , 1 , 64 ), ( 'conv' , 256 , 512 ), ( 'conv' , 64 , 128 ), ( 'conv' , 64 , 64 ), ( 'pool' , 0 , 64 )] print_all_cnn_configs() : This function will print all the CNN architectures in PyTorch Format Parameters : None print_all_architecture() This function will print all the CNN architectures generated Parameters : None get_bestCNN() Parameters: path_trainset : str | path to the image training set path_testset : str | Optional[str] | path to the image test set split_required : bool | default = False | set to true if only there is no test set batch_size : int | default = 16 | Batch size lossFn : str | default = crossentropy | Most multiclass image classification problems use CrossEntropyLoss LR : float | default = 3e4 | Learning Rate EPOCHS : int | default = 10 | number Epochs image_shape : Tuple[int,int] | default = (28,28) | dimension of the input image from the training dataset Returns : Returns a tuple containing the best CNN model generated, its configuration, and history of all models generated ( best_CNN_model, best_model_config, history_of_all_models)","title":"class CreateCNN"},{"location":"documentation/cnn2/#autonncnncnn_generatorcreatecnn","text":"class CreateCNN ( _size : int = 10 ): Parameters : _size : int | default = 10 | Maximum number of CNN models to be generated","title":"AutoNN.CNN.cnn_generator.CreateCNN"},{"location":"documentation/cnn2/#methods","text":"","title":"Methods:"},{"location":"documentation/cnn2/#create_config","text":"This function will create configuration based on which CNN models will be generated. Parameters : min : int | minimum number of layers the gnerated CNN model can have max : int | maximum number of layers the gnerated CNN model can have Example >>> print ( CreateCNN . create_config ( 3 , 10 )) >>> [( 'conv' , 64 , 64 ), ( 'pool' , 1 , 64 ), ( 'conv' , 256 , 512 ), ( 'conv' , 64 , 128 ), ( 'conv' , 64 , 64 ), ( 'pool' , 0 , 64 )]","title":"create_config() :"},{"location":"documentation/cnn2/#print_all_cnn_configs","text":"This function will print all the CNN architectures in PyTorch Format Parameters : None","title":"print_all_cnn_configs()  :"},{"location":"documentation/cnn2/#print_all_architecture","text":"This function will print all the CNN architectures generated Parameters : None","title":"print_all_architecture()"},{"location":"documentation/cnn2/#get_bestcnn","text":"Parameters: path_trainset : str | path to the image training set path_testset : str | Optional[str] | path to the image test set split_required : bool | default = False | set to true if only there is no test set batch_size : int | default = 16 | Batch size lossFn : str | default = crossentropy | Most multiclass image classification problems use CrossEntropyLoss LR : float | default = 3e4 | Learning Rate EPOCHS : int | default = 10 | number Epochs image_shape : Tuple[int,int] | default = (28,28) | dimension of the input image from the training dataset Returns : Returns a tuple containing the best CNN model generated, its configuration, and history of all models generated ( best_CNN_model, best_model_config, history_of_all_models)","title":"get_bestCNN()"},{"location":"documentation/utils1/","text":"AutoNN.CNN.utils.image_augmentation.Augment class Augment ( path ) This class will augment the image dataset using the following image operations: Rotations Horizontal Flip Vertical Flip Parameters : path : str | path to the image dataset folder Note ''' path: provide the path to your image folder which you want to augment ../Folder/dataset/cats/x1.png ../Folder/dataset/cats/x2.png . . . ../Folder/dataset/dogs/xx1.png ../Folder/dataset/dogs/xx2.png ../Folder/dataset/dogs/xx3.png . . path = '../Folder/dataset/' ''' Method: augment() : Call this function to start augmentation Parameters : None Returns : None","title":"class Augment"},{"location":"documentation/utils1/#autonncnnutilsimage_augmentationaugment","text":"class Augment ( path ) This class will augment the image dataset using the following image operations: Rotations Horizontal Flip Vertical Flip Parameters : path : str | path to the image dataset folder Note ''' path: provide the path to your image folder which you want to augment ../Folder/dataset/cats/x1.png ../Folder/dataset/cats/x2.png . . . ../Folder/dataset/dogs/xx1.png ../Folder/dataset/dogs/xx2.png ../Folder/dataset/dogs/xx3.png . . path = '../Folder/dataset/' '''","title":"AutoNN.CNN.utils.image_augmentation.Augment"},{"location":"documentation/utils1/#method","text":"","title":"Method:"},{"location":"documentation/utils1/#augment","text":"Call this function to start augmentation Parameters : None Returns : None","title":"augment() :"},{"location":"gui/lesson1/","text":"How to use AutoNN GUI for tabular Dataset","title":"For Tabular Dataset"},{"location":"gui/lesson1/#how-to-use-autonn-gui-for-tabular-dataset","text":"","title":"How to use AutoNN GUI for tabular Dataset"},{"location":"gui/lesson2/","text":"How to use AutoNN GUI for Image Dataset","title":"For Image Dataset"},{"location":"gui/lesson2/#how-to-use-autonn-gui-for-image-dataset","text":"","title":"How to use AutoNN GUI for Image Dataset"},{"location":"tutorial/tut/","text":"Image Classification Using AutoNN AutoNN's CNN (Convolutional Neural Network) Models are built on PyTorch. 1. How to train a CNN model for image classification: Import CreateCNN from CNN's cnn_generator module Example from AutoNN.CNN.cnn_generator import CreateCNN , CNN inst = CreateCNN () model , model_config , history = inst . get_bestCNN ( path_trainset = \"E:/output/cifar10/cifar10/train\" , path_testset = \"E:/output/cifar10/cifar10/test\" , split_required = False , EPOCHS = 10 , image_shape = ( 32 , 32 )) Output \u2591\u2588\u2580\u2580\u2588 \u2588\u2591\u2591\u2588 \u2580\u2580\u2588\u2580\u2580 \u2588\u2580\u2580\u2588 \u2592\u2588\u2584\u2591\u2592\u2588 \u2592\u2588\u2584\u2591\u2592\u2588 \u2592\u2588\u2584\u2584\u2588 \u2588\u2591\u2591\u2588 \u2591\u2591\u2588\u2591\u2591 \u2588\u2591\u2591\u2588 \u2592\u2588\u2592\u2588\u2592\u2588 \u2592\u2588\u2592\u2588\u2592\u2588 \u2592\u2588\u2591\u2592\u2588 \u2591\u2580\u2580\u2580 \u2591\u2591\u2580\u2591\u2591 \u2580\u2580\u2580\u2580 \u2592\u2588\u2591\u2591\u2580\u2588 \u2592\u2588\u2591\u2591\u2580\u2588 Version: 2.0.0 An AutoML framework by Anish Konar, Arjun Ghosh, Rajarshi Banerjee, Sagnik Nayak. Default computing platform: cuda Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] # Classes: 10 Training set size: 40000 | Validation Set size: 10000 | Test Set size: 10000 Architecture search Complete..! Time Taken: 0:00:01.688582 Number of models generated: 2 Searching for the best model. Please be patient. Thank you.... Training CNN model cnn0 Epoch: 1/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:08<00:00, 36.24it/s] Training Accuracy: 35.1775 Training Loss:1.7207594780921935 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 65.11it/s] Validation Accuracy: 43.38 Validation Loss:1.5083902006149292 Epoch: 2/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.34it/s] Training Accuracy: 44.7975 Training Loss:1.483097927236557 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.63it/s] Validation Accuracy: 47.59 Validation Loss:1.4107291974067688 Epoch: 3/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.67it/s] Training Accuracy: 49.26 Training Loss:1.3825817276716232 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.44it/s] Validation Accuracy: 49.26 Validation Loss:1.3538662633895875 Epoch: 4/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:02<00:00, 39.78it/s] Training Accuracy: 51.4975 Training Loss:1.3264493201732634 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.79it/s] Validation Accuracy: 54.59 Validation Loss:1.263453982925415 Epoch: 5/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.61it/s] Training Accuracy: 53.3775 Training Loss:1.2788944167137146 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.93it/s] Validation Accuracy: 53.4 Validation Loss:1.2734063954353332 Epoch: 6/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.67it/s] Training Accuracy: 54.59 Training Loss:1.2445036834478378 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.81it/s] Validation Accuracy: 54.01 Validation Loss:1.2412574873924256 Epoch: 7/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.66it/s] Training Accuracy: 56.045 Training Loss:1.2121670446991921 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.66it/s] Validation Accuracy: 57.49 Validation Loss:1.1828145512580872 Epoch: 8/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:02<00:00, 39.71it/s] Training Accuracy: 56.75 Training Loss:1.1846893740534783 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.39it/s] Validation Accuracy: 58.49 Validation Loss:1.1632665138721465 Epoch: 9/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:02<00:00, 39.73it/s] Training Accuracy: 58.13 Training Loss:1.153260654783249 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.20it/s] Validation Accuracy: 60.65 Validation Loss:1.1054361756324769 Epoch: 10/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:02<00:00, 40.28it/s] Training Accuracy: 58.895 Training Loss:1.1318354423761368 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 73.48it/s] Validation Accuracy: 59.0 Validation Loss:1.1538037222385407 Calculating test accuracy CNN model cnn0 Test ACCuracy: 59.84 Test Loss: 1.13254158577919 ------------------------------------------------------------------------------------------------------------------------------------------------------ ______________________________________________________________________________________________________________________________________________________ Training CNN model cnn1 Epoch: 1/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 59.80it/s] Training Accuracy: 30.5625 Training Loss:1.8546679210186006 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.54it/s] Validation Accuracy: 33.79 Validation Loss:1.7818523860931397 Epoch: 2/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 60.42it/s] Training Accuracy: 39.33 Training Loss:1.6098018644332885 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.10it/s] Validation Accuracy: 43.24 Validation Loss:1.520786734867096 Epoch: 3/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 60.35it/s] Training Accuracy: 44.2325 Training Loss:1.5038440037250518 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.69it/s] Validation Accuracy: 45.07 Validation Loss:1.4924028639793396 Epoch: 4/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 60.33it/s] Training Accuracy: 47.06 Training Loss:1.438860204720497 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.10it/s] Validation Accuracy: 47.9 Validation Loss:1.4355408569335937 Epoch: 5/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 60.41it/s] Training Accuracy: 49.3625 Training Loss:1.3855291500329971 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.00it/s] Validation Accuracy: 51.42 Validation Loss:1.328598715877533 Epoch: 6/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 59.96it/s] Training Accuracy: 51.2 Training Loss:1.3459105017662047 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 66.04it/s] Validation Accuracy: 53.64 Validation Loss:1.2791677060127258 Epoch: 7/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:44<00:00, 56.65it/s] Training Accuracy: 52.4025 Training Loss:1.3105635814905168 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 69.72it/s] Validation Accuracy: 52.93 Validation Loss:1.2803085575103759 Epoch: 8/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:44<00:00, 56.75it/s] Training Accuracy: 53.41 Training Loss:1.2841510282278061 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 69.40it/s] Validation Accuracy: 55.3 Validation Loss:1.2356650713443755 Epoch: 9/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:43<00:00, 57.20it/s] Training Accuracy: 54.435 Training Loss:1.2552653106451035 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 67.85it/s] Validation Accuracy: 57.19 Validation Loss:1.1992870372772217 Epoch: 10/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:43<00:00, 57.08it/s] Training Accuracy: 55.0625 Training Loss:1.2330288346767426 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 67.08it/s] Validation Accuracy: 56.51 Validation Loss:1.2072079391002655 Calculating test accuracy CNN model cnn1 Test ACCuracy: 55.25 Test Loss: 1.2267251291751862 ------------------------------------------------------------------------------------------------------------------------------------------------------ ______________________________________________________________________________________________________________________________________________________ Best test accuracy achieved by model cnn0: 59.84 Print the model: print ( model ) Output CNN( (network): Sequential( (0): SkipLayer( (skiplayers): Sequential( (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (skip_connection): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1)) (relu): ReLU() ) (1): SkipLayer( (skiplayers): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (skip_connection): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1)) (relu): ReLU() ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (classifier): Sequential( (0): Linear(in_features=128, out_features=32, bias=True) (1): ReLU() (2): Linear(in_features=32, out_features=10, bias=True) ) ) Get list of all classes. Example: print ( inst . get_classes ) Output ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] Print Model configuration: print ( model_config ) Output [('conv', 16, 16), ('conv', 16, 128)] Print history of all training data: print ( history ) Output { 'cnn0': { 'trainloss': [1.7207594780921935, 1.483097927236557, 1.3825817276716232, 1.3264493201732634, 1.2788944167137146, 1.2445036834478378, 1.2121670446991921, 1.1846893740534783, 1.153260654783249, 1.1318354423761368], 'trainacc': [35.1775, 44.7975, 49.26, 51.4975, 53.3775, 54.59, 56.045, 56.75, 58.13, 58.895], 'valloss': [1.5083902006149292, 1.4107291974067688, 1.3538662633895875, 1.263453982925415, 1.2734063954353332, 1.2412574873924256, 1.1828145512580872, 1.1632665138721465, 1.1054361756324769, 1.1538037222385407], 'valacc': [43.38, 47.59, 49.26, 54.59, 53.4, 54.01, 57.49, 58.49, 60.65, 59.0]}, 'cnn1': { 'trainloss': [1.8546679210186006, 1.6098018644332885, 1.5038440037250518, 1.438860204720497, 1.3855291500329971, 1.3459105017662047, 1.3105635814905168, 1.2841510282278061, 1.2552653106451035, 1.2330288346767426], 'trainacc': [30.5625, 39.33, 44.2325, 47.06, 49.3625, 51.2, 52.4025, 53.41, 54.435, 55.0625], 'valloss': [1.7818523860931397, 1.520786734867096, 1.4924028639793396, 1.4355408569335937, 1.328598715877533, 1.2791677060127258, 1.2803085575103759, 1.2356650713443755, 1.1992870372772217, 1.2072079391002655], 'valacc': [33.79, 43.24, 45.07, 47.9, 51.42, 53.64, 52.93, 55.3, 57.19, 56.51] } } 2. Plot the Training loss vs Validation loss: from AutoNN.CNN.utils.EDA import plot_graph plot_graph ( history ) 3. How to save the model: model . save ( inst . get_classes , inst . get_imageshape , path = './best models/' , filename = 'mnistmodel.pth' , config_file_path = './best models/' , config_filename = 'mnistcfg.json' ) 4. To check the summary of the model: model . summary ( input_shape = ( 3 , 32 , 32 )) # this method will print the keras like summary of the model 5. How to load saved model: myModel = CNN ( 3 , 10 ) myModel . load ( PATH = './best models/mnistmodel.pth' , config_path = \"./best models/mnistcfg.json\" , printmodel = True ) Output Network Architecture loaded! CNN( (network): Sequential( (0): SkipLayer( (skiplayers): Sequential( (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (skip_connection): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1)) (relu): ReLU() ) (1): SkipLayer( (skiplayers): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (skip_connection): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1)) (relu): ReLU() ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (classifier): Sequential( (0): Linear(in_features=128, out_features=32, bias=True) (1): ReLU() (2): Linear(in_features=32, out_features=10, bias=True) ) ) Loading complete, your model is now ready for evaluation! 6. How to use Loaded model on new images: test_images = [ 'E:/output/cifar10/cifar10/test/bird/0012.png' , # bird 'E:/output/cifar10/cifar10/train/ship/0002.png' ] # ship myModel . predict ( paths = test_images ) Output ['bird', 'ship']","title":"Image Classification"},{"location":"tutorial/tut/#image-classification-using-autonn","text":"AutoNN's CNN (Convolutional Neural Network) Models are built on PyTorch.","title":"Image Classification Using AutoNN"},{"location":"tutorial/tut/#1-how-to-train-a-cnn-model-for-image-classification","text":"Import CreateCNN from CNN's cnn_generator module Example from AutoNN.CNN.cnn_generator import CreateCNN , CNN inst = CreateCNN () model , model_config , history = inst . get_bestCNN ( path_trainset = \"E:/output/cifar10/cifar10/train\" , path_testset = \"E:/output/cifar10/cifar10/test\" , split_required = False , EPOCHS = 10 , image_shape = ( 32 , 32 )) Output \u2591\u2588\u2580\u2580\u2588 \u2588\u2591\u2591\u2588 \u2580\u2580\u2588\u2580\u2580 \u2588\u2580\u2580\u2588 \u2592\u2588\u2584\u2591\u2592\u2588 \u2592\u2588\u2584\u2591\u2592\u2588 \u2592\u2588\u2584\u2584\u2588 \u2588\u2591\u2591\u2588 \u2591\u2591\u2588\u2591\u2591 \u2588\u2591\u2591\u2588 \u2592\u2588\u2592\u2588\u2592\u2588 \u2592\u2588\u2592\u2588\u2592\u2588 \u2592\u2588\u2591\u2592\u2588 \u2591\u2580\u2580\u2580 \u2591\u2591\u2580\u2591\u2591 \u2580\u2580\u2580\u2580 \u2592\u2588\u2591\u2591\u2580\u2588 \u2592\u2588\u2591\u2591\u2580\u2588 Version: 2.0.0 An AutoML framework by Anish Konar, Arjun Ghosh, Rajarshi Banerjee, Sagnik Nayak. Default computing platform: cuda Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'] # Classes: 10 Training set size: 40000 | Validation Set size: 10000 | Test Set size: 10000 Architecture search Complete..! Time Taken: 0:00:01.688582 Number of models generated: 2 Searching for the best model. Please be patient. Thank you.... Training CNN model cnn0 Epoch: 1/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:08<00:00, 36.24it/s] Training Accuracy: 35.1775 Training Loss:1.7207594780921935 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 65.11it/s] Validation Accuracy: 43.38 Validation Loss:1.5083902006149292 Epoch: 2/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.34it/s] Training Accuracy: 44.7975 Training Loss:1.483097927236557 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.63it/s] Validation Accuracy: 47.59 Validation Loss:1.4107291974067688 Epoch: 3/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.67it/s] Training Accuracy: 49.26 Training Loss:1.3825817276716232 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.44it/s] Validation Accuracy: 49.26 Validation Loss:1.3538662633895875 Epoch: 4/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:02<00:00, 39.78it/s] Training Accuracy: 51.4975 Training Loss:1.3264493201732634 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.79it/s] Validation Accuracy: 54.59 Validation Loss:1.263453982925415 Epoch: 5/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.61it/s] Training Accuracy: 53.3775 Training Loss:1.2788944167137146 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.93it/s] Validation Accuracy: 53.4 Validation Loss:1.2734063954353332 Epoch: 6/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.67it/s] Training Accuracy: 54.59 Training Loss:1.2445036834478378 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.81it/s] Validation Accuracy: 54.01 Validation Loss:1.2412574873924256 Epoch: 7/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:03<00:00, 39.66it/s] Training Accuracy: 56.045 Training Loss:1.2121670446991921 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.66it/s] Validation Accuracy: 57.49 Validation Loss:1.1828145512580872 Epoch: 8/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:02<00:00, 39.71it/s] Training Accuracy: 56.75 Training Loss:1.1846893740534783 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.39it/s] Validation Accuracy: 58.49 Validation Loss:1.1632665138721465 Epoch: 9/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:02<00:00, 39.73it/s] Training Accuracy: 58.13 Training Loss:1.153260654783249 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 70.20it/s] Validation Accuracy: 60.65 Validation Loss:1.1054361756324769 Epoch: 10/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [01:02<00:00, 40.28it/s] Training Accuracy: 58.895 Training Loss:1.1318354423761368 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 73.48it/s] Validation Accuracy: 59.0 Validation Loss:1.1538037222385407 Calculating test accuracy CNN model cnn0 Test ACCuracy: 59.84 Test Loss: 1.13254158577919 ------------------------------------------------------------------------------------------------------------------------------------------------------ ______________________________________________________________________________________________________________________________________________________ Training CNN model cnn1 Epoch: 1/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 59.80it/s] Training Accuracy: 30.5625 Training Loss:1.8546679210186006 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.54it/s] Validation Accuracy: 33.79 Validation Loss:1.7818523860931397 Epoch: 2/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 60.42it/s] Training Accuracy: 39.33 Training Loss:1.6098018644332885 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.10it/s] Validation Accuracy: 43.24 Validation Loss:1.520786734867096 Epoch: 3/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 60.35it/s] Training Accuracy: 44.2325 Training Loss:1.5038440037250518 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.69it/s] Validation Accuracy: 45.07 Validation Loss:1.4924028639793396 Epoch: 4/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 60.33it/s] Training Accuracy: 47.06 Training Loss:1.438860204720497 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.10it/s] Validation Accuracy: 47.9 Validation Loss:1.4355408569335937 Epoch: 5/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 60.41it/s] Training Accuracy: 49.3625 Training Loss:1.3855291500329971 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 76.00it/s] Validation Accuracy: 51.42 Validation Loss:1.328598715877533 Epoch: 6/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:41<00:00, 59.96it/s] Training Accuracy: 51.2 Training Loss:1.3459105017662047 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 66.04it/s] Validation Accuracy: 53.64 Validation Loss:1.2791677060127258 Epoch: 7/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:44<00:00, 56.65it/s] Training Accuracy: 52.4025 Training Loss:1.3105635814905168 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:08<00:00, 69.72it/s] Validation Accuracy: 52.93 Validation Loss:1.2803085575103759 Epoch: 8/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:44<00:00, 56.75it/s] Training Accuracy: 53.41 Training Loss:1.2841510282278061 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 69.40it/s] Validation Accuracy: 55.3 Validation Loss:1.2356650713443755 Epoch: 9/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:43<00:00, 57.20it/s] Training Accuracy: 54.435 Training Loss:1.2552653106451035 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 67.85it/s] Validation Accuracy: 57.19 Validation Loss:1.1992870372772217 Epoch: 10/10 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2500/2500 [00:43<00:00, 57.08it/s] Training Accuracy: 55.0625 Training Loss:1.2330288346767426 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 625/625 [00:09<00:00, 67.08it/s] Validation Accuracy: 56.51 Validation Loss:1.2072079391002655 Calculating test accuracy CNN model cnn1 Test ACCuracy: 55.25 Test Loss: 1.2267251291751862 ------------------------------------------------------------------------------------------------------------------------------------------------------ ______________________________________________________________________________________________________________________________________________________ Best test accuracy achieved by model cnn0: 59.84","title":"1. How to train a CNN model for image classification:"},{"location":"tutorial/tut/#print-the-model","text":"print ( model ) Output CNN( (network): Sequential( (0): SkipLayer( (skiplayers): Sequential( (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (skip_connection): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1)) (relu): ReLU() ) (1): SkipLayer( (skiplayers): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (skip_connection): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1)) (relu): ReLU() ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (classifier): Sequential( (0): Linear(in_features=128, out_features=32, bias=True) (1): ReLU() (2): Linear(in_features=32, out_features=10, bias=True) ) )","title":"Print the model:"},{"location":"tutorial/tut/#get-list-of-all-classes-example","text":"print ( inst . get_classes ) Output ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']","title":"Get list of all classes. Example:"},{"location":"tutorial/tut/#print-model-configuration","text":"print ( model_config ) Output [('conv', 16, 16), ('conv', 16, 128)]","title":"Print Model configuration:"},{"location":"tutorial/tut/#print-history-of-all-training-data","text":"print ( history ) Output { 'cnn0': { 'trainloss': [1.7207594780921935, 1.483097927236557, 1.3825817276716232, 1.3264493201732634, 1.2788944167137146, 1.2445036834478378, 1.2121670446991921, 1.1846893740534783, 1.153260654783249, 1.1318354423761368], 'trainacc': [35.1775, 44.7975, 49.26, 51.4975, 53.3775, 54.59, 56.045, 56.75, 58.13, 58.895], 'valloss': [1.5083902006149292, 1.4107291974067688, 1.3538662633895875, 1.263453982925415, 1.2734063954353332, 1.2412574873924256, 1.1828145512580872, 1.1632665138721465, 1.1054361756324769, 1.1538037222385407], 'valacc': [43.38, 47.59, 49.26, 54.59, 53.4, 54.01, 57.49, 58.49, 60.65, 59.0]}, 'cnn1': { 'trainloss': [1.8546679210186006, 1.6098018644332885, 1.5038440037250518, 1.438860204720497, 1.3855291500329971, 1.3459105017662047, 1.3105635814905168, 1.2841510282278061, 1.2552653106451035, 1.2330288346767426], 'trainacc': [30.5625, 39.33, 44.2325, 47.06, 49.3625, 51.2, 52.4025, 53.41, 54.435, 55.0625], 'valloss': [1.7818523860931397, 1.520786734867096, 1.4924028639793396, 1.4355408569335937, 1.328598715877533, 1.2791677060127258, 1.2803085575103759, 1.2356650713443755, 1.1992870372772217, 1.2072079391002655], 'valacc': [33.79, 43.24, 45.07, 47.9, 51.42, 53.64, 52.93, 55.3, 57.19, 56.51] } }","title":"Print history of all training data:"},{"location":"tutorial/tut/#2-plot-the-training-loss-vs-validation-loss","text":"from AutoNN.CNN.utils.EDA import plot_graph plot_graph ( history )","title":"2. Plot the Training loss vs Validation loss:"},{"location":"tutorial/tut/#3-how-to-save-the-model","text":"model . save ( inst . get_classes , inst . get_imageshape , path = './best models/' , filename = 'mnistmodel.pth' , config_file_path = './best models/' , config_filename = 'mnistcfg.json' )","title":"3. How to save the model:"},{"location":"tutorial/tut/#4-to-check-the-summary-of-the-model","text":"model . summary ( input_shape = ( 3 , 32 , 32 )) # this method will print the keras like summary of the model","title":"4. To check the summary of the model:"},{"location":"tutorial/tut/#5-how-to-load-saved-model","text":"myModel = CNN ( 3 , 10 ) myModel . load ( PATH = './best models/mnistmodel.pth' , config_path = \"./best models/mnistcfg.json\" , printmodel = True ) Output Network Architecture loaded! CNN( (network): Sequential( (0): SkipLayer( (skiplayers): Sequential( (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (skip_connection): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1)) (relu): ReLU() ) (1): SkipLayer( (skiplayers): Sequential( (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (skip_connection): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1)) (relu): ReLU() ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (classifier): Sequential( (0): Linear(in_features=128, out_features=32, bias=True) (1): ReLU() (2): Linear(in_features=32, out_features=10, bias=True) ) ) Loading complete, your model is now ready for evaluation!","title":"5. How to load saved model:"},{"location":"tutorial/tut/#6-how-to-use-loaded-model-on-new-images","text":"test_images = [ 'E:/output/cifar10/cifar10/test/bird/0012.png' , # bird 'E:/output/cifar10/cifar10/train/ship/0002.png' ] # ship myModel . predict ( paths = test_images ) Output ['bird', 'ship']","title":"6. How to use Loaded model on new images:"},{"location":"tutorial/tut1/","text":"ANN models","title":"Handle Tabular Dataset"},{"location":"tutorial/tut1/#ann-models","text":"","title":"ANN models"}]}