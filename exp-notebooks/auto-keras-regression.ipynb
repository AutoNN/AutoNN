{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SVyZBHaE6zqD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:37:16.194829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "# from autokeras import StructuredDataRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from IPython.display import HTML\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, '/home/anish/ASC_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASC_ML.networkbuilding import multiple_model_gen_v3 as multiple\n",
    "from ASC_ML.networkbuilding import dataframe_extractor as de\n",
    "from ASC_ML.networkbuilding import model_generation as model_gen\n",
    "from ASC_ML.networkbuilding import model_optimization as model_opt\n",
    "from ASC_ML.networkbuilding import model_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Bi5A13BZ6_17"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/anish/Downloads/autokeras-regression-master/Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "n9heEDsL7VRF",
    "outputId": "08d5989f-cd83-4bf3-bcb0-8622664384fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "xj63U7al-28H",
    "outputId": "74713606-0aba-4d27-9639-091b601b7e27"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"TV\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "6JNLdc67Jsz8",
    "outputId": "52abc809-f857-4243-d3a8-b3468b72843d"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"radio\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "HhyWxbnSJ0pX",
    "outputId": "f680d6b6-b482-471a-e09f-ed5cbee67653"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"newspaper\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y_T3s3Yj7jRk"
   },
   "outputs": [],
   "source": [
    "target_col = \"sales\"\n",
    "X = df.loc[:, df.columns != target_col]\n",
    "y = df.loc[:, target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DAJC0VIH7ptP"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((y_train.shape[0],1))\n",
    "y_test = y_test.reshape((y_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:40:08.154893: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-31 20:40:08.155539: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-31 20:40:08.214974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:40:08.215228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-31 20:40:08.215272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 20:40:08.217884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-31 20:40:08.217953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-31 20:40:08.220170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-31 20:40:08.220578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-31 20:40:08.223275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-31 20:40:08.224837: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-31 20:40:08.229555: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-31 20:40:08.229722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:40:08.229985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:40:08.230132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-31 20:40:08.230515: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-31 20:40:08.230781: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-31 20:40:08.230882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:40:08.231023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-31 20:40:08.231056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 20:40:08.231080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-31 20:40:08.231102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-31 20:40:08.231123: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-31 20:40:08.231144: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-31 20:40:08.231165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-31 20:40:08.231187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-31 20:40:08.231209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-31 20:40:08.231275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:40:08.231452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:40:08.231573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-31 20:40:08.231614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 20:40:08.616379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-31 20:40:08.616407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-08-31 20:40:08.616412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-08-31 20:40:08.616565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:40:08.616717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:40:08.616835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:40:08.616927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5044 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-08-31 20:40:08.889831: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-08-31 20:40:08.890260: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n",
      "2022-08-31 20:40:10.133618: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  10.594283103942871 , TEST :  11.34982967376709\n",
      "output_layer_dense_32_32_loss  :  1.1226089000701904 , TEST :  1.2004287242889404\n",
      "output_layer_dense_32_64_loss  :  1.1307462453842163 , TEST :  1.2921745777130127\n",
      "output_layer_dense_32_128_loss  :  1.2170664072036743 , TEST :  1.279090166091919\n",
      "output_layer_dense_64_32_loss  :  1.1581077575683594 , TEST :  1.2090129852294922\n",
      "output_layer_dense_64_64_loss  :  1.3285554647445679 , TEST :  1.3847533464431763\n",
      "output_layer_dense_64_128_loss  :  1.0729682445526123 , TEST :  1.230327844619751\n",
      "output_layer_dense_128_32_loss  :  1.249609351158142 , TEST :  1.2621759176254272\n",
      "output_layer_dense_128_64_loss  :  1.0354626178741455 , TEST :  1.2002227306365967\n",
      "output_layer_dense_128_128_loss  :  1.279158353805542 , TEST :  1.291643738746643\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  11.597386360168457 , TEST :  13.247419357299805\n",
      "output_layer_dense_32_32_32_loss  :  1.0324798822402954 , TEST :  1.1432483196258545\n",
      "output_layer_dense_32_32_64_loss  :  1.0075980424880981 , TEST :  1.0682637691497803\n",
      "output_layer_dense_32_32_128_loss  :  0.965293288230896 , TEST :  1.1084342002868652\n",
      "output_layer_dense_32_64_32_loss  :  0.9880782961845398 , TEST :  1.1141064167022705\n",
      "output_layer_dense_32_64_64_loss  :  1.2822784185409546 , TEST :  1.561834692955017\n",
      "output_layer_dense_32_64_128_loss  :  1.3359715938568115 , TEST :  1.394703984260559\n",
      "output_layer_dense_32_128_32_loss  :  1.2932984828948975 , TEST :  1.53521728515625\n",
      "output_layer_dense_32_128_64_loss  :  1.0191090106964111 , TEST :  1.1258059740066528\n",
      "output_layer_dense_32_128_128_loss  :  1.4952356815338135 , TEST :  1.805978536605835\n",
      "output_layer_dense_64_32_32_loss  :  1.1780437231063843 , TEST :  1.3898271322250366\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3f640ceee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  10.789617538452148 , TEST :  11.95559024810791\n",
      "output_layer_dense_64_64_32_loss  :  1.1160800457000732 , TEST :  1.3344638347625732\n",
      "output_layer_dense_64_64_64_loss  :  1.0479552745819092 , TEST :  1.2012832164764404\n",
      "output_layer_dense_64_64_128_loss  :  0.9527229070663452 , TEST :  1.0981225967407227\n",
      "output_layer_dense_64_128_32_loss  :  1.089025616645813 , TEST :  1.0760314464569092\n",
      "output_layer_dense_64_128_64_loss  :  1.0318279266357422 , TEST :  1.1188920736312866\n",
      "output_layer_dense_64_128_128_loss  :  1.0143253803253174 , TEST :  1.2229293584823608\n",
      "output_layer_dense_128_32_32_loss  :  1.0530469417572021 , TEST :  1.152923822402954\n",
      "output_layer_dense_128_64_32_loss  :  1.0953119993209839 , TEST :  1.1887983083724976\n",
      "output_layer_dense_128_64_64_loss  :  1.3254282474517822 , TEST :  1.2951700687408447\n",
      "output_layer_dense_128_128_32_loss  :  1.0638935565948486 , TEST :  1.2669751644134521\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3f641334c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  2.323321580886841 , TEST :  2.566749095916748\n",
      "output_layer_dense_128_128_64_loss  :  1.3325061798095703 , TEST :  1.4402388334274292\n",
      "output_layer_dense_128_128_128_loss  :  0.9908151626586914 , TEST :  1.1265103816986084\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "[{'model_name': 'dense_32_32_64', 'score': 1.0682637691497803, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3f64259cd0>}, {'model_name': 'dense_64_128_32', 'score': 1.0760314464569092, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3f641de190>}, {'model_name': 'dense_64_64_128', 'score': 1.0981225967407227, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3f641e56d0>}, {'model_name': 'dense_32_32_128', 'score': 1.1084342002868652, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3f642598e0>}, {'model_name': 'dense_32_64_32', 'score': 1.1141064167022705, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_64_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 64, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3f64259460>}, {'model_name': 'dense_64_128_64', 'score': 1.1188920736312866, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3f6421dd60>}, {'model_name': 'dense_32_128_64', 'score': 1.1258059740066528, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_128_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 128, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3f6425aaf0>}, {'model_name': 'dense_128_128_128', 'score': 1.1265103816986084, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_128_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 128, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3fbc75df70>}, {'model_name': 'dense_32_32_32', 'score': 1.1432483196258545, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3f643a20d0>}, {'model_name': 'dense_128_32_32', 'score': 1.152923822402954, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_32_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 32, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f3f401fcf40>}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Time Taken :  11.030333042144775\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 3, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = False)\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list, save_dir = \"/home/anish/ASC_ML_test_weights/candidate_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_32_64\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3fd01e1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.31922340393066406, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunUniform, BEST_LEARINING_RATE : 0.002, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.38567402958869934 , TEST :  0.513252317905426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:41:19.506763: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_32_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.793637216091156, BEST_ACTIVATION : relu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4653832018375397 , TEST :  0.577656090259552\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_128_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_64_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.4756823480129242, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunUniform, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.38202396035194397 , TEST :  0.48571911454200745\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2669084668159485, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunUniform, BEST_LEARINING_RATE : 0.01, BEST_BATCHSIZE : 64\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.384723037481308 , TEST :  0.4453960359096527\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_32_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_64_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.39349502325057983, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunUniform, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4180920720100403 , TEST :  0.5636706352233887\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_64_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_128_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5285534858703613, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunUniform, BEST_LEARINING_RATE : 0.0002, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.6196008920669556 , TEST :  0.6851707696914673\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_128_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_128_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.30739372968673706, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.826002299785614 , TEST :  0.9901336431503296\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_128_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_128_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.4125913679599762, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunNormal, BEST_LEARINING_RATE : 0.0005, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3109543025493622 , TEST :  0.4389670491218567\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_128_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_32_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.28708308935165405, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunUniform, BEST_LEARINING_RATE : 0.00251, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.2571888267993927 , TEST :  0.3870408535003662\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_32_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_32_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.3906829059123993, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunUniform, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3806971609592438 , TEST :  0.40418821573257446\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_32_32/assets\n"
     ]
    }
   ],
   "source": [
    "opt.optimize_models(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 64}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 32}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 128}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 64, 'layer3': 32}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 64}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 128, 'layer3': 64}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 128, 'layer3': 128}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 32}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 32, 'layer3': 32}, [1, None]]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.model_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.002, 16, 'selu', 'LecunUniform'],\n",
       " [0.001, 16, 'relu', 'GlorotNormal'],\n",
       " [0.001, 32, 'selu', 'LecunUniform'],\n",
       " [0.01, 64, 'selu', 'LecunUniform'],\n",
       " [0.001, 32, 'selu', 'LecunUniform'],\n",
       " [0.0002, 16, 'selu', 'LecunUniform'],\n",
       " [0.0004, 16, 'selu', 'LecunUniform'],\n",
       " [0.0005, 16, 'selu', 'LecunNormal'],\n",
       " [0.00251, 32, 'selu', 'LecunUniform'],\n",
       " [0.00063, 16, 'selu', 'LecunUniform']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_hyp_permodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class Dropout_Optimization():\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, epochs, model):\n",
    "        self._train_x = train_x\n",
    "        self._train_y = train_y\n",
    "        self._test_x = test_x\n",
    "        self._test_y = test_y\n",
    "        self._epochs = epochs\n",
    "        self._model = model\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        # Logic to get loss funtion\n",
    "        # return \"mean_absolute_percentage_error\"\n",
    "        # return self.root_mean_squared_error\n",
    "        # return \"mean_squared_error\"\n",
    "        return \"mean_absolute_error\"\n",
    "\n",
    "    def dropout_optimization(self, lr = 1e-3, batch_size = 64, epoch = 100):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        dropout_indices = self._get_dropout_index()\n",
    "        dropout_list = [0,0.2,0.5]\n",
    "        dropout_comb_list = []\n",
    "        dropout_loss_list = []\n",
    "        for dropout0 in dropout_list:\n",
    "            for dropout1 in dropout_list:\n",
    "                dropout_comb_list.append([dropout0,dropout1])\n",
    "                self._model.layers[dropout_indices[0]].rate = dropout0\n",
    "                self._model.layers[dropout_indices[1]].rate = dropout1\n",
    "                optimizer = Adam(lr = lr)\n",
    "                self._model.compile(loss = loss_fn, optimizer = optimizer)\n",
    "                history = self._model.fit(self._train_x, self._train_y, epochs = epoch, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "                scores = self._model.evaluate(self._train_x, self._train_y, verbose = 0)\n",
    "                scores_test = self._model.evaluate(self._test_x, self._test_y, verbose = 0)\n",
    "#                 print(f\"For Dropouts D0 = {dropout0}, D1 = {dropout1}, TRAIN_LOSS = {scores}, TEST_LOSS = {scores_test}\")\n",
    "                dropout_loss_list.append(scores_test)\n",
    "                \n",
    "        best_dropout_rates = dropout_comb_list[dropout_loss_list.index(min(dropout_loss_list))]\n",
    "        self._model.layers[dropout_indices[0]].rate = best_dropout_rates[0]\n",
    "        self._model.layers[dropout_indices[1]].rate = best_dropout_rates[1]\n",
    "        return best_dropout_rates\n",
    "                \n",
    "\n",
    "    def _get_dropout_index(self):\n",
    "        dropout_indices = []\n",
    "        ind = 0\n",
    "        for layer in self._model.layers:\n",
    "            if layer.__class__.__name__ == \"Dropout\":\n",
    "                dropout_indices.append(ind)\n",
    "            ind = ind+1\n",
    "        return dropout_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.initializers import RandomUniform, GlorotUniform, GlorotNormal, HeUniform, HeNormal\n",
    "\n",
    "from ASC_ML.networkbuilding import model_generation as model_gen\n",
    "from ASC_ML.networkbuilding import hyperparameter_optimization as hyp_opt\n",
    "\n",
    "class Model_Stacking2:\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, model_path_list, model_conf_list, save_dir = \"\"):\n",
    "        self._model_path_list = model_path_list\n",
    "        self._model_conf_list = model_conf_list\n",
    "        self._train_x = train_x\n",
    "        self._train_y = train_y\n",
    "        self._test_x = test_x\n",
    "        self._test_y = test_y\n",
    "        self._save_dir = save_dir\n",
    "        self._stacked_model_paths = []\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        # Logic to get loss funtion\n",
    "        # return \"mean_absolute_percentage_error\"\n",
    "        # return self.root_mean_squared_error\n",
    "        # return \"mean_squared_error\"\n",
    "        return \"mean_absolute_error\"\n",
    "\n",
    "    def _stacked_model_generator(self):\n",
    "        for path in self._model_path_list:\n",
    "            for model_conf in self._model_conf_list:\n",
    "                model1 = load_model(path)\n",
    "                activation = model1.layers[-2].get_config()[\"activation\"]\n",
    "                reduced_model1 = Model(name = model1.name+\"_reduced\", inputs = model1.input, outputs = model1.layers[-2].output)\n",
    "                last_layer = reduced_model1.output\n",
    "                x = last_layer\n",
    "                model2_obj = model_gen.NN_ModelGeneration(*model_conf)\n",
    "                x = Dropout(0.0)(x)\n",
    "                for layer_name in model2_obj.layer_conf:\n",
    "                    x = Dense(model2_obj.layer_conf[layer_name], activation = activation, name = layer_name+\"_2nd\")(x)\n",
    "                x = Dropout(0.0)(x)\n",
    "                output_layer = Dense(model2_obj.output_layer_conf[0], activation = model2_obj.output_layer_conf[1], name = \"output_layer\" + \"_\" + model2_obj.model_name)(x)\n",
    "\n",
    "                stacked_model = Model(name = model1.name + \"_st_\" + model2_obj.model_name,inputs = reduced_model1.input, outputs = output_layer)\n",
    "                x = None\n",
    "                output_layer = None\n",
    "                yield stacked_model\n",
    "\n",
    "    def optimize_stacked_models(self):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        stacked_model_generator = self._stacked_model_generator()\n",
    "        for model in stacked_model_generator:\n",
    "            print(model.name)\n",
    "            print(model.summary())\n",
    "            h = hyp_opt.Hyperparameter_Optimization([self._train_x], [self._train_y], model, loss_fn, activation_opt = True, initializer_opt = True)\n",
    "            best_lr, best_batch_size, _, best_initializer = h.get_best_hyperparameters()\n",
    "            print(best_initializer)\n",
    "            self._reinitialize_model(model, best_initializer)\n",
    "            \n",
    "            dr = Dropout_Optimization(self._train_x, self._train_y, self._test_x, self._test_y, epochs = 100, model = model)\n",
    "            best_dropout_rates = dr.dropout_optimization(lr = best_lr, batch_size = best_batch_size, epoch = 100)\n",
    "            print(f\"DROPOUT RATES : {best_dropout_rates}\")\n",
    "            \n",
    "            model = self._train_models(model = model, lr = best_lr, batch_size = best_batch_size)\n",
    "            self._save_model(model)\n",
    "            \n",
    "#             print(f\"BEST LR STACKED {best_lr}, BEST BATCH SIZE {best_batch_size}\")\n",
    "#             dr = Dropout_Optimization(self._train_x, self._train_y, self._test_x, self._test_y, epochs = 100, model = model)\n",
    "#             dr.dropout_optimization(lr = best_lr, batch_size = best_batch_size, epoch = 100)\n",
    "    \n",
    "    def _train_models(self, model, lr, batch_size):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        optimizer = Adam(lr = lr)\n",
    "        model.compile(loss = loss_fn, optimizer = optimizer)\n",
    "        history = model.fit(self._train_x, self._train_y, epochs = 100, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "        scores = model.evaluate(self._train_x, self._train_y, verbose = 0)\n",
    "        scores_test = model.evaluate(self._test_x, self._test_y, verbose = 0)\n",
    "        print(f\"TRAIN_LOSS = {scores}, TEST_LOSS = {scores_test}\")\n",
    "        return model\n",
    "        \n",
    "    @staticmethod\n",
    "    def _reinitialize_model(model, initializer_str = \"RandomUniform\"):\n",
    "        if initializer_str == \"RandomUniform\":\n",
    "            initializer = RandomUniform(seed = 420)\n",
    "        elif initializer_str == \"GlorotUniform\":\n",
    "            initializer = GlorotUniform(seed = 420)\n",
    "        elif initializer_str == \"HeUniform\":\n",
    "            initializer = HeUniform(seed = 420)\n",
    "        elif initializer_str == \"GlorotNormal\":\n",
    "            initializer = GlorotNormal(seed = 420)\n",
    "        elif initializer_str == \"HeNormal\":\n",
    "            initializer = HeNormal(seed = 420)\n",
    "        for layer in model.layers:\n",
    "            layer.set_weights([initializer(shape=w.shape) for w in layer.get_weights()])\n",
    "            \n",
    "    def _save_model(self, model):\n",
    "        path = os.path.join(self._save_dir,model.name)\n",
    "        model.save(path)\n",
    "        self._stacked_model_paths.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_32_32_64_st_dense_32_32_64\n",
      "Model: \"dense_32_32_64_st_dense_32_32_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_32_32_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_32_64 (Dense (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_32_64 (Dense (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_32_64 (Dense (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_32_64_2nd (D (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_32_64_2nd (D (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_32_64_2nd (D (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_32_32_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,609\n",
      "Trainable params: 8,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2544627785682678, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunNormal, BEST_LEARINING_RATE : 0.00126, BEST_BATCHSIZE : 16\n",
      "LecunNormal\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.1866564303636551, TEST_LOSS = 0.38304275274276733\n",
      "dense_32_32_64_st_dense_64_128_32\n",
      "Model: \"dense_32_32_64_st_dense_64_128_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_32_32_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_32_64 (Dense (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_32_64 (Dense (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_32_64 (Dense (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32_2nd ( (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32_2nd ( (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_128_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 19,937\n",
      "Trainable params: 19,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2397851049900055, BEST_ACTIVATION : selu, BEST_INITIALIZER : LecunUniform, BEST_LEARINING_RATE : 0.0005, BEST_BATCHSIZE : 16\n",
      "LecunUniform\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m stacked_models \u001b[38;5;241m=\u001b[39m model_stacking\u001b[38;5;241m.\u001b[39mModel_Stacking(X_train, y_train, X_test, y_test, opt\u001b[38;5;241m.\u001b[39msaved_paths, opt\u001b[38;5;241m.\u001b[39mmodel_confs, save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/anish/ASC_ML_test_weights/stacked_models/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstacked_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_stacked_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/model_stacking.py:63\u001b[0m, in \u001b[0;36mModel_Stacking.optimize_stacked_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(model, best_initializer)\n\u001b[1;32m     62\u001b[0m dr \u001b[38;5;241m=\u001b[39m Dropout_Optimization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_y, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, model \u001b[38;5;241m=\u001b[39m model)\n\u001b[0;32m---> 63\u001b[0m best_dropout_rates \u001b[38;5;241m=\u001b[39m \u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROPOUT RATES : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_dropout_rates\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_models(model \u001b[38;5;241m=\u001b[39m model, lr \u001b[38;5;241m=\u001b[39m best_lr, batch_size \u001b[38;5;241m=\u001b[39m best_batch_size)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/dropout_optimization.py:34\u001b[0m, in \u001b[0;36mDropout_Optimization.dropout_optimization\u001b[0;34m(self, lr, batch_size, epoch)\u001b[0m\n\u001b[1;32m     32\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m loss_fn, optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[0;32m---> 34\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_y, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m scores_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_y, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:555\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    564\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    567\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    568\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stacked_models = model_stacking.Model_Stacking(X_train, y_train, X_test, y_test, opt.saved_paths, opt.model_confs, save_dir = \"/home/anish/ASC_ML_test_weights/stacked_models/\")\n",
    "stacked_models.optimize_stacked_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_models = model_stacking.Model_Stacking(opt.saved_paths, opt.model_confs)\n",
    "stacked_models = Model_Stacking2(X_train, y_train, X_test, y_test, opt.saved_paths, opt.model_confs, save_dir = \"/home/anish/ASC_ML_test_weights/stacked_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_64_128_32_st_dense_64_128_32\n",
      "Model: \"dense_64_128_32_st_dense_64_128_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32_2nd ( (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32_2nd ( (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_128_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 27,297\n",
      "Trainable params: 27,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2102661430835724, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00126, BEST_BATCHSIZE : 64\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.18974287807941437, TEST_LOSS = 0.3626607358455658\n",
      "dense_64_128_32_st_dense_64_128_64\n",
      "Model: \"dense_64_128_32_st_dense_64_128_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_64_2nd ( (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_64_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_64_2nd ( (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_128_64 (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 31,457\n",
      "Trainable params: 31,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2152978628873825, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "GlorotNormal\n",
      "DROPOUT RATES : [0, 0.2]\n",
      "TRAIN_LOSS = 0.2746140658855438, TEST_LOSS = 0.395169198513031\n",
      "dense_64_128_32_st_dense_64_64_128\n",
      "Model: \"dense_64_128_32_st_dense_64_64_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_128_2nd ( (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_128_2nd ( (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_128_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_128 (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 27,425\n",
      "Trainable params: 27,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2167428433895111, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 32\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0.2]\n",
      "TRAIN_LOSS = 0.46205559372901917, TEST_LOSS = 0.5042843818664551\n",
      "dense_64_128_32_st_dense_128_64_32\n",
      "Model: \"dense_64_128_32_st_dense_128_64_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_64_32_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_64_32_2nd ( (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_64_32_2nd ( (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_64_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 27,297\n",
      "Trainable params: 27,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.20106205344200134, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.20413604378700256, TEST_LOSS = 0.3925964832305908\n",
      "dense_64_128_32_st_dense_32_128\n",
      "Model: \"dense_64_128_32_st_dense_32_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_128_2nd (Den (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_128_2nd (Den (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_32_128 (D (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 18,113\n",
      "Trainable params: 18,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.19186227023601532, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00032, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.17292746901512146, TEST_LOSS = 0.3159737288951874\n",
      "dense_64_128_32_st_dense_32_32_128\n",
      "Model: \"dense_64_128_32_st_dense_32_32_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_32_128_2nd ( (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_32_128_2nd ( (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_32_128_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_32_32_128 (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 19,169\n",
      "Trainable params: 19,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2549762725830078, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotNormal\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.1746048629283905, TEST_LOSS = 0.3850560188293457\n",
      "dense_64_128_32_st_dense_128_64_64\n",
      "Model: \"dense_64_128_32_st_dense_128_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_64_64_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_64_64_2nd ( (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_64_64_2nd ( (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_64_64 (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 29,409\n",
      "Trainable params: 29,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.26172542572021484, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0.2]\n",
      "TRAIN_LOSS = 0.4665142893791199, TEST_LOSS = 0.6047951579093933\n",
      "dense_64_128_32_st_dense_128_32_32\n",
      "Model: \"dense_64_128_32_st_dense_128_32_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_32_32_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_32_32_2nd ( (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_32_32_2nd ( (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_32_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.25475889444351196, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00251, BEST_BATCHSIZE : 64\n",
      "GlorotNormal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.3202672004699707, TEST_LOSS = 0.47966986894607544\n",
      "dense_64_128_32_st_dense_128_128_32\n",
      "Model: \"dense_64_128_32_st_dense_128_128_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_128_32_2nd  (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_128_32_2nd  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_128_32_2nd  (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_128_3 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 37,601\n",
      "Trainable params: 37,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstacked_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_stacked_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mModel_Stacking2.optimize_stacked_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     53\u001b[0m h \u001b[38;5;241m=\u001b[39m hyp_opt\u001b[38;5;241m.\u001b[39mHyperparameter_Optimization([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_x], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_y], model, loss_fn, activation_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, initializer_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 54\u001b[0m best_lr, best_batch_size, _, best_initializer \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_initializer)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(model, best_initializer)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:120\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.get_best_hyperparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m initializer \u001b[38;5;129;01min\u001b[39;00m intializer_list[i]:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(initializer_str\u001b[38;5;241m=\u001b[39minitializer)\n\u001b[0;32m--> 120\u001b[0m     lr, batch_size, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_batch_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitializer_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(best_loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m loss\u001b[38;5;241m<\u001b[39mbest_loss):\n\u001b[1;32m    122\u001b[0m         best_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:147\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.lr_batch_optimization\u001b[0;34m(self, initializer_str)\u001b[0m\n\u001b[1;32m    145\u001b[0m     best_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lr_opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     best_lr, best_batch_size, best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_batch_size_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitializer_str\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitializer_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_lr, best_batch_size, best_loss\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:90\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.get_best_batch_size_lr\u001b[0;34m(self, initializer_str)\u001b[0m\n\u001b[1;32m     87\u001b[0m best_lr_batch, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_best_lr(batch_size)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(initializer_str\u001b[38;5;241m=\u001b[39minitializer_str)\n\u001b[0;32m---> 90\u001b[0m best_loss_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_lr_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m best_lr_list\u001b[38;5;241m.\u001b[39mappend(best_lr_batch)\n\u001b[1;32m     93\u001b[0m best_loss_list\u001b[38;5;241m.\u001b[39mappend(best_loss_batch)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:75\u001b[0m, in \u001b[0;36mHyperparameter_Optimization._train_model\u001b[0;34m(self, lr, batch_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_fn, optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[0;32m---> 75\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_Y, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1077\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n\u001b[1;32m   1068\u001b[0m   callbacks \u001b[38;5;241m=\u001b[39m callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList(\n\u001b[1;32m   1069\u001b[0m       callbacks,\n\u001b[1;32m   1070\u001b[0m       add_history\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1074\u001b[0m       epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m   1075\u001b[0m       steps\u001b[38;5;241m=\u001b[39mdata_handler\u001b[38;5;241m.\u001b[39minferred_steps)\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_counter\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:324\u001b[0m, in \u001b[0;36mModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    317\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# six.raise_from supresses the original AttributeError from being raised\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIt looks like you are subclassing `Model` and you \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforgot to call `super(YourClass, self).__init__()`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    322\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Always start with this line.\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2847\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;66;03m# Clean out the old attribute, which clears _layers and _trainable_weights\u001b[39;00m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;66;03m# if necessary.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2847\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__delattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   2849\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2797\u001b[0m, in \u001b[0;36mLayer.__delattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2794\u001b[0m   \u001b[38;5;28msuper\u001b[39m(tracking\u001b[38;5;241m.\u001b[39mAutoTrackable, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__delattr__\u001b[39m(name)\n\u001b[1;32m   2795\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2797\u001b[0m reference_count \u001b[38;5;241m=\u001b[39m \u001b[43mreference_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexisting_value\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reference_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2799\u001b[0m   \u001b[38;5;66;03m# There are other remaining references. We can't remove this object from\u001b[39;00m\n\u001b[1;32m   2800\u001b[0m   \u001b[38;5;66;03m# _layers etc.\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m   reference_counts[existing_value] \u001b[38;5;241m=\u001b[39m reference_count \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/util/object_identity.py:138\u001b[0m, in \u001b[0;36mObjectIdentityDictionary.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 138\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/util/object_identity.py:67\u001b[0m, in \u001b[0;36m_ObjectIdentityWrapper.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;66;03m# Wrapper id() is also fine for weakrefs. In fact, we rely on\u001b[39;00m\n\u001b[1;32m     65\u001b[0m   \u001b[38;5;66;03m# id(weakref.ref(a)) == id(weakref.ref(a)) and weakref.ref(a) is\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   \u001b[38;5;66;03m# weakref.ref(a) in _WeakObjectIdentityWrapper.\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stacked_models.optimize_stacked_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"/home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_64/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selu\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "activation = model.layers[-2].get_config()[\"activation\"]\n",
    "print(activation)\n",
    "print(type(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64_reduced\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 8,576\n",
      "Trainable params: 8,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reduce_model = Model(name = model.name+\"_reduced\", inputs = model.input, outputs = model.layers[-2].output)\n",
    "print(reduce_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Flatten, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = Sequential()\n",
    "# new_model.add(Dropout(0.1))\n",
    "# new_model.add(reduce_model)\n",
    "# new_model.add(Dropout(0.2))\n",
    "# new_model.add(Dense(1024, activation = activation))\n",
    "# new_model.add(Dense(1024, activation = activation))\n",
    "# new_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = reduce_model.output\n",
    "x = last_layer\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1024, activation = activation)(x)\n",
    "x = Dense(1024, activation = activation)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1)(x)\n",
    "new_model = Model(inputs = reduce_model.input, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_326 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_327 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,125,761\n",
      "Trainable params: 1,125,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7]\n"
     ]
    }
   ],
   "source": [
    "dropout_ind = []\n",
    "ind = 0\n",
    "for layer in new_model.layers:\n",
    "    if layer.__class__.__name__ == \"Dropout\":\n",
    "        dropout_ind.append(ind)\n",
    "    ind = ind+1\n",
    "print(dropout_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.layers[4].rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.layers[4].rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 2)\n",
      "(63, 1) (63,)\n",
      "(42, 1) (21, 1) (42,) (21,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load the sonar dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "print(dataframe.shape)\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "data = data.astype('float32')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  564.4772338867188 , TEST :  696.4302978515625\n",
      "output_layer_dense_32_32_loss  :  77.97647094726562 , TEST :  102.96764373779297\n",
      "output_layer_dense_32_64_loss  :  72.4428939819336 , TEST :  94.78680419921875\n",
      "output_layer_dense_32_128_loss  :  43.49039840698242 , TEST :  50.427490234375\n",
      "output_layer_dense_32_1024_loss  :  32.640380859375 , TEST :  31.093881607055664\n",
      "output_layer_dense_64_32_loss  :  68.5215072631836 , TEST :  88.98941802978516\n",
      "output_layer_dense_64_64_loss  :  67.38311004638672 , TEST :  87.2926254272461\n",
      "output_layer_dense_64_128_loss  :  41.06880569458008 , TEST :  45.563011169433594\n",
      "output_layer_dense_64_1024_loss  :  32.03666687011719 , TEST :  28.78836441040039\n",
      "output_layer_dense_128_32_loss  :  72.19493103027344 , TEST :  94.40507507324219\n",
      "output_layer_dense_128_64_loss  :  56.72202682495117 , TEST :  72.11593627929688\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  204.6041717529297 , TEST :  193.50648498535156\n",
      "output_layer_dense_128_128_loss  :  43.74370574951172 , TEST :  50.91599655151367\n",
      "output_layer_dense_128_1024_loss  :  31.940673828125 , TEST :  27.309024810791016\n",
      "output_layer_dense_1024_32_loss  :  31.918380737304688 , TEST :  27.996408462524414\n",
      "output_layer_dense_1024_64_loss  :  33.159645080566406 , TEST :  34.39208984375\n",
      "output_layer_dense_1024_128_loss  :  31.97357177734375 , TEST :  25.20755386352539\n",
      "output_layer_dense_1024_1024_loss  :  31.868175506591797 , TEST :  27.685407638549805\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  396.1885681152344 , TEST :  412.23150634765625\n",
      "output_layer_dense_32_32_32_loss  :  67.75357818603516 , TEST :  87.86875915527344\n",
      "output_layer_dense_32_32_64_loss  :  55.70736312866211 , TEST :  70.67930603027344\n",
      "output_layer_dense_32_32_128_loss  :  33.16255569458008 , TEST :  25.683181762695312\n",
      "output_layer_dense_32_32_1024_loss  :  32.28651809692383 , TEST :  29.9041805267334\n",
      "output_layer_dense_32_64_32_loss  :  35.29856872558594 , TEST :  32.24654006958008\n",
      "output_layer_dense_32_64_64_loss  :  43.165130615234375 , TEST :  49.84916305541992\n",
      "output_layer_dense_32_64_128_loss  :  32.039371490478516 , TEST :  28.813858032226562\n",
      "output_layer_dense_32_64_1024_loss  :  31.844669342041016 , TEST :  27.289440155029297\n",
      "output_layer_dense_32_128_32_loss  :  31.92618179321289 , TEST :  27.147016525268555\n",
      "output_layer_dense_32_128_64_loss  :  33.00459671020508 , TEST :  32.75004959106445\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0a203ec700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  400.072998046875 , TEST :  415.59356689453125\n",
      "output_layer_dense_32_128_128_loss  :  33.348819732666016 , TEST :  35.67073440551758\n",
      "output_layer_dense_32_128_1024_loss  :  31.862337112426758 , TEST :  26.892961502075195\n",
      "output_layer_dense_32_1024_32_loss  :  32.63373565673828 , TEST :  31.09195327758789\n",
      "output_layer_dense_32_1024_64_loss  :  31.856761932373047 , TEST :  26.121145248413086\n",
      "output_layer_dense_32_1024_128_loss  :  31.77286148071289 , TEST :  26.318124771118164\n",
      "output_layer_dense_32_1024_1024_loss  :  31.885509490966797 , TEST :  25.188533782958984\n",
      "output_layer_dense_64_32_32_loss  :  63.9492301940918 , TEST :  82.36168670654297\n",
      "output_layer_dense_64_64_32_loss  :  72.885009765625 , TEST :  95.42500305175781\n",
      "output_layer_dense_64_64_64_loss  :  37.93951416015625 , TEST :  38.811222076416016\n",
      "output_layer_dense_64_64_128_loss  :  31.939241409301758 , TEST :  27.71219825744629\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d9f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  327.50689697265625 , TEST :  299.78814697265625\n",
      "output_layer_dense_64_64_1024_loss  :  31.8554630279541 , TEST :  25.88766098022461\n",
      "output_layer_dense_64_128_32_loss  :  31.906051635742188 , TEST :  25.64059066772461\n",
      "output_layer_dense_64_128_64_loss  :  33.201045989990234 , TEST :  34.193389892578125\n",
      "output_layer_dense_64_128_128_loss  :  32.75349426269531 , TEST :  31.522672653198242\n",
      "output_layer_dense_64_128_1024_loss  :  31.98941421508789 , TEST :  28.798473358154297\n",
      "output_layer_dense_64_1024_32_loss  :  33.3077278137207 , TEST :  35.31038284301758\n",
      "output_layer_dense_64_1024_64_loss  :  31.882036209106445 , TEST :  26.396068572998047\n",
      "output_layer_dense_64_1024_128_loss  :  32.024383544921875 , TEST :  28.8597354888916\n",
      "output_layer_dense_64_1024_1024_loss  :  31.849613189697266 , TEST :  27.19002914428711\n",
      "output_layer_dense_128_32_32_loss  :  36.737648010253906 , TEST :  35.98911666870117\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09813ad0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  342.26483154296875 , TEST :  328.2178039550781\n",
      "output_layer_dense_128_64_32_loss  :  48.028038024902344 , TEST :  58.27384567260742\n",
      "output_layer_dense_128_64_64_loss  :  35.14159393310547 , TEST :  31.83365821838379\n",
      "output_layer_dense_128_128_32_loss  :  33.40260696411133 , TEST :  35.939876556396484\n",
      "output_layer_dense_128_128_64_loss  :  33.0523796081543 , TEST :  33.2486572265625\n",
      "output_layer_dense_128_128_128_loss  :  32.45167922973633 , TEST :  30.385448455810547\n",
      "output_layer_dense_128_128_1024_loss  :  32.060020446777344 , TEST :  29.12714195251465\n",
      "output_layer_dense_128_1024_32_loss  :  32.3466796875 , TEST :  25.076053619384766\n",
      "output_layer_dense_128_1024_64_loss  :  31.98933982849121 , TEST :  28.839698791503906\n",
      "output_layer_dense_128_1024_128_loss  :  31.976551055908203 , TEST :  28.71439552307129\n",
      "output_layer_dense_128_1024_1024_loss  :  31.815929412841797 , TEST :  26.779003143310547\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  333.677490234375 , TEST :  306.97418212890625\n",
      "output_layer_dense_1024_32_32_loss  :  44.59679412841797 , TEST :  52.55773162841797\n",
      "output_layer_dense_1024_64_32_loss  :  33.508392333984375 , TEST :  36.54766082763672\n",
      "output_layer_dense_1024_64_64_loss  :  31.81412124633789 , TEST :  26.398746490478516\n",
      "output_layer_dense_1024_128_32_loss  :  32.89533233642578 , TEST :  32.505619049072266\n",
      "output_layer_dense_1024_128_64_loss  :  31.82064437866211 , TEST :  26.59869384765625\n",
      "output_layer_dense_1024_128_128_loss  :  31.81867027282715 , TEST :  26.49064064025879\n",
      "output_layer_dense_1024_1024_32_loss  :  31.895700454711914 , TEST :  27.852462768554688\n",
      "output_layer_dense_1024_1024_64_loss  :  31.739051818847656 , TEST :  26.053115844726562\n",
      "output_layer_dense_1024_1024_128_loss  :  31.811500549316406 , TEST :  26.66451072692871\n",
      "output_layer_dense_1024_1024_1024_loss  :  31.777271270751953 , TEST :  25.304996490478516\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "[{'model_name': 'dense_128_1024_32', 'score': 25.076053619384766, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_1024_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 128, 'layer2': 1024, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d1a7f0>}, {'model_name': 'dense_32_1024_1024', 'score': 25.188533782958984, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0988425a60>}, {'model_name': 'dense_1024_128', 'score': 25.20755386352539, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_128', 'model_conf': ['', 1, 2, 'relu', {'layer1': 1024, 'layer2': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d68220>}, {'model_name': 'dense_1024_1024_1024', 'score': 25.304996490478516, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f09807cc700>}, {'model_name': 'dense_64_128_32', 'score': 25.64059066772461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f098195ac70>}, {'model_name': 'dense_32_32_128', 'score': 25.683181762695312, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0980615580>}, {'model_name': 'dense_64_64_1024', 'score': 25.88766098022461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983a2b160>}, {'model_name': 'dense_1024_1024_64', 'score': 26.053115844726562, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983c1efa0>}, {'model_name': 'dense_32_1024_64', 'score': 26.121145248413086, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad7550>}, {'model_name': 'dense_32_1024_128', 'score': 26.318124771118164, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad70a0>}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_128_1024_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_128_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_32_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_64_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_128/assets\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Time Taken :  20.406763076782227\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 1, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = True)\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : dense_128_1024_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.345319747924805, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.02512, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981bbd700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.84622573852539, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00158, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0983e43d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.873470306396484 , TEST :  24.018808364868164\n",
      "Model Name : dense_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.384897232055664, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098847c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  32.86589050292969 , TEST :  32.15849685668945\n",
      "Model Name : dense_1024_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.181747436523438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098167b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.778873443603516 , TEST :  28.295467376708984\n",
      "Model Name : dense_64_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.6921329498291, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00398, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09838ab790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.848989486694336 , TEST :  24.678855895996094\n",
      "Model Name : dense_32_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.34592628479004, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fd4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.671247482299805 , TEST :  28.42959213256836\n",
      "Model Name : dense_64_64_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.222423553466797, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882c7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.99043846130371 , TEST :  26.99068832397461\n",
      "Model Name : dense_1024_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 27.45450210571289, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01585, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d19a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.205533981323242, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981f60b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.2604923248291 , TEST :  26.66190528869629\n",
      "Model Name : dense_32_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.960067749023438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.002, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09884280d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.737110137939453 , TEST :  25.75638198852539\n"
     ]
    }
   ],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list)\n",
    "opt.optimize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-GljDEx7Q8i"
   },
   "outputs": [],
   "source": [
    "search = StructuredDataRegressor(max_trials=15, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CF1WqFSj7TAN",
    "outputId": "022c0fdf-8cfd-45ed-ddce-e183911b0e99"
   },
   "outputs": [],
   "source": [
    "search.fit(x=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pJvdP_eb7vYp",
    "outputId": "15a9315a-a61d-4a11-ba0e-467eaafd7415"
   },
   "outputs": [],
   "source": [
    "train_mae, _ = search.evaluate(X_train, y_train, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(train_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ESltODdC8AO0",
    "outputId": "30d0352d-1ed0-40ca-bbe0-cfe17fe836cb"
   },
   "outputs": [],
   "source": [
    "test_mae, _ = search.evaluate(X_test, y_test, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vi_KQC2K8pzs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autokeras-regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
