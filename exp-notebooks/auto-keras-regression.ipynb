{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SVyZBHaE6zqD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "# from autokeras import StructuredDataRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, '/home/anish/ASC_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 12:23:36.306801: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from ASC_ML.networkbuilding import multiple_model_gen_v3 as multiple\n",
    "from ASC_ML.networkbuilding import dataframe_extractor as de\n",
    "from ASC_ML.networkbuilding import model_generation as model_gen\n",
    "from ASC_ML.networkbuilding import model_optimization as model_opt\n",
    "from ASC_ML.networkbuilding import model_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Bi5A13BZ6_17"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/anish/Downloads/autokeras-regression-master/Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "n9heEDsL7VRF",
    "outputId": "08d5989f-cd83-4bf3-bcb0-8622664384fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "xj63U7al-28H",
    "outputId": "74713606-0aba-4d27-9639-091b601b7e27"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"TV\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "6JNLdc67Jsz8",
    "outputId": "52abc809-f857-4243-d3a8-b3468b72843d"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"radio\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "HhyWxbnSJ0pX",
    "outputId": "f680d6b6-b482-471a-e09f-ed5cbee67653"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"newspaper\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y_T3s3Yj7jRk"
   },
   "outputs": [],
   "source": [
    "target_col = \"sales\"\n",
    "X = df.loc[:, df.columns != target_col]\n",
    "y = df.loc[:, target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DAJC0VIH7ptP"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((y_train.shape[0],1))\n",
    "y_test = y_test.reshape((y_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 12:23:40.193838: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-24 12:23:40.194488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-24 12:23:40.297150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-24 12:23:40.297521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-24 12:23:40.297586: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-24 12:23:40.301172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-24 12:23:40.301271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-24 12:23:40.303643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-24 12:23:40.304088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-24 12:23:40.306769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-24 12:23:40.308064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-24 12:23:40.312553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-24 12:23:40.312710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-24 12:23:40.312964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-24 12:23:40.313095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-24 12:23:40.313423: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-24 12:23:40.313698: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-24 12:23:40.313815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-24 12:23:40.313968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-24 12:23:40.314005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-24 12:23:40.314031: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-24 12:23:40.314054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-24 12:23:40.314076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-24 12:23:40.314098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-24 12:23:40.314121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-24 12:23:40.314145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-24 12:23:40.314168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-24 12:23:40.314239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-24 12:23:40.314428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-24 12:23:40.314553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-24 12:23:40.314601: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-24 12:23:40.702259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-24 12:23:40.702284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-08-24 12:23:40.702289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-08-24 12:23:40.702441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-24 12:23:40.702591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-24 12:23:40.702708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-24 12:23:40.702799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4994 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-08-24 12:23:40.972375: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-08-24 12:23:40.972757: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n",
      "2022-08-24 12:23:42.213150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  10.778642654418945 , TEST :  11.98387336730957\n",
      "output_layer_dense_32_32_loss  :  1.1265661716461182 , TEST :  1.2632334232330322\n",
      "output_layer_dense_32_64_loss  :  1.4161955118179321 , TEST :  1.6519906520843506\n",
      "output_layer_dense_32_128_loss  :  1.0632340908050537 , TEST :  1.2069647312164307\n",
      "output_layer_dense_64_32_loss  :  1.118895173072815 , TEST :  1.1915706396102905\n",
      "output_layer_dense_64_64_loss  :  1.0536153316497803 , TEST :  1.1337779760360718\n",
      "output_layer_dense_64_128_loss  :  1.3214002847671509 , TEST :  1.592393159866333\n",
      "output_layer_dense_128_32_loss  :  1.1111313104629517 , TEST :  1.2431926727294922\n",
      "output_layer_dense_128_64_loss  :  1.035083532333374 , TEST :  1.1527841091156006\n",
      "output_layer_dense_128_128_loss  :  1.5325196981430054 , TEST :  1.5479661226272583\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  10.523179054260254 , TEST :  11.970897674560547\n",
      "output_layer_dense_32_32_32_loss  :  1.0524529218673706 , TEST :  1.2248430252075195\n",
      "output_layer_dense_32_32_64_loss  :  0.9784668684005737 , TEST :  1.1552687883377075\n",
      "output_layer_dense_32_32_128_loss  :  1.0240424871444702 , TEST :  1.1034151315689087\n",
      "output_layer_dense_32_64_32_loss  :  1.2526006698608398 , TEST :  1.3180203437805176\n",
      "output_layer_dense_32_64_64_loss  :  1.0106167793273926 , TEST :  1.157041311264038\n",
      "output_layer_dense_32_64_128_loss  :  1.0576856136322021 , TEST :  1.2373394966125488\n",
      "output_layer_dense_32_128_32_loss  :  1.0058847665786743 , TEST :  1.210414171218872\n",
      "output_layer_dense_32_128_64_loss  :  1.0121499300003052 , TEST :  1.1299331188201904\n",
      "output_layer_dense_32_128_128_loss  :  1.0513756275177002 , TEST :  1.3155840635299683\n",
      "output_layer_dense_64_32_32_loss  :  1.0779035091400146 , TEST :  1.1190379858016968\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f62a03fe700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  10.3163480758667 , TEST :  11.727151870727539\n",
      "output_layer_dense_64_64_32_loss  :  1.0241920948028564 , TEST :  1.1777000427246094\n",
      "output_layer_dense_64_64_64_loss  :  1.0312353372573853 , TEST :  1.1778234243392944\n",
      "output_layer_dense_64_64_128_loss  :  0.9447104334831238 , TEST :  1.005737543106079\n",
      "output_layer_dense_64_128_32_loss  :  1.0344120264053345 , TEST :  1.1653631925582886\n",
      "output_layer_dense_64_128_64_loss  :  1.0029746294021606 , TEST :  1.280437707901001\n",
      "output_layer_dense_64_128_128_loss  :  1.0086863040924072 , TEST :  1.197505235671997\n",
      "output_layer_dense_128_32_32_loss  :  0.9987965822219849 , TEST :  1.1045689582824707\n",
      "output_layer_dense_128_64_32_loss  :  1.0325758457183838 , TEST :  1.1900434494018555\n",
      "output_layer_dense_128_64_64_loss  :  0.9782142639160156 , TEST :  1.0888279676437378\n",
      "output_layer_dense_128_128_32_loss  :  1.2605512142181396 , TEST :  1.3391443490982056\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f631ff0c940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  3.045854091644287 , TEST :  3.6969521045684814\n",
      "output_layer_dense_128_128_64_loss  :  1.434401512145996 , TEST :  1.7117029428482056\n",
      "output_layer_dense_128_128_128_loss  :  1.6114528179168701 , TEST :  1.9852491617202759\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "[{'model_name': 'dense_64_64_128', 'score': 1.005737543106079, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f62a0521c70>}, {'model_name': 'dense_128_64_64', 'score': 1.0888279676437378, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_64_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 64, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f62a06f4700>}, {'model_name': 'dense_32_32_128', 'score': 1.1034151315689087, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f62a058e520>}, {'model_name': 'dense_128_32_32', 'score': 1.1045689582824707, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_32_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 32, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f62a06f4df0>}, {'model_name': 'dense_64_32_32', 'score': 1.1190379858016968, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_32_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 32, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f62a058db80>}, {'model_name': 'dense_32_128_64', 'score': 1.1299331188201904, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_128_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 128, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f62a067ee50>}, {'model_name': 'dense_64_64', 'score': 1.1337779760360718, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64', 'model_conf': ['', 3, 2, 'relu', {'layer1': 64, 'layer2': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f62b86b8610>}, {'model_name': 'dense_128_64', 'score': 1.1527841091156006, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_64', 'model_conf': ['', 3, 2, 'relu', {'layer1': 128, 'layer2': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f631f6120a0>}, {'model_name': 'dense_32_32_64', 'score': 1.1552687883377075, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f62a058f850>}, {'model_name': 'dense_32_64_64', 'score': 1.157041311264038, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_64_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 64, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f62a058ea30>}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Time Taken :  11.286076784133911\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 3, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = False)\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list, save_dir = \"/home/anish/ASC_ML_test_weights/candidate_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_64_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.6418301463127136, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f627c4194c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.19062253832817078 , TEST :  0.3664901554584503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-24 12:24:05.525876: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_64_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.6777932643890381, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f62a03fe4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.22902187705039978 , TEST :  0.34208768606185913\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_64_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5000563859939575, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.002, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f627c39b9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.6047565340995789 , TEST :  0.7348828315734863\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_32_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_32_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.6433295011520386, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f631c269b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.25014084577560425 , TEST :  0.422230064868927\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_32_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_32_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5919227600097656, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f62b82055e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3163336217403412 , TEST :  0.5012418627738953\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_32_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_128_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5371891260147095, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f62b85a9550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.2978348731994629 , TEST :  0.42810720205307007\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_128_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.6469870805740356, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f627c254ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.5571690797805786 , TEST :  0.5825513005256653\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5602091550827026, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f62a03fe310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.32643407583236694 , TEST :  0.43122047185897827\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_32_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.6151617765426636, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f631c076700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.2157072126865387 , TEST :  0.37423253059387207\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_32_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_64_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5714032053947449, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f631c0763a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.22795161604881287 , TEST :  0.45421162247657776\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_64_64/assets\n"
     ]
    }
   ],
   "source": [
    "opt.optimize_models(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 128}, [1, None]], ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 64, 'layer3': 64}, [1, None]], ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]], ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 32, 'layer3': 32}, [1, None]], ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 32, 'layer3': 32}, [1, None]], ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 128, 'layer3': 64}, [1, None]], ['', 3, 2, 'relu', {'layer1': 64, 'layer2': 64}, [1, None]], ['', 3, 2, 'relu', {'layer1': 128, 'layer2': 64}, [1, None]], ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 64}, [1, None]], ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 64, 'layer3': 64}, [1, None]]]\n"
     ]
    }
   ],
   "source": [
    "print(opt.model_confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class Dropout_Optimization():\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, epochs, model):\n",
    "        self._train_x = train_x\n",
    "        self._train_y = train_y\n",
    "        self._test_x = test_x\n",
    "        self._test_y = test_y\n",
    "        self._epochs = epochs\n",
    "        self._model = model\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        # Logic to get loss funtion\n",
    "        # return \"mean_absolute_percentage_error\"\n",
    "        # return self.root_mean_squared_error\n",
    "        # return \"mean_squared_error\"\n",
    "        return \"mean_absolute_error\"\n",
    "\n",
    "    def dropout_optimization(self, lr = 1e-3, batch_size = 64, epoch = 100):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        dropout_indices = self._get_dropout_index()\n",
    "        dropout_list = [0,0.2,0.5]\n",
    "        dropout_losses = []\n",
    "        for dropout0 in dropout_list:\n",
    "            for dropout1 in dropout_list:\n",
    "                self._model.layers[dropout_indices[0]].rate = dropout0\n",
    "                self._model.layers[dropout_indices[1]].rate = dropout1\n",
    "                optimizer = Adam(lr = lr)\n",
    "                self._model.compile(loss = loss_fn, optimizer = optimizer)\n",
    "                history = self._model.fit(self._train_x, self._train_y, epochs = epoch, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "                scores = self._model.evaluate(self._train_x, self._train_x, verbose = 0)\n",
    "                scores_test = self._model.evaluate(self._test_x, self._test_y, verbose = 0)\n",
    "                print(f\"For Dropouts D0 = {dropout0}, D1 = {dropout1}, TRAIN_LOSS = {scores}, TEST_LOSS = {scores_test}\")\n",
    "\n",
    "    def _get_dropout_index(self):\n",
    "        dropout_indices = []\n",
    "        ind = 0\n",
    "        for layer in self._model.layers:\n",
    "            if layer.__class__.__name__ == \"Dropout\":\n",
    "                dropout_indices.append(ind)\n",
    "            ind = ind+1\n",
    "        return dropout_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "\n",
    "from ASC_ML.networkbuilding import model_generation as model_gen\n",
    "from ASC_ML.networkbuilding import hyperparameter_optimization as hyp_opt\n",
    "\n",
    "class Model_Stacking2:\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, model_path_list, model_conf_list):\n",
    "        self._model_path_list = model_path_list\n",
    "        self._model_conf_list = model_conf_list\n",
    "        self._train_x = train_x\n",
    "        self._train_y = train_y\n",
    "        self._test_x = test_x\n",
    "        self._test_y = test_y\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        # Logic to get loss funtion\n",
    "        # return \"mean_absolute_percentage_error\"\n",
    "        # return self.root_mean_squared_error\n",
    "        # return \"mean_squared_error\"\n",
    "        return \"mean_absolute_error\"\n",
    "\n",
    "    def _stacked_model_generator(self):\n",
    "        for path in self._model_path_list:\n",
    "            for model_conf in self._model_conf_list:\n",
    "                model1 = load_model(path)\n",
    "                activation = model1.layers[-2].get_config()[\"activation\"]\n",
    "                reduced_model1 = Model(name = model1.name+\"_reduced\", inputs = model1.input, outputs = model1.layers[-2].output)\n",
    "                last_layer = reduced_model1.output\n",
    "                x = last_layer\n",
    "                model2_obj = model_gen.NN_ModelGeneration(*model_conf)\n",
    "                x = Dropout(0.0)(x)\n",
    "                for layer_name in model2_obj.layer_conf:\n",
    "                    x = Dense(model2_obj.layer_conf[layer_name], activation = activation, name = layer_name+\"_2nd\")(x)\n",
    "                x = Dropout(0.0)(x)\n",
    "                output_layer = Dense(model2_obj.output_layer_conf[0], activation = model2_obj.output_layer_conf[1], name = \"output_layer\" + \"_\" + model2_obj.model_name)(x)\n",
    "\n",
    "                stacked_model = Model(name = model1.name + \"_st_\" + model2_obj.model_name,inputs = reduced_model1.input, outputs = output_layer)\n",
    "                x = None\n",
    "                output_layer = None\n",
    "                yield stacked_model\n",
    "\n",
    "    def optimize_stacked_models(self):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        stacked_model_generator = self._stacked_model_generator()\n",
    "        for model in stacked_model_generator:\n",
    "#             print(model.summary())\n",
    "            print(model.name)\n",
    "            h = hyp_opt.Hyperparameter_Optimization([self._train_x], [self._train_y], model, loss_fn, activation_opt = False, initializer_opt = False)\n",
    "            best_lr, best_batch_size, _, _ = h.get_best_hyperparameters()\n",
    "            print(best_lr)\n",
    "#             print(f\"BEST LR STACKED {best_lr}, BEST BATCH SIZE {best_batch_size}\")\n",
    "            dr = Dropout_Optimization(self._train_x, self._train_y, self._test_x, self._test_y, epochs = 100, model = model)\n",
    "            dr.dropout_optimization(lr = best_lr, batch_size = best_batch_size, epoch = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_models = model_stacking.Model_Stacking(opt.saved_paths, opt.model_confs)\n",
    "stacked_models = Model_Stacking2(X_train, y_train, X_test, y_test, opt.saved_paths, opt.model_confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_64_64_128_st_dense_64_64_128\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.45273637771606445, BEST_ACTIVATION : None, BEST_INITIALIZER : None, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "0.0004\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f62643ef3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0, D1 = 0, TRAIN_LOSS = 56.5985221862793, TEST_LOSS = 4.755899906158447\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f62b84dddc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0, D1 = 0.2, TRAIN_LOSS = 56.03972625732422, TEST_LOSS = 4.876981258392334\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f627c6ecb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0, D1 = 0.5, TRAIN_LOSS = 56.851356506347656, TEST_LOSS = 4.755295753479004\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6264497790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0.2, D1 = 0, TRAIN_LOSS = 56.57208251953125, TEST_LOSS = 4.760276794433594\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f610dd0ec10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0.2, D1 = 0.2, TRAIN_LOSS = 55.9648323059082, TEST_LOSS = 4.896320819854736\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f611c0c9d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0.2, D1 = 0.5, TRAIN_LOSS = 56.707672119140625, TEST_LOSS = 4.744999885559082\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f6265520820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0.5, D1 = 0, TRAIN_LOSS = 56.574363708496094, TEST_LOSS = 4.759897708892822\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f60e0468160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0.5, D1 = 0.2, TRAIN_LOSS = 56.22029495239258, TEST_LOSS = 4.831273078918457\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f62643ba550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0.5, D1 = 0.5, TRAIN_LOSS = 55.6210823059082, TEST_LOSS = 4.987414360046387\n",
      "dense_64_64_128_st_dense_128_64_64\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.3871013820171356, BEST_ACTIVATION : None, BEST_INITIALIZER : None, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "0.00063\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f610dea5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Dropouts D0 = 0, D1 = 0, TRAIN_LOSS = 56.592735290527344, TEST_LOSS = 4.756857872009277\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f610da91550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "For Dropouts D0 = 0, D1 = 0.2, TRAIN_LOSS = 56.07628631591797, TEST_LOSS = 4.867613315582275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstacked_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_stacked_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36mModel_Stacking2.optimize_stacked_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#             print(f\"BEST LR STACKED {best_lr}, BEST BATCH SIZE {best_batch_size}\")\u001b[39;00m\n\u001b[1;32m     53\u001b[0m             dr \u001b[38;5;241m=\u001b[39m Dropout_Optimization(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_y, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, model \u001b[38;5;241m=\u001b[39m model)\n\u001b[0;32m---> 54\u001b[0m             \u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36mDropout_Optimization.dropout_optimization\u001b[0;34m(self, lr, batch_size, epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m loss_fn, optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[0;32m---> 30\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_x, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     33\u001b[0m scores_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_y, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:855\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    852\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    853\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    858\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2942\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[1;32m   2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1918\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1914\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1917\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_call_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m     args,\n\u001b[1;32m   1922\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1923\u001b[0m     executing_eagerly)\n\u001b[1;32m   1924\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2174\u001b[0m, in \u001b[0;36mConcreteFunction._build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   2172\u001b[0m     outputs_list[i] \u001b[38;5;241m=\u001b[39m result[j]\n\u001b[1;32m   2173\u001b[0m     j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2174\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moutputs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/util/nest.py:579\u001b[0m, in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.pack_sequence_as\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpack_sequence_as\u001b[39m(structure, flat_sequence, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    547\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a given flattened sequence packed into a given structure.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  If `structure` is a scalar, `flat_sequence` must be a single-element list;\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m    TypeError: `structure` is or contains a dict with non-sortable keys.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/util/nest.py:514\u001b[0m, in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    511\u001b[0m   value_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(value)\n\u001b[1;32m    512\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value_str[:length] \u001b[38;5;241m+\u001b[39m (value_str[length:] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    515\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    516\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to pack value:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124minto a sequence, but found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    517\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible type `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    518\u001b[0m       \u001b[38;5;241m.\u001b[39mformat(truncate(flat_sequence, \u001b[38;5;241m100\u001b[39m), \u001b[38;5;28mtype\u001b[39m(flat_sequence)))\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_seq(structure):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stacked_models.optimize_stacked_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"/home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_64/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selu\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "activation = model.layers[-2].get_config()[\"activation\"]\n",
    "print(activation)\n",
    "print(type(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64_reduced\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 8,576\n",
      "Trainable params: 8,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reduce_model = Model(name = model.name+\"_reduced\", inputs = model.input, outputs = model.layers[-2].output)\n",
    "print(reduce_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Flatten, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = Sequential()\n",
    "# new_model.add(Dropout(0.1))\n",
    "# new_model.add(reduce_model)\n",
    "# new_model.add(Dropout(0.2))\n",
    "# new_model.add(Dense(1024, activation = activation))\n",
    "# new_model.add(Dense(1024, activation = activation))\n",
    "# new_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = reduce_model.output\n",
    "x = last_layer\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1024, activation = activation)(x)\n",
    "x = Dense(1024, activation = activation)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1)(x)\n",
    "new_model = Model(inputs = reduce_model.input, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_326 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_327 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,125,761\n",
      "Trainable params: 1,125,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7]\n"
     ]
    }
   ],
   "source": [
    "dropout_ind = []\n",
    "ind = 0\n",
    "for layer in new_model.layers:\n",
    "    if layer.__class__.__name__ == \"Dropout\":\n",
    "        dropout_ind.append(ind)\n",
    "    ind = ind+1\n",
    "print(dropout_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.layers[4].rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.layers[4].rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 2)\n",
      "(63, 1) (63,)\n",
      "(42, 1) (21, 1) (42,) (21,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load the sonar dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "print(dataframe.shape)\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "data = data.astype('float32')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  564.4772338867188 , TEST :  696.4302978515625\n",
      "output_layer_dense_32_32_loss  :  77.97647094726562 , TEST :  102.96764373779297\n",
      "output_layer_dense_32_64_loss  :  72.4428939819336 , TEST :  94.78680419921875\n",
      "output_layer_dense_32_128_loss  :  43.49039840698242 , TEST :  50.427490234375\n",
      "output_layer_dense_32_1024_loss  :  32.640380859375 , TEST :  31.093881607055664\n",
      "output_layer_dense_64_32_loss  :  68.5215072631836 , TEST :  88.98941802978516\n",
      "output_layer_dense_64_64_loss  :  67.38311004638672 , TEST :  87.2926254272461\n",
      "output_layer_dense_64_128_loss  :  41.06880569458008 , TEST :  45.563011169433594\n",
      "output_layer_dense_64_1024_loss  :  32.03666687011719 , TEST :  28.78836441040039\n",
      "output_layer_dense_128_32_loss  :  72.19493103027344 , TEST :  94.40507507324219\n",
      "output_layer_dense_128_64_loss  :  56.72202682495117 , TEST :  72.11593627929688\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  204.6041717529297 , TEST :  193.50648498535156\n",
      "output_layer_dense_128_128_loss  :  43.74370574951172 , TEST :  50.91599655151367\n",
      "output_layer_dense_128_1024_loss  :  31.940673828125 , TEST :  27.309024810791016\n",
      "output_layer_dense_1024_32_loss  :  31.918380737304688 , TEST :  27.996408462524414\n",
      "output_layer_dense_1024_64_loss  :  33.159645080566406 , TEST :  34.39208984375\n",
      "output_layer_dense_1024_128_loss  :  31.97357177734375 , TEST :  25.20755386352539\n",
      "output_layer_dense_1024_1024_loss  :  31.868175506591797 , TEST :  27.685407638549805\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  396.1885681152344 , TEST :  412.23150634765625\n",
      "output_layer_dense_32_32_32_loss  :  67.75357818603516 , TEST :  87.86875915527344\n",
      "output_layer_dense_32_32_64_loss  :  55.70736312866211 , TEST :  70.67930603027344\n",
      "output_layer_dense_32_32_128_loss  :  33.16255569458008 , TEST :  25.683181762695312\n",
      "output_layer_dense_32_32_1024_loss  :  32.28651809692383 , TEST :  29.9041805267334\n",
      "output_layer_dense_32_64_32_loss  :  35.29856872558594 , TEST :  32.24654006958008\n",
      "output_layer_dense_32_64_64_loss  :  43.165130615234375 , TEST :  49.84916305541992\n",
      "output_layer_dense_32_64_128_loss  :  32.039371490478516 , TEST :  28.813858032226562\n",
      "output_layer_dense_32_64_1024_loss  :  31.844669342041016 , TEST :  27.289440155029297\n",
      "output_layer_dense_32_128_32_loss  :  31.92618179321289 , TEST :  27.147016525268555\n",
      "output_layer_dense_32_128_64_loss  :  33.00459671020508 , TEST :  32.75004959106445\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0a203ec700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  400.072998046875 , TEST :  415.59356689453125\n",
      "output_layer_dense_32_128_128_loss  :  33.348819732666016 , TEST :  35.67073440551758\n",
      "output_layer_dense_32_128_1024_loss  :  31.862337112426758 , TEST :  26.892961502075195\n",
      "output_layer_dense_32_1024_32_loss  :  32.63373565673828 , TEST :  31.09195327758789\n",
      "output_layer_dense_32_1024_64_loss  :  31.856761932373047 , TEST :  26.121145248413086\n",
      "output_layer_dense_32_1024_128_loss  :  31.77286148071289 , TEST :  26.318124771118164\n",
      "output_layer_dense_32_1024_1024_loss  :  31.885509490966797 , TEST :  25.188533782958984\n",
      "output_layer_dense_64_32_32_loss  :  63.9492301940918 , TEST :  82.36168670654297\n",
      "output_layer_dense_64_64_32_loss  :  72.885009765625 , TEST :  95.42500305175781\n",
      "output_layer_dense_64_64_64_loss  :  37.93951416015625 , TEST :  38.811222076416016\n",
      "output_layer_dense_64_64_128_loss  :  31.939241409301758 , TEST :  27.71219825744629\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d9f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  327.50689697265625 , TEST :  299.78814697265625\n",
      "output_layer_dense_64_64_1024_loss  :  31.8554630279541 , TEST :  25.88766098022461\n",
      "output_layer_dense_64_128_32_loss  :  31.906051635742188 , TEST :  25.64059066772461\n",
      "output_layer_dense_64_128_64_loss  :  33.201045989990234 , TEST :  34.193389892578125\n",
      "output_layer_dense_64_128_128_loss  :  32.75349426269531 , TEST :  31.522672653198242\n",
      "output_layer_dense_64_128_1024_loss  :  31.98941421508789 , TEST :  28.798473358154297\n",
      "output_layer_dense_64_1024_32_loss  :  33.3077278137207 , TEST :  35.31038284301758\n",
      "output_layer_dense_64_1024_64_loss  :  31.882036209106445 , TEST :  26.396068572998047\n",
      "output_layer_dense_64_1024_128_loss  :  32.024383544921875 , TEST :  28.8597354888916\n",
      "output_layer_dense_64_1024_1024_loss  :  31.849613189697266 , TEST :  27.19002914428711\n",
      "output_layer_dense_128_32_32_loss  :  36.737648010253906 , TEST :  35.98911666870117\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09813ad0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  342.26483154296875 , TEST :  328.2178039550781\n",
      "output_layer_dense_128_64_32_loss  :  48.028038024902344 , TEST :  58.27384567260742\n",
      "output_layer_dense_128_64_64_loss  :  35.14159393310547 , TEST :  31.83365821838379\n",
      "output_layer_dense_128_128_32_loss  :  33.40260696411133 , TEST :  35.939876556396484\n",
      "output_layer_dense_128_128_64_loss  :  33.0523796081543 , TEST :  33.2486572265625\n",
      "output_layer_dense_128_128_128_loss  :  32.45167922973633 , TEST :  30.385448455810547\n",
      "output_layer_dense_128_128_1024_loss  :  32.060020446777344 , TEST :  29.12714195251465\n",
      "output_layer_dense_128_1024_32_loss  :  32.3466796875 , TEST :  25.076053619384766\n",
      "output_layer_dense_128_1024_64_loss  :  31.98933982849121 , TEST :  28.839698791503906\n",
      "output_layer_dense_128_1024_128_loss  :  31.976551055908203 , TEST :  28.71439552307129\n",
      "output_layer_dense_128_1024_1024_loss  :  31.815929412841797 , TEST :  26.779003143310547\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  333.677490234375 , TEST :  306.97418212890625\n",
      "output_layer_dense_1024_32_32_loss  :  44.59679412841797 , TEST :  52.55773162841797\n",
      "output_layer_dense_1024_64_32_loss  :  33.508392333984375 , TEST :  36.54766082763672\n",
      "output_layer_dense_1024_64_64_loss  :  31.81412124633789 , TEST :  26.398746490478516\n",
      "output_layer_dense_1024_128_32_loss  :  32.89533233642578 , TEST :  32.505619049072266\n",
      "output_layer_dense_1024_128_64_loss  :  31.82064437866211 , TEST :  26.59869384765625\n",
      "output_layer_dense_1024_128_128_loss  :  31.81867027282715 , TEST :  26.49064064025879\n",
      "output_layer_dense_1024_1024_32_loss  :  31.895700454711914 , TEST :  27.852462768554688\n",
      "output_layer_dense_1024_1024_64_loss  :  31.739051818847656 , TEST :  26.053115844726562\n",
      "output_layer_dense_1024_1024_128_loss  :  31.811500549316406 , TEST :  26.66451072692871\n",
      "output_layer_dense_1024_1024_1024_loss  :  31.777271270751953 , TEST :  25.304996490478516\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "[{'model_name': 'dense_128_1024_32', 'score': 25.076053619384766, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_1024_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 128, 'layer2': 1024, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d1a7f0>}, {'model_name': 'dense_32_1024_1024', 'score': 25.188533782958984, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0988425a60>}, {'model_name': 'dense_1024_128', 'score': 25.20755386352539, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_128', 'model_conf': ['', 1, 2, 'relu', {'layer1': 1024, 'layer2': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d68220>}, {'model_name': 'dense_1024_1024_1024', 'score': 25.304996490478516, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f09807cc700>}, {'model_name': 'dense_64_128_32', 'score': 25.64059066772461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f098195ac70>}, {'model_name': 'dense_32_32_128', 'score': 25.683181762695312, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0980615580>}, {'model_name': 'dense_64_64_1024', 'score': 25.88766098022461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983a2b160>}, {'model_name': 'dense_1024_1024_64', 'score': 26.053115844726562, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983c1efa0>}, {'model_name': 'dense_32_1024_64', 'score': 26.121145248413086, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad7550>}, {'model_name': 'dense_32_1024_128', 'score': 26.318124771118164, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad70a0>}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_128_1024_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_128_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_32_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_64_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_128/assets\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Time Taken :  20.406763076782227\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 1, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = True)\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : dense_128_1024_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.345319747924805, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.02512, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981bbd700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.84622573852539, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00158, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0983e43d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.873470306396484 , TEST :  24.018808364868164\n",
      "Model Name : dense_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.384897232055664, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098847c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  32.86589050292969 , TEST :  32.15849685668945\n",
      "Model Name : dense_1024_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.181747436523438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098167b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.778873443603516 , TEST :  28.295467376708984\n",
      "Model Name : dense_64_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.6921329498291, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00398, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09838ab790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.848989486694336 , TEST :  24.678855895996094\n",
      "Model Name : dense_32_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.34592628479004, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fd4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.671247482299805 , TEST :  28.42959213256836\n",
      "Model Name : dense_64_64_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.222423553466797, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882c7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.99043846130371 , TEST :  26.99068832397461\n",
      "Model Name : dense_1024_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 27.45450210571289, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01585, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d19a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.205533981323242, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981f60b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.2604923248291 , TEST :  26.66190528869629\n",
      "Model Name : dense_32_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.960067749023438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.002, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09884280d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.737110137939453 , TEST :  25.75638198852539\n"
     ]
    }
   ],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list)\n",
    "opt.optimize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-GljDEx7Q8i"
   },
   "outputs": [],
   "source": [
    "search = StructuredDataRegressor(max_trials=15, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CF1WqFSj7TAN",
    "outputId": "022c0fdf-8cfd-45ed-ddce-e183911b0e99"
   },
   "outputs": [],
   "source": [
    "search.fit(x=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pJvdP_eb7vYp",
    "outputId": "15a9315a-a61d-4a11-ba0e-467eaafd7415"
   },
   "outputs": [],
   "source": [
    "train_mae, _ = search.evaluate(X_train, y_train, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(train_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ESltODdC8AO0",
    "outputId": "30d0352d-1ed0-40ca-bbe0-cfe17fe836cb"
   },
   "outputs": [],
   "source": [
    "test_mae, _ = search.evaluate(X_test, y_test, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vi_KQC2K8pzs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autokeras-regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
