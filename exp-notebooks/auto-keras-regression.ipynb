{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SVyZBHaE6zqD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 20:13:43.985215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "# from autokeras import StructuredDataRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from IPython.display import HTML\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, '/home/anish/ASC_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASC_ML.networkbuilding import multiple_model_gen_v3 as multiple\n",
    "from ASC_ML.networkbuilding import dataframe_extractor as de\n",
    "from ASC_ML.networkbuilding import model_generation as model_gen\n",
    "from ASC_ML.networkbuilding import model_optimization as model_opt\n",
    "from ASC_ML.networkbuilding import model_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Bi5A13BZ6_17"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/anish/Downloads/autokeras-regression-master/Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "n9heEDsL7VRF",
    "outputId": "08d5989f-cd83-4bf3-bcb0-8622664384fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "xj63U7al-28H",
    "outputId": "74713606-0aba-4d27-9639-091b601b7e27"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"TV\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "6JNLdc67Jsz8",
    "outputId": "52abc809-f857-4243-d3a8-b3468b72843d"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"radio\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "HhyWxbnSJ0pX",
    "outputId": "f680d6b6-b482-471a-e09f-ed5cbee67653"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"newspaper\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y_T3s3Yj7jRk"
   },
   "outputs": [],
   "source": [
    "target_col = \"sales\"\n",
    "X = df.loc[:, df.columns != target_col]\n",
    "y = df.loc[:, target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DAJC0VIH7ptP"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((y_train.shape[0],1))\n",
    "y_test = y_test.reshape((y_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 20:13:50.754857: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-27 20:13:50.757310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-27 20:13:50.832638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 20:13:50.832966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-27 20:13:50.833023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-27 20:13:50.835392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-27 20:13:50.835462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-27 20:13:50.837433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-27 20:13:50.837819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-27 20:13:50.839699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-27 20:13:50.840558: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-27 20:13:50.844073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-27 20:13:50.844198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 20:13:50.844419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 20:13:50.844544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-27 20:13:50.844836: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-27 20:13:50.845059: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-27 20:13:50.845154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 20:13:50.845293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-27 20:13:50.845323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-27 20:13:50.845347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-27 20:13:50.845369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-27 20:13:50.845390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-27 20:13:50.845412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-27 20:13:50.845433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-27 20:13:50.845456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-27 20:13:50.845478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-27 20:13:50.845543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 20:13:50.845721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 20:13:50.845843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-27 20:13:50.845882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-27 20:13:51.230087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-27 20:13:51.230114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-08-27 20:13:51.230119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-08-27 20:13:51.230267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 20:13:51.230420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 20:13:51.230536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 20:13:51.230628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5013 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-08-27 20:13:51.499720: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-08-27 20:13:51.500098: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n",
      "2022-08-27 20:13:52.727776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  9.773396492004395 , TEST :  10.996709823608398\n",
      "output_layer_dense_32_32_loss  :  1.1544725894927979 , TEST :  1.1870815753936768\n",
      "output_layer_dense_32_64_loss  :  1.074446678161621 , TEST :  1.2056605815887451\n",
      "output_layer_dense_32_128_loss  :  1.0229222774505615 , TEST :  1.1063857078552246\n",
      "output_layer_dense_64_32_loss  :  1.1641592979431152 , TEST :  1.3507206439971924\n",
      "output_layer_dense_64_64_loss  :  1.036392092704773 , TEST :  1.2366340160369873\n",
      "output_layer_dense_64_128_loss  :  1.1911075115203857 , TEST :  1.190260887145996\n",
      "output_layer_dense_128_32_loss  :  1.0380256175994873 , TEST :  1.2527062892913818\n",
      "output_layer_dense_128_64_loss  :  1.0901509523391724 , TEST :  1.2866219282150269\n",
      "output_layer_dense_128_128_loss  :  1.0017197132110596 , TEST :  1.1806387901306152\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  11.478938102722168 , TEST :  12.368840217590332\n",
      "output_layer_dense_32_32_32_loss  :  1.0214974880218506 , TEST :  1.1926298141479492\n",
      "output_layer_dense_32_32_64_loss  :  1.2069674730300903 , TEST :  1.234649419784546\n",
      "output_layer_dense_32_32_128_loss  :  1.0834025144577026 , TEST :  1.133123755455017\n",
      "output_layer_dense_32_64_32_loss  :  1.26435387134552 , TEST :  1.2713267803192139\n",
      "output_layer_dense_32_64_64_loss  :  1.0772124528884888 , TEST :  1.2183828353881836\n",
      "output_layer_dense_32_64_128_loss  :  1.0638200044631958 , TEST :  1.2623271942138672\n",
      "output_layer_dense_32_128_32_loss  :  1.1868475675582886 , TEST :  1.2804447412490845\n",
      "output_layer_dense_32_128_64_loss  :  1.3087352514266968 , TEST :  1.3413994312286377\n",
      "output_layer_dense_32_128_128_loss  :  1.1676430702209473 , TEST :  1.2843730449676514\n",
      "output_layer_dense_64_32_32_loss  :  1.0984594821929932 , TEST :  1.1501833200454712\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2d70490f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  10.539387702941895 , TEST :  11.577917098999023\n",
      "output_layer_dense_64_64_32_loss  :  1.3343745470046997 , TEST :  1.5540945529937744\n",
      "output_layer_dense_64_64_64_loss  :  1.0730918645858765 , TEST :  1.180182695388794\n",
      "output_layer_dense_64_64_128_loss  :  0.9291521906852722 , TEST :  1.0916346311569214\n",
      "output_layer_dense_64_128_32_loss  :  0.9615174531936646 , TEST :  1.0210529565811157\n",
      "output_layer_dense_64_128_64_loss  :  0.9579703211784363 , TEST :  1.049407958984375\n",
      "output_layer_dense_64_128_128_loss  :  1.0956447124481201 , TEST :  1.1589889526367188\n",
      "output_layer_dense_128_32_32_loss  :  1.099487066268921 , TEST :  1.1385738849639893\n",
      "output_layer_dense_128_64_32_loss  :  1.0028350353240967 , TEST :  1.101218819618225\n",
      "output_layer_dense_128_64_64_loss  :  1.0036046504974365 , TEST :  1.1352146863937378\n",
      "output_layer_dense_128_128_32_loss  :  1.0817101001739502 , TEST :  1.1475481986999512\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2dabb93af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  2.6502535343170166 , TEST :  3.0312588214874268\n",
      "output_layer_dense_128_128_64_loss  :  1.3211510181427002 , TEST :  1.3953306674957275\n",
      "output_layer_dense_128_128_128_loss  :  1.3291022777557373 , TEST :  1.6359281539916992\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "[{'model_name': 'dense_64_128_32', 'score': 1.0210529565811157, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2d7042a730>}, {'model_name': 'dense_64_128_64', 'score': 1.049407958984375, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2d7042aa90>}, {'model_name': 'dense_64_64_128', 'score': 1.0916346311569214, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2d705ef400>}, {'model_name': 'dense_128_64_32', 'score': 1.101218819618225, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_64_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 64, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2d7041ce50>}, {'model_name': 'dense_32_128', 'score': 1.1063857078552246, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_128', 'model_conf': ['', 3, 2, 'relu', {'layer1': 32, 'layer2': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2dabe39bb0>}, {'model_name': 'dense_32_32_128', 'score': 1.133123755455017, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2d7048cd60>}, {'model_name': 'dense_128_64_64', 'score': 1.1352146863937378, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_64_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 64, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2d704568b0>}, {'model_name': 'dense_128_32_32', 'score': 1.1385738849639893, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_32_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 32, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2d7041caf0>}, {'model_name': 'dense_128_128_32', 'score': 1.1475481986999512, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_128_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 128, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2d705eeca0>}, {'model_name': 'dense_64_32_32', 'score': 1.1501833200454712, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_32_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 32, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f2d7048f2e0>}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Time Taken :  11.337820291519165\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 3, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = False)\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list, save_dir = \"/home/anish/ASC_ML_test_weights/candidate_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_128_32\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f2e0c036430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2760373055934906, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00251, BEST_BATCHSIZE : 64\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.5418072938919067 , TEST :  0.557325541973114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 20:14:33.939240: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_128_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_128_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.25366735458374023, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0005, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.32220664620399475 , TEST :  0.4030741751194\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_128_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_64_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2514764368534088, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00501, BEST_BATCHSIZE : 64\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.24512842297554016 , TEST :  0.3150291442871094\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_64_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.28035059571266174, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.21510770916938782 , TEST :  0.3864220082759857\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_64_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2590157091617584, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.2622268795967102 , TEST :  0.3949057459831238\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2333206832408905, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00158, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.24063289165496826 , TEST :  0.37297767400741577\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_32_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_64_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.22421221435070038, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0005, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.22974534332752228 , TEST :  0.4427967965602875\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_64_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_32_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.33144259452819824, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.002, BEST_BATCHSIZE : 64\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.2448338270187378 , TEST :  0.37211236357688904\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_32_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.30132946372032166, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00501, BEST_BATCHSIZE : 128\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.5721027255058289 , TEST :  0.703842043876648\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_128_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_32_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.22648437321186066, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.18936368823051453 , TEST :  0.40228986740112305\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_32_32/assets\n"
     ]
    }
   ],
   "source": [
    "opt.optimize_models(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 32}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 64}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 128}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 64, 'layer3': 32}, [1, None]],\n",
       " ['', 3, 2, 'relu', {'layer1': 32, 'layer2': 128}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 64, 'layer3': 64}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 32, 'layer3': 32}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 128, 'layer3': 32}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 32, 'layer3': 32}, [1, None]]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.model_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.00251, 64, 'selu', 'GlorotUniform'],\n",
       " [0.0005, 32, 'selu', 'GlorotNormal'],\n",
       " [0.00501, 64, 'selu', 'GlorotUniform'],\n",
       " [0.001, 32, 'selu', 'GlorotUniform'],\n",
       " [0.001, 16, 'selu', 'GlorotNormal'],\n",
       " [0.00158, 32, 'selu', 'GlorotUniform'],\n",
       " [0.0005, 16, 'selu', 'GlorotNormal'],\n",
       " [0.002, 64, 'selu', 'GlorotUniform'],\n",
       " [0.00501, 128, 'selu', 'GlorotNormal'],\n",
       " [0.001, 32, 'selu', 'GlorotUniform']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_hyp_permodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class Dropout_Optimization():\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, epochs, model):\n",
    "        self._train_x = train_x\n",
    "        self._train_y = train_y\n",
    "        self._test_x = test_x\n",
    "        self._test_y = test_y\n",
    "        self._epochs = epochs\n",
    "        self._model = model\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        # Logic to get loss funtion\n",
    "        # return \"mean_absolute_percentage_error\"\n",
    "        # return self.root_mean_squared_error\n",
    "        # return \"mean_squared_error\"\n",
    "        return \"mean_absolute_error\"\n",
    "\n",
    "    def dropout_optimization(self, lr = 1e-3, batch_size = 64, epoch = 100):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        dropout_indices = self._get_dropout_index()\n",
    "        dropout_list = [0,0.2,0.5]\n",
    "        dropout_comb_list = []\n",
    "        dropout_loss_list = []\n",
    "        for dropout0 in dropout_list:\n",
    "            for dropout1 in dropout_list:\n",
    "                dropout_comb_list.append([dropout0,dropout1])\n",
    "                self._model.layers[dropout_indices[0]].rate = dropout0\n",
    "                self._model.layers[dropout_indices[1]].rate = dropout1\n",
    "                optimizer = Adam(lr = lr)\n",
    "                self._model.compile(loss = loss_fn, optimizer = optimizer)\n",
    "                history = self._model.fit(self._train_x, self._train_y, epochs = epoch, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "                scores = self._model.evaluate(self._train_x, self._train_y, verbose = 0)\n",
    "                scores_test = self._model.evaluate(self._test_x, self._test_y, verbose = 0)\n",
    "#                 print(f\"For Dropouts D0 = {dropout0}, D1 = {dropout1}, TRAIN_LOSS = {scores}, TEST_LOSS = {scores_test}\")\n",
    "                dropout_loss_list.append(scores_test)\n",
    "                \n",
    "        best_dropout_rates = dropout_comb_list[dropout_loss_list.index(min(dropout_loss_list))]\n",
    "        self._model.layers[dropout_indices[0]].rate = best_dropout_rates[0]\n",
    "        self._model.layers[dropout_indices[1]].rate = best_dropout_rates[1]\n",
    "        return best_dropout_rates\n",
    "                \n",
    "\n",
    "    def _get_dropout_index(self):\n",
    "        dropout_indices = []\n",
    "        ind = 0\n",
    "        for layer in self._model.layers:\n",
    "            if layer.__class__.__name__ == \"Dropout\":\n",
    "                dropout_indices.append(ind)\n",
    "            ind = ind+1\n",
    "        return dropout_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.initializers import RandomUniform, GlorotUniform, GlorotNormal, HeUniform, HeNormal\n",
    "\n",
    "from ASC_ML.networkbuilding import model_generation as model_gen\n",
    "from ASC_ML.networkbuilding import hyperparameter_optimization as hyp_opt\n",
    "\n",
    "class Model_Stacking2:\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, model_path_list, model_conf_list, save_dir = \"\"):\n",
    "        self._model_path_list = model_path_list\n",
    "        self._model_conf_list = model_conf_list\n",
    "        self._train_x = train_x\n",
    "        self._train_y = train_y\n",
    "        self._test_x = test_x\n",
    "        self._test_y = test_y\n",
    "        self._save_dir = save_dir\n",
    "        self._stacked_model_paths = []\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        # Logic to get loss funtion\n",
    "        # return \"mean_absolute_percentage_error\"\n",
    "        # return self.root_mean_squared_error\n",
    "        # return \"mean_squared_error\"\n",
    "        return \"mean_absolute_error\"\n",
    "\n",
    "    def _stacked_model_generator(self):\n",
    "        for path in self._model_path_list:\n",
    "            for model_conf in self._model_conf_list:\n",
    "                model1 = load_model(path)\n",
    "                activation = model1.layers[-2].get_config()[\"activation\"]\n",
    "                reduced_model1 = Model(name = model1.name+\"_reduced\", inputs = model1.input, outputs = model1.layers[-2].output)\n",
    "                last_layer = reduced_model1.output\n",
    "                x = last_layer\n",
    "                model2_obj = model_gen.NN_ModelGeneration(*model_conf)\n",
    "                x = Dropout(0.0)(x)\n",
    "                for layer_name in model2_obj.layer_conf:\n",
    "                    x = Dense(model2_obj.layer_conf[layer_name], activation = activation, name = layer_name+\"_2nd\")(x)\n",
    "                x = Dropout(0.0)(x)\n",
    "                output_layer = Dense(model2_obj.output_layer_conf[0], activation = model2_obj.output_layer_conf[1], name = \"output_layer\" + \"_\" + model2_obj.model_name)(x)\n",
    "\n",
    "                stacked_model = Model(name = model1.name + \"_st_\" + model2_obj.model_name,inputs = reduced_model1.input, outputs = output_layer)\n",
    "                x = None\n",
    "                output_layer = None\n",
    "                yield stacked_model\n",
    "\n",
    "    def optimize_stacked_models(self):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        stacked_model_generator = self._stacked_model_generator()\n",
    "        for model in stacked_model_generator:\n",
    "            print(model.name)\n",
    "            print(model.summary())\n",
    "            h = hyp_opt.Hyperparameter_Optimization([self._train_x], [self._train_y], model, loss_fn, activation_opt = True, initializer_opt = True)\n",
    "            best_lr, best_batch_size, _, best_initializer = h.get_best_hyperparameters()\n",
    "            print(best_initializer)\n",
    "            self._reinitialize_model(model, best_initializer)\n",
    "            \n",
    "            dr = Dropout_Optimization(self._train_x, self._train_y, self._test_x, self._test_y, epochs = 100, model = model)\n",
    "            best_dropout_rates = dr.dropout_optimization(lr = best_lr, batch_size = best_batch_size, epoch = 100)\n",
    "            print(f\"DROPOUT RATES : {best_dropout_rates}\")\n",
    "            \n",
    "            model = self._train_models(model = model, lr = best_lr, batch_size = best_batch_size)\n",
    "            self._save_model(model)\n",
    "            \n",
    "#             print(f\"BEST LR STACKED {best_lr}, BEST BATCH SIZE {best_batch_size}\")\n",
    "#             dr = Dropout_Optimization(self._train_x, self._train_y, self._test_x, self._test_y, epochs = 100, model = model)\n",
    "#             dr.dropout_optimization(lr = best_lr, batch_size = best_batch_size, epoch = 100)\n",
    "    \n",
    "    def _train_models(self, model, lr, batch_size):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        optimizer = Adam(lr = lr)\n",
    "        model.compile(loss = loss_fn, optimizer = optimizer)\n",
    "        history = model.fit(self._train_x, self._train_y, epochs = 100, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "        scores = model.evaluate(self._train_x, self._train_y, verbose = 0)\n",
    "        scores_test = model.evaluate(self._test_x, self._test_y, verbose = 0)\n",
    "        print(f\"TRAIN_LOSS = {scores}, TEST_LOSS = {scores_test}\")\n",
    "        return model\n",
    "        \n",
    "    @staticmethod\n",
    "    def _reinitialize_model(model, initializer_str = \"RandomUniform\"):\n",
    "        if initializer_str == \"RandomUniform\":\n",
    "            initializer = RandomUniform(seed = 420)\n",
    "        elif initializer_str == \"GlorotUniform\":\n",
    "            initializer = GlorotUniform(seed = 420)\n",
    "        elif initializer_str == \"HeUniform\":\n",
    "            initializer = HeUniform(seed = 420)\n",
    "        elif initializer_str == \"GlorotNormal\":\n",
    "            initializer = GlorotNormal(seed = 420)\n",
    "        elif initializer_str == \"HeNormal\":\n",
    "            initializer = HeNormal(seed = 420)\n",
    "        for layer in model.layers:\n",
    "            layer.set_weights([initializer(shape=w.shape) for w in layer.get_weights()])\n",
    "            \n",
    "    def _save_model(self, model):\n",
    "        path = os.path.join(self._save_dir,model.name)\n",
    "        model.save(path)\n",
    "        self._stacked_model_paths.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_models = model_stacking.Model_Stacking(opt.saved_paths, opt.model_confs)\n",
    "stacked_models = Model_Stacking2(X_train, y_train, X_test, y_test, opt.saved_paths, opt.model_confs, save_dir = \"/home/anish/ASC_ML_test_weights/stacked_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_64_128_32_st_dense_64_128_32\n",
      "Model: \"dense_64_128_32_st_dense_64_128_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32_2nd ( (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32_2nd ( (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_128_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 27,297\n",
      "Trainable params: 27,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2102661430835724, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00126, BEST_BATCHSIZE : 64\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.18974287807941437, TEST_LOSS = 0.3626607358455658\n",
      "dense_64_128_32_st_dense_64_128_64\n",
      "Model: \"dense_64_128_32_st_dense_64_128_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_64_2nd ( (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_64_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_64_2nd ( (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_128_64 (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 31,457\n",
      "Trainable params: 31,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2152978628873825, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "GlorotNormal\n",
      "DROPOUT RATES : [0, 0.2]\n",
      "TRAIN_LOSS = 0.2746140658855438, TEST_LOSS = 0.395169198513031\n",
      "dense_64_128_32_st_dense_64_64_128\n",
      "Model: \"dense_64_128_32_st_dense_64_64_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_128_2nd ( (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_128_2nd ( (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_128_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_128 (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 27,425\n",
      "Trainable params: 27,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2167428433895111, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 32\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0.2]\n",
      "TRAIN_LOSS = 0.46205559372901917, TEST_LOSS = 0.5042843818664551\n",
      "dense_64_128_32_st_dense_128_64_32\n",
      "Model: \"dense_64_128_32_st_dense_128_64_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_64_32_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_64_32_2nd ( (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_64_32_2nd ( (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_64_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 27,297\n",
      "Trainable params: 27,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.20106205344200134, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.20413604378700256, TEST_LOSS = 0.3925964832305908\n",
      "dense_64_128_32_st_dense_32_128\n",
      "Model: \"dense_64_128_32_st_dense_32_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_128_2nd (Den (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_128_2nd (Den (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_32_128 (D (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 18,113\n",
      "Trainable params: 18,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.19186227023601532, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00032, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.17292746901512146, TEST_LOSS = 0.3159737288951874\n",
      "dense_64_128_32_st_dense_32_32_128\n",
      "Model: \"dense_64_128_32_st_dense_32_32_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_32_128_2nd ( (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_32_128_2nd ( (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_32_128_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_32_32_128 (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 19,169\n",
      "Trainable params: 19,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2549762725830078, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotNormal\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.1746048629283905, TEST_LOSS = 0.3850560188293457\n",
      "dense_64_128_32_st_dense_128_64_64\n",
      "Model: \"dense_64_128_32_st_dense_128_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_64_64_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_64_64_2nd ( (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_64_64_2nd ( (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_64_64 (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 29,409\n",
      "Trainable params: 29,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.26172542572021484, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0.2]\n",
      "TRAIN_LOSS = 0.4665142893791199, TEST_LOSS = 0.6047951579093933\n",
      "dense_64_128_32_st_dense_128_32_32\n",
      "Model: \"dense_64_128_32_st_dense_128_32_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_32_32_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_32_32_2nd ( (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_32_32_2nd ( (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_32_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.25475889444351196, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00251, BEST_BATCHSIZE : 64\n",
      "GlorotNormal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.3202672004699707, TEST_LOSS = 0.47966986894607544\n",
      "dense_64_128_32_st_dense_128_128_32\n",
      "Model: \"dense_64_128_32_st_dense_128_128_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_128_32_2nd  (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_128_32_2nd  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_128_32_2nd  (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_128_3 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 37,601\n",
      "Trainable params: 37,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstacked_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_stacked_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mModel_Stacking2.optimize_stacked_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     53\u001b[0m h \u001b[38;5;241m=\u001b[39m hyp_opt\u001b[38;5;241m.\u001b[39mHyperparameter_Optimization([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_x], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_y], model, loss_fn, activation_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, initializer_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 54\u001b[0m best_lr, best_batch_size, _, best_initializer \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_initializer)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(model, best_initializer)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:120\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.get_best_hyperparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m initializer \u001b[38;5;129;01min\u001b[39;00m intializer_list[i]:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(initializer_str\u001b[38;5;241m=\u001b[39minitializer)\n\u001b[0;32m--> 120\u001b[0m     lr, batch_size, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_batch_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitializer_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(best_loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m loss\u001b[38;5;241m<\u001b[39mbest_loss):\n\u001b[1;32m    122\u001b[0m         best_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:147\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.lr_batch_optimization\u001b[0;34m(self, initializer_str)\u001b[0m\n\u001b[1;32m    145\u001b[0m     best_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lr_opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     best_lr, best_batch_size, best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_batch_size_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitializer_str\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitializer_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_lr, best_batch_size, best_loss\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:90\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.get_best_batch_size_lr\u001b[0;34m(self, initializer_str)\u001b[0m\n\u001b[1;32m     87\u001b[0m best_lr_batch, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_best_lr(batch_size)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(initializer_str\u001b[38;5;241m=\u001b[39minitializer_str)\n\u001b[0;32m---> 90\u001b[0m best_loss_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_lr_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m best_lr_list\u001b[38;5;241m.\u001b[39mappend(best_lr_batch)\n\u001b[1;32m     93\u001b[0m best_loss_list\u001b[38;5;241m.\u001b[39mappend(best_loss_batch)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:75\u001b[0m, in \u001b[0;36mHyperparameter_Optimization._train_model\u001b[0;34m(self, lr, batch_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_fn, optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[0;32m---> 75\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_Y, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1077\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n\u001b[1;32m   1068\u001b[0m   callbacks \u001b[38;5;241m=\u001b[39m callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList(\n\u001b[1;32m   1069\u001b[0m       callbacks,\n\u001b[1;32m   1070\u001b[0m       add_history\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1074\u001b[0m       epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m   1075\u001b[0m       steps\u001b[38;5;241m=\u001b[39mdata_handler\u001b[38;5;241m.\u001b[39minferred_steps)\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_counter\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:324\u001b[0m, in \u001b[0;36mModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    317\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# six.raise_from supresses the original AttributeError from being raised\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIt looks like you are subclassing `Model` and you \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforgot to call `super(YourClass, self).__init__()`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    322\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Always start with this line.\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2847\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;66;03m# Clean out the old attribute, which clears _layers and _trainable_weights\u001b[39;00m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;66;03m# if necessary.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2847\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__delattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   2849\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2797\u001b[0m, in \u001b[0;36mLayer.__delattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2794\u001b[0m   \u001b[38;5;28msuper\u001b[39m(tracking\u001b[38;5;241m.\u001b[39mAutoTrackable, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__delattr__\u001b[39m(name)\n\u001b[1;32m   2795\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2797\u001b[0m reference_count \u001b[38;5;241m=\u001b[39m \u001b[43mreference_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexisting_value\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reference_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2799\u001b[0m   \u001b[38;5;66;03m# There are other remaining references. We can't remove this object from\u001b[39;00m\n\u001b[1;32m   2800\u001b[0m   \u001b[38;5;66;03m# _layers etc.\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m   reference_counts[existing_value] \u001b[38;5;241m=\u001b[39m reference_count \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/util/object_identity.py:138\u001b[0m, in \u001b[0;36mObjectIdentityDictionary.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 138\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/util/object_identity.py:67\u001b[0m, in \u001b[0;36m_ObjectIdentityWrapper.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;66;03m# Wrapper id() is also fine for weakrefs. In fact, we rely on\u001b[39;00m\n\u001b[1;32m     65\u001b[0m   \u001b[38;5;66;03m# id(weakref.ref(a)) == id(weakref.ref(a)) and weakref.ref(a) is\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   \u001b[38;5;66;03m# weakref.ref(a) in _WeakObjectIdentityWrapper.\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stacked_models.optimize_stacked_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"/home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_64/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selu\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "activation = model.layers[-2].get_config()[\"activation\"]\n",
    "print(activation)\n",
    "print(type(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64_reduced\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 8,576\n",
      "Trainable params: 8,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reduce_model = Model(name = model.name+\"_reduced\", inputs = model.input, outputs = model.layers[-2].output)\n",
    "print(reduce_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Flatten, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = Sequential()\n",
    "# new_model.add(Dropout(0.1))\n",
    "# new_model.add(reduce_model)\n",
    "# new_model.add(Dropout(0.2))\n",
    "# new_model.add(Dense(1024, activation = activation))\n",
    "# new_model.add(Dense(1024, activation = activation))\n",
    "# new_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = reduce_model.output\n",
    "x = last_layer\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1024, activation = activation)(x)\n",
    "x = Dense(1024, activation = activation)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1)(x)\n",
    "new_model = Model(inputs = reduce_model.input, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_326 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_327 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,125,761\n",
      "Trainable params: 1,125,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7]\n"
     ]
    }
   ],
   "source": [
    "dropout_ind = []\n",
    "ind = 0\n",
    "for layer in new_model.layers:\n",
    "    if layer.__class__.__name__ == \"Dropout\":\n",
    "        dropout_ind.append(ind)\n",
    "    ind = ind+1\n",
    "print(dropout_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.layers[4].rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.layers[4].rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 2)\n",
      "(63, 1) (63,)\n",
      "(42, 1) (21, 1) (42,) (21,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load the sonar dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "print(dataframe.shape)\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "data = data.astype('float32')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  564.4772338867188 , TEST :  696.4302978515625\n",
      "output_layer_dense_32_32_loss  :  77.97647094726562 , TEST :  102.96764373779297\n",
      "output_layer_dense_32_64_loss  :  72.4428939819336 , TEST :  94.78680419921875\n",
      "output_layer_dense_32_128_loss  :  43.49039840698242 , TEST :  50.427490234375\n",
      "output_layer_dense_32_1024_loss  :  32.640380859375 , TEST :  31.093881607055664\n",
      "output_layer_dense_64_32_loss  :  68.5215072631836 , TEST :  88.98941802978516\n",
      "output_layer_dense_64_64_loss  :  67.38311004638672 , TEST :  87.2926254272461\n",
      "output_layer_dense_64_128_loss  :  41.06880569458008 , TEST :  45.563011169433594\n",
      "output_layer_dense_64_1024_loss  :  32.03666687011719 , TEST :  28.78836441040039\n",
      "output_layer_dense_128_32_loss  :  72.19493103027344 , TEST :  94.40507507324219\n",
      "output_layer_dense_128_64_loss  :  56.72202682495117 , TEST :  72.11593627929688\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  204.6041717529297 , TEST :  193.50648498535156\n",
      "output_layer_dense_128_128_loss  :  43.74370574951172 , TEST :  50.91599655151367\n",
      "output_layer_dense_128_1024_loss  :  31.940673828125 , TEST :  27.309024810791016\n",
      "output_layer_dense_1024_32_loss  :  31.918380737304688 , TEST :  27.996408462524414\n",
      "output_layer_dense_1024_64_loss  :  33.159645080566406 , TEST :  34.39208984375\n",
      "output_layer_dense_1024_128_loss  :  31.97357177734375 , TEST :  25.20755386352539\n",
      "output_layer_dense_1024_1024_loss  :  31.868175506591797 , TEST :  27.685407638549805\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  396.1885681152344 , TEST :  412.23150634765625\n",
      "output_layer_dense_32_32_32_loss  :  67.75357818603516 , TEST :  87.86875915527344\n",
      "output_layer_dense_32_32_64_loss  :  55.70736312866211 , TEST :  70.67930603027344\n",
      "output_layer_dense_32_32_128_loss  :  33.16255569458008 , TEST :  25.683181762695312\n",
      "output_layer_dense_32_32_1024_loss  :  32.28651809692383 , TEST :  29.9041805267334\n",
      "output_layer_dense_32_64_32_loss  :  35.29856872558594 , TEST :  32.24654006958008\n",
      "output_layer_dense_32_64_64_loss  :  43.165130615234375 , TEST :  49.84916305541992\n",
      "output_layer_dense_32_64_128_loss  :  32.039371490478516 , TEST :  28.813858032226562\n",
      "output_layer_dense_32_64_1024_loss  :  31.844669342041016 , TEST :  27.289440155029297\n",
      "output_layer_dense_32_128_32_loss  :  31.92618179321289 , TEST :  27.147016525268555\n",
      "output_layer_dense_32_128_64_loss  :  33.00459671020508 , TEST :  32.75004959106445\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0a203ec700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  400.072998046875 , TEST :  415.59356689453125\n",
      "output_layer_dense_32_128_128_loss  :  33.348819732666016 , TEST :  35.67073440551758\n",
      "output_layer_dense_32_128_1024_loss  :  31.862337112426758 , TEST :  26.892961502075195\n",
      "output_layer_dense_32_1024_32_loss  :  32.63373565673828 , TEST :  31.09195327758789\n",
      "output_layer_dense_32_1024_64_loss  :  31.856761932373047 , TEST :  26.121145248413086\n",
      "output_layer_dense_32_1024_128_loss  :  31.77286148071289 , TEST :  26.318124771118164\n",
      "output_layer_dense_32_1024_1024_loss  :  31.885509490966797 , TEST :  25.188533782958984\n",
      "output_layer_dense_64_32_32_loss  :  63.9492301940918 , TEST :  82.36168670654297\n",
      "output_layer_dense_64_64_32_loss  :  72.885009765625 , TEST :  95.42500305175781\n",
      "output_layer_dense_64_64_64_loss  :  37.93951416015625 , TEST :  38.811222076416016\n",
      "output_layer_dense_64_64_128_loss  :  31.939241409301758 , TEST :  27.71219825744629\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d9f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  327.50689697265625 , TEST :  299.78814697265625\n",
      "output_layer_dense_64_64_1024_loss  :  31.8554630279541 , TEST :  25.88766098022461\n",
      "output_layer_dense_64_128_32_loss  :  31.906051635742188 , TEST :  25.64059066772461\n",
      "output_layer_dense_64_128_64_loss  :  33.201045989990234 , TEST :  34.193389892578125\n",
      "output_layer_dense_64_128_128_loss  :  32.75349426269531 , TEST :  31.522672653198242\n",
      "output_layer_dense_64_128_1024_loss  :  31.98941421508789 , TEST :  28.798473358154297\n",
      "output_layer_dense_64_1024_32_loss  :  33.3077278137207 , TEST :  35.31038284301758\n",
      "output_layer_dense_64_1024_64_loss  :  31.882036209106445 , TEST :  26.396068572998047\n",
      "output_layer_dense_64_1024_128_loss  :  32.024383544921875 , TEST :  28.8597354888916\n",
      "output_layer_dense_64_1024_1024_loss  :  31.849613189697266 , TEST :  27.19002914428711\n",
      "output_layer_dense_128_32_32_loss  :  36.737648010253906 , TEST :  35.98911666870117\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09813ad0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  342.26483154296875 , TEST :  328.2178039550781\n",
      "output_layer_dense_128_64_32_loss  :  48.028038024902344 , TEST :  58.27384567260742\n",
      "output_layer_dense_128_64_64_loss  :  35.14159393310547 , TEST :  31.83365821838379\n",
      "output_layer_dense_128_128_32_loss  :  33.40260696411133 , TEST :  35.939876556396484\n",
      "output_layer_dense_128_128_64_loss  :  33.0523796081543 , TEST :  33.2486572265625\n",
      "output_layer_dense_128_128_128_loss  :  32.45167922973633 , TEST :  30.385448455810547\n",
      "output_layer_dense_128_128_1024_loss  :  32.060020446777344 , TEST :  29.12714195251465\n",
      "output_layer_dense_128_1024_32_loss  :  32.3466796875 , TEST :  25.076053619384766\n",
      "output_layer_dense_128_1024_64_loss  :  31.98933982849121 , TEST :  28.839698791503906\n",
      "output_layer_dense_128_1024_128_loss  :  31.976551055908203 , TEST :  28.71439552307129\n",
      "output_layer_dense_128_1024_1024_loss  :  31.815929412841797 , TEST :  26.779003143310547\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  333.677490234375 , TEST :  306.97418212890625\n",
      "output_layer_dense_1024_32_32_loss  :  44.59679412841797 , TEST :  52.55773162841797\n",
      "output_layer_dense_1024_64_32_loss  :  33.508392333984375 , TEST :  36.54766082763672\n",
      "output_layer_dense_1024_64_64_loss  :  31.81412124633789 , TEST :  26.398746490478516\n",
      "output_layer_dense_1024_128_32_loss  :  32.89533233642578 , TEST :  32.505619049072266\n",
      "output_layer_dense_1024_128_64_loss  :  31.82064437866211 , TEST :  26.59869384765625\n",
      "output_layer_dense_1024_128_128_loss  :  31.81867027282715 , TEST :  26.49064064025879\n",
      "output_layer_dense_1024_1024_32_loss  :  31.895700454711914 , TEST :  27.852462768554688\n",
      "output_layer_dense_1024_1024_64_loss  :  31.739051818847656 , TEST :  26.053115844726562\n",
      "output_layer_dense_1024_1024_128_loss  :  31.811500549316406 , TEST :  26.66451072692871\n",
      "output_layer_dense_1024_1024_1024_loss  :  31.777271270751953 , TEST :  25.304996490478516\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "[{'model_name': 'dense_128_1024_32', 'score': 25.076053619384766, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_1024_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 128, 'layer2': 1024, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d1a7f0>}, {'model_name': 'dense_32_1024_1024', 'score': 25.188533782958984, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0988425a60>}, {'model_name': 'dense_1024_128', 'score': 25.20755386352539, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_128', 'model_conf': ['', 1, 2, 'relu', {'layer1': 1024, 'layer2': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d68220>}, {'model_name': 'dense_1024_1024_1024', 'score': 25.304996490478516, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f09807cc700>}, {'model_name': 'dense_64_128_32', 'score': 25.64059066772461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f098195ac70>}, {'model_name': 'dense_32_32_128', 'score': 25.683181762695312, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0980615580>}, {'model_name': 'dense_64_64_1024', 'score': 25.88766098022461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983a2b160>}, {'model_name': 'dense_1024_1024_64', 'score': 26.053115844726562, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983c1efa0>}, {'model_name': 'dense_32_1024_64', 'score': 26.121145248413086, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad7550>}, {'model_name': 'dense_32_1024_128', 'score': 26.318124771118164, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad70a0>}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_128_1024_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_128_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_32_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_64_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_128/assets\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Time Taken :  20.406763076782227\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 1, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = True)\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : dense_128_1024_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.345319747924805, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.02512, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981bbd700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.84622573852539, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00158, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0983e43d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.873470306396484 , TEST :  24.018808364868164\n",
      "Model Name : dense_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.384897232055664, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098847c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  32.86589050292969 , TEST :  32.15849685668945\n",
      "Model Name : dense_1024_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.181747436523438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098167b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.778873443603516 , TEST :  28.295467376708984\n",
      "Model Name : dense_64_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.6921329498291, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00398, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09838ab790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.848989486694336 , TEST :  24.678855895996094\n",
      "Model Name : dense_32_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.34592628479004, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fd4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.671247482299805 , TEST :  28.42959213256836\n",
      "Model Name : dense_64_64_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.222423553466797, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882c7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.99043846130371 , TEST :  26.99068832397461\n",
      "Model Name : dense_1024_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 27.45450210571289, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01585, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d19a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.205533981323242, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981f60b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.2604923248291 , TEST :  26.66190528869629\n",
      "Model Name : dense_32_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.960067749023438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.002, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09884280d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.737110137939453 , TEST :  25.75638198852539\n"
     ]
    }
   ],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list)\n",
    "opt.optimize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-GljDEx7Q8i"
   },
   "outputs": [],
   "source": [
    "search = StructuredDataRegressor(max_trials=15, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CF1WqFSj7TAN",
    "outputId": "022c0fdf-8cfd-45ed-ddce-e183911b0e99"
   },
   "outputs": [],
   "source": [
    "search.fit(x=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pJvdP_eb7vYp",
    "outputId": "15a9315a-a61d-4a11-ba0e-467eaafd7415"
   },
   "outputs": [],
   "source": [
    "train_mae, _ = search.evaluate(X_train, y_train, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(train_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ESltODdC8AO0",
    "outputId": "30d0352d-1ed0-40ca-bbe0-cfe17fe836cb"
   },
   "outputs": [],
   "source": [
    "test_mae, _ = search.evaluate(X_test, y_test, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vi_KQC2K8pzs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autokeras-regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
