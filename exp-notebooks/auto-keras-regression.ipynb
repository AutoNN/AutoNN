{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "SVyZBHaE6zqD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "# from autokeras import StructuredDataRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from IPython.display import HTML\n",
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, '/home/anish/ASC_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 18:38:54.340831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from ASC_ML.networkbuilding import multiple_model_gen_v3 as multiple\n",
    "from ASC_ML.networkbuilding import dataframe_extractor as de\n",
    "from ASC_ML.networkbuilding import model_generation as model_gen\n",
    "from ASC_ML.networkbuilding import model_optimization as model_opt\n",
    "from ASC_ML.networkbuilding import model_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Bi5A13BZ6_17"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/anish/Downloads/autokeras-regression-master/Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "n9heEDsL7VRF",
    "outputId": "08d5989f-cd83-4bf3-bcb0-8622664384fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "xj63U7al-28H",
    "outputId": "74713606-0aba-4d27-9639-091b601b7e27"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"TV\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "6JNLdc67Jsz8",
    "outputId": "52abc809-f857-4243-d3a8-b3468b72843d"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"radio\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "HhyWxbnSJ0pX",
    "outputId": "f680d6b6-b482-471a-e09f-ed5cbee67653"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"newspaper\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y_T3s3Yj7jRk"
   },
   "outputs": [],
   "source": [
    "target_col = \"sales\"\n",
    "X = df.loc[:, df.columns != target_col]\n",
    "y = df.loc[:, target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DAJC0VIH7ptP"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((y_train.shape[0],1))\n",
    "y_test = y_test.reshape((y_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 18:38:57.891120: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-27 18:38:57.891761: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-27 18:38:57.942444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 18:38:57.942569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-27 18:38:57.942588: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-27 18:38:57.943611: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-27 18:38:57.943640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-27 18:38:57.944627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-27 18:38:57.944802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-27 18:38:57.945770: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-27 18:38:57.946421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-27 18:38:57.948928: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-27 18:38:57.949031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 18:38:57.949190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 18:38:57.949274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-27 18:38:57.949641: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-27 18:38:57.949825: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-27 18:38:57.949904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 18:38:57.949998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-27 18:38:57.950020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-27 18:38:57.950035: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-27 18:38:57.950048: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-27 18:38:57.950061: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-27 18:38:57.950074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-27 18:38:57.950087: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-27 18:38:57.950100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-27 18:38:57.950113: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-27 18:38:57.950153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 18:38:57.950269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 18:38:57.950349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-27 18:38:57.950374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-27 18:38:58.329992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-27 18:38:58.330019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-08-27 18:38:58.330024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-08-27 18:38:58.330175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 18:38:58.330318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 18:38:58.330433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-27 18:38:58.330524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5055 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-08-27 18:38:58.605601: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-08-27 18:38:58.605971: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n",
      "2022-08-27 18:38:59.851061: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  10.41256046295166 , TEST :  10.865803718566895\n",
      "output_layer_dense_32_32_loss  :  1.1276155710220337 , TEST :  1.1664645671844482\n",
      "output_layer_dense_32_64_loss  :  1.1592581272125244 , TEST :  1.2132033109664917\n",
      "output_layer_dense_32_128_loss  :  0.9687111973762512 , TEST :  1.145270586013794\n",
      "output_layer_dense_64_32_loss  :  1.1947652101516724 , TEST :  1.1248911619186401\n",
      "output_layer_dense_64_64_loss  :  1.2176878452301025 , TEST :  1.2695287466049194\n",
      "output_layer_dense_64_128_loss  :  1.3174989223480225 , TEST :  1.3468296527862549\n",
      "output_layer_dense_128_32_loss  :  1.1951124668121338 , TEST :  1.2340493202209473\n",
      "output_layer_dense_128_64_loss  :  1.1886870861053467 , TEST :  1.2728761434555054\n",
      "output_layer_dense_128_128_loss  :  1.0432239770889282 , TEST :  1.0926899909973145\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  10.840103149414062 , TEST :  12.468206405639648\n",
      "output_layer_dense_32_32_32_loss  :  1.1787726879119873 , TEST :  1.3808284997940063\n",
      "output_layer_dense_32_32_64_loss  :  1.0411380529403687 , TEST :  1.2156471014022827\n",
      "output_layer_dense_32_32_128_loss  :  1.0015615224838257 , TEST :  1.1958808898925781\n",
      "output_layer_dense_32_64_32_loss  :  0.9919775724411011 , TEST :  1.1788181066513062\n",
      "output_layer_dense_32_64_64_loss  :  1.2414785623550415 , TEST :  1.5345414876937866\n",
      "output_layer_dense_32_64_128_loss  :  1.0541808605194092 , TEST :  1.2031888961791992\n",
      "output_layer_dense_32_128_32_loss  :  1.0202947854995728 , TEST :  1.1490230560302734\n",
      "output_layer_dense_32_128_64_loss  :  1.0425117015838623 , TEST :  1.2475395202636719\n",
      "output_layer_dense_32_128_128_loss  :  0.9873288869857788 , TEST :  1.085234522819519\n",
      "output_layer_dense_64_32_32_loss  :  1.2808576822280884 , TEST :  1.2775046825408936\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb9f43c3a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  11.784856796264648 , TEST :  13.219955444335938\n",
      "output_layer_dense_64_64_32_loss  :  1.337359070777893 , TEST :  1.363561749458313\n",
      "output_layer_dense_64_64_64_loss  :  1.0132442712783813 , TEST :  1.1183949708938599\n",
      "output_layer_dense_64_64_128_loss  :  1.0162585973739624 , TEST :  1.1686038970947266\n",
      "output_layer_dense_64_128_32_loss  :  1.3927223682403564 , TEST :  1.734667420387268\n",
      "output_layer_dense_64_128_64_loss  :  1.0794142484664917 , TEST :  1.1552006006240845\n",
      "output_layer_dense_64_128_128_loss  :  1.2154737710952759 , TEST :  1.190104365348816\n",
      "output_layer_dense_128_32_32_loss  :  1.054985761642456 , TEST :  1.189560890197754\n",
      "output_layer_dense_128_64_32_loss  :  1.0712345838546753 , TEST :  1.2087877988815308\n",
      "output_layer_dense_128_64_64_loss  :  1.366044044494629 , TEST :  1.6103194952011108\n",
      "output_layer_dense_128_128_32_loss  :  1.238120436668396 , TEST :  1.4807548522949219\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fba4c7378b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  2.2192084789276123 , TEST :  2.448669910430908\n",
      "output_layer_dense_128_128_64_loss  :  1.1931095123291016 , TEST :  1.3597691059112549\n",
      "output_layer_dense_128_128_128_loss  :  1.0260989665985107 , TEST :  1.0889008045196533\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "[{'model_name': 'dense_32_128_128', 'score': 1.085234522819519, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_128_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 128, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fb9f454f700>}, {'model_name': 'dense_128_128_128', 'score': 1.0889008045196533, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_128_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 128, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fba70161490>}, {'model_name': 'dense_128_128', 'score': 1.0926899909973145, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_128', 'model_conf': ['', 3, 2, 'relu', {'layer1': 128, 'layer2': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fba4c5c01c0>}, {'model_name': 'dense_64_64_64', 'score': 1.1183949708938599, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fb9f46b5880>}, {'model_name': 'dense_64_32', 'score': 1.1248911619186401, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_32', 'model_conf': ['', 3, 2, 'relu', {'layer1': 64, 'layer2': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fba4c6e08b0>}, {'model_name': 'dense_32_128', 'score': 1.145270586013794, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_128', 'model_conf': ['', 3, 2, 'relu', {'layer1': 32, 'layer2': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fba4c637f70>}, {'model_name': 'dense_32_128_32', 'score': 1.1490230560302734, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_128_32', 'model_conf': ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 128, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fb9f454fe20>}, {'model_name': 'dense_64_128_64', 'score': 1.1552006006240845, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_64', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fba4c5b9d90>}, {'model_name': 'dense_32_32', 'score': 1.1664645671844482, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32', 'model_conf': ['', 3, 2, 'relu', {'layer1': 32, 'layer2': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fba4c637e50>}, {'model_name': 'dense_64_64_128', 'score': 1.1686038970947266, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_128', 'model_conf': ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7fb9f44f6e50>}]\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Time Taken :  11.11124873161316\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 3, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = False)\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list, save_dir = \"/home/anish/ASC_ML_test_weights/candidate_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_128_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5649034976959229, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0005, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb9c85868b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.2000199854373932 , TEST :  0.3235742449760437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-27 18:39:25.741293: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_128_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_128_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5482297539710999, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb9f464a430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.26586928963661194 , TEST :  0.44447606801986694\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_128_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.6248886585235596, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00025, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fba4c07d4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.2970917224884033 , TEST :  0.39893364906311035\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_64_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.6313995122909546, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fba70288430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.25094443559646606 , TEST :  0.3970472812652588\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.8066732287406921, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.002, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fba70148940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.33882784843444824 , TEST :  0.37067341804504395\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5920138955116272, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00126, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fba4c28bdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.5437983274459839 , TEST :  0.6801711916923523\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.49172478914260864, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb9d044fee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.2283691167831421 , TEST :  0.47589007019996643\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_128_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_128_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.6103410720825195, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fba4c56e790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.38335520029067993 , TEST :  0.46907028555870056\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_128_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_32_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.7082774639129639, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00631, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb9d05fdb80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3174479305744171 , TEST :  0.4267424941062927\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_32_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_64_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.580427885055542, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00079, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fba7022b8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.37376314401626587 , TEST :  0.4464358687400818\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_128/assets\n"
     ]
    }
   ],
   "source": [
    "opt.optimize_models(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 3, 3, 'relu', {'layer1': 32, 'layer2': 128, 'layer3': 128}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 128, 'layer2': 128, 'layer3': 128}, [1, None]],\n",
       " ['', 3, 2, 'relu', {'layer1': 128, 'layer2': 128}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 64}, [1, None]],\n",
       " ['', 3, 2, 'relu', {'layer1': 64, 'layer2': 32}, [1, None]],\n",
       " ['', 3, 2, 'relu', {'layer1': 32, 'layer2': 128}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 32, 'layer2': 128, 'layer3': 32}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 64}, [1, None]],\n",
       " ['', 3, 2, 'relu', {'layer1': 32, 'layer2': 32}, [1, None]],\n",
       " ['', 3, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 128}, [1, None]]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.model_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0005, 16, 'selu', 'GlorotUniform'],\n",
       " [0.0004, 16, 'selu', 'GlorotNormal'],\n",
       " [0.00025, 16, 'selu', 'GlorotUniform'],\n",
       " [0.00063, 16, 'selu', 'GlorotUniform'],\n",
       " [0.002, 16, 'selu', 'GlorotUniform'],\n",
       " [0.00126, 16, 'selu', 'GlorotUniform'],\n",
       " [0.00063, 16, 'selu', 'GlorotUniform'],\n",
       " [0.00063, 16, 'selu', 'GlorotNormal'],\n",
       " [0.00631, 16, 'selu', 'GlorotUniform'],\n",
       " [0.00079, 16, 'selu', 'GlorotUniform']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.best_hyp_permodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class Dropout_Optimization():\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, epochs, model):\n",
    "        self._train_x = train_x\n",
    "        self._train_y = train_y\n",
    "        self._test_x = test_x\n",
    "        self._test_y = test_y\n",
    "        self._epochs = epochs\n",
    "        self._model = model\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        # Logic to get loss funtion\n",
    "        # return \"mean_absolute_percentage_error\"\n",
    "        # return self.root_mean_squared_error\n",
    "        # return \"mean_squared_error\"\n",
    "        return \"mean_absolute_error\"\n",
    "\n",
    "    def dropout_optimization(self, lr = 1e-3, batch_size = 64, epoch = 100):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        dropout_indices = self._get_dropout_index()\n",
    "        dropout_list = [0,0.2,0.5]\n",
    "        dropout_comb_list = []\n",
    "        dropout_loss_list = []\n",
    "        for dropout0 in dropout_list:\n",
    "            for dropout1 in dropout_list:\n",
    "                dropout_comb_list.append([dropout0,dropout1])\n",
    "                self._model.layers[dropout_indices[0]].rate = dropout0\n",
    "                self._model.layers[dropout_indices[1]].rate = dropout1\n",
    "                optimizer = Adam(lr = lr)\n",
    "                self._model.compile(loss = loss_fn, optimizer = optimizer)\n",
    "                history = self._model.fit(self._train_x, self._train_y, epochs = epoch, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "                scores = self._model.evaluate(self._train_x, self._train_y, verbose = 0)\n",
    "                scores_test = self._model.evaluate(self._test_x, self._test_y, verbose = 0)\n",
    "#                 print(f\"For Dropouts D0 = {dropout0}, D1 = {dropout1}, TRAIN_LOSS = {scores}, TEST_LOSS = {scores_test}\")\n",
    "                dropout_loss_list.append(scores_test)\n",
    "                \n",
    "        best_dropout_rates = dropout_comb_list[dropout_loss_list.index(min(dropout_loss_list))]\n",
    "        self._model.layers[dropout_indices[0]].rate = best_dropout_rates[0]\n",
    "        self._model.layers[dropout_indices[1]].rate = best_dropout_rates[1]\n",
    "        return best_dropout_rates\n",
    "                \n",
    "\n",
    "    def _get_dropout_index(self):\n",
    "        dropout_indices = []\n",
    "        ind = 0\n",
    "        for layer in self._model.layers:\n",
    "            if layer.__class__.__name__ == \"Dropout\":\n",
    "                dropout_indices.append(ind)\n",
    "            ind = ind+1\n",
    "        return dropout_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.initializers import RandomUniform, GlorotUniform, GlorotNormal, HeUniform, HeNormal\n",
    "\n",
    "from ASC_ML.networkbuilding import model_generation as model_gen\n",
    "from ASC_ML.networkbuilding import hyperparameter_optimization as hyp_opt\n",
    "\n",
    "class Model_Stacking2:\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, model_path_list, model_conf_list, save_dir = \"\"):\n",
    "        self._model_path_list = model_path_list\n",
    "        self._model_conf_list = model_conf_list\n",
    "        self._train_x = train_x\n",
    "        self._train_y = train_y\n",
    "        self._test_x = test_x\n",
    "        self._test_y = test_y\n",
    "        self._save_dir = save_dir\n",
    "        self._stacked_model_paths = []\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        # Logic to get loss funtion\n",
    "        # return \"mean_absolute_percentage_error\"\n",
    "        # return self.root_mean_squared_error\n",
    "        # return \"mean_squared_error\"\n",
    "        return \"mean_absolute_error\"\n",
    "\n",
    "    def _stacked_model_generator(self):\n",
    "        for path in self._model_path_list:\n",
    "            for model_conf in self._model_conf_list:\n",
    "                model1 = load_model(path)\n",
    "                activation = model1.layers[-2].get_config()[\"activation\"]\n",
    "                reduced_model1 = Model(name = model1.name+\"_reduced\", inputs = model1.input, outputs = model1.layers[-2].output)\n",
    "                last_layer = reduced_model1.output\n",
    "                x = last_layer\n",
    "                model2_obj = model_gen.NN_ModelGeneration(*model_conf)\n",
    "                x = Dropout(0.0)(x)\n",
    "                for layer_name in model2_obj.layer_conf:\n",
    "                    x = Dense(model2_obj.layer_conf[layer_name], activation = activation, name = layer_name+\"_2nd\")(x)\n",
    "                x = Dropout(0.0)(x)\n",
    "                output_layer = Dense(model2_obj.output_layer_conf[0], activation = model2_obj.output_layer_conf[1], name = \"output_layer\" + \"_\" + model2_obj.model_name)(x)\n",
    "\n",
    "                stacked_model = Model(name = model1.name + \"_st_\" + model2_obj.model_name,inputs = reduced_model1.input, outputs = output_layer)\n",
    "                x = None\n",
    "                output_layer = None\n",
    "                yield stacked_model\n",
    "\n",
    "    def optimize_stacked_models(self):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        stacked_model_generator = self._stacked_model_generator()\n",
    "        for model in stacked_model_generator:\n",
    "            print(model.name)\n",
    "            print(model.summary())\n",
    "            h = hyp_opt.Hyperparameter_Optimization([self._train_x], [self._train_y], model, loss_fn, activation_opt = True, initializer_opt = True)\n",
    "            best_lr, best_batch_size, _, best_initializer = h.get_best_hyperparameters()\n",
    "            print(best_initializer)\n",
    "            self._reinitialize_model(model, best_initializer)\n",
    "            \n",
    "            dr = Dropout_Optimization(self._train_x, self._train_y, self._test_x, self._test_y, epochs = 100, model = model)\n",
    "            best_dropout_rates = dr.dropout_optimization(lr = best_lr, batch_size = best_batch_size, epoch = 100)\n",
    "            \n",
    "            model = self._train_models(model = model, lr = best_lr, batch_size = best_batch_size)\n",
    "            self._save_model(model)\n",
    "            \n",
    "#             print(f\"BEST LR STACKED {best_lr}, BEST BATCH SIZE {best_batch_size}\")\n",
    "#             dr = Dropout_Optimization(self._train_x, self._train_y, self._test_x, self._test_y, epochs = 100, model = model)\n",
    "#             dr.dropout_optimization(lr = best_lr, batch_size = best_batch_size, epoch = 100)\n",
    "    \n",
    "    def _train_models(self, model, lr, batch_size):\n",
    "        loss_fn = self.get_loss_function()\n",
    "        optimizer = Adam(lr = lr)\n",
    "        model.compile(loss = loss_fn, optimizer = optimizer)\n",
    "        history = model.fit(self._train_x, self._train_y, epochs = 100, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "        scores = model.evaluate(self._train_x, self._train_y, verbose = 0)\n",
    "        scores_test = model.evaluate(self._test_x, self._test_y, verbose = 0)\n",
    "        print(f\"TRAIN_LOSS = {scores}, TEST_LOSS = {scores_test}\")\n",
    "        return model\n",
    "        \n",
    "    @staticmethod\n",
    "    def _reinitialize_model(model, initializer_str = \"RandomUniform\"):\n",
    "        if initializer_str == \"RandomUniform\":\n",
    "            initializer = RandomUniform(seed = 420)\n",
    "        elif initializer_str == \"GlorotUniform\":\n",
    "            initializer = GlorotUniform(seed = 420)\n",
    "        elif initializer_str == \"HeUniform\":\n",
    "            initializer = HeUniform(seed = 420)\n",
    "        elif initializer_str == \"GlorotNormal\":\n",
    "            initializer = GlorotNormal(seed = 420)\n",
    "        elif initializer_str == \"HeNormal\":\n",
    "            initializer = HeNormal(seed = 420)\n",
    "        for layer in model.layers:\n",
    "            layer.set_weights([initializer(shape=w.shape) for w in layer.get_weights()])\n",
    "            \n",
    "    def _save_model(self, model):\n",
    "        path = os.path.join(self._save_dir,model.name)\n",
    "        model.save(path)\n",
    "        self._stacked_model_paths.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_models = model_stacking.Model_Stacking(opt.saved_paths, opt.model_confs)\n",
    "stacked_models = Model_Stacking2(X_train, y_train, X_test, y_test, opt.saved_paths, opt.model_confs, save_dir = \"/home/anish/ASC_ML_test_weights/stacked_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_32_128_128_st_dense_32_128_128\n",
      "Model: \"dense_32_128_128_st_dense_32_128_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_32_128_128 [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_128_128 (Den (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_128_128 (Den (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_128_128 (Den (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_128_128_2nd  (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_128_128_2nd  (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_128_128_2nd  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_32_128_12 (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 45,857\n",
      "Trainable params: 45,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5406903028488159, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00025, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n",
      "For Dropouts D0 = 0, D1 = 0, TRAIN_LOSS = 0.37207064032554626, TEST_LOSS = 0.4624374508857727\n",
      "For Dropouts D0 = 0, D1 = 0.2, TRAIN_LOSS = 0.4407477378845215, TEST_LOSS = 0.5808321833610535\n",
      "For Dropouts D0 = 0, D1 = 0.5, TRAIN_LOSS = 0.3717619478702545, TEST_LOSS = 0.3822208046913147\n",
      "For Dropouts D0 = 0.2, D1 = 0, TRAIN_LOSS = 1.0103870630264282, TEST_LOSS = 1.0213382244110107\n",
      "For Dropouts D0 = 0.2, D1 = 0.2, TRAIN_LOSS = 0.7599348425865173, TEST_LOSS = 0.8163679838180542\n",
      "For Dropouts D0 = 0.2, D1 = 0.5, TRAIN_LOSS = 0.9011729955673218, TEST_LOSS = 0.9751296043395996\n",
      "For Dropouts D0 = 0.5, D1 = 0, TRAIN_LOSS = 1.3955920934677124, TEST_LOSS = 1.466938853263855\n",
      "For Dropouts D0 = 0.5, D1 = 0.2, TRAIN_LOSS = 0.9600883722305298, TEST_LOSS = 1.088428258895874\n",
      "For Dropouts D0 = 0.5, D1 = 0.5, TRAIN_LOSS = 0.942740797996521, TEST_LOSS = 1.0271929502487183\n",
      "TRAIN_LOSS = 0.39164531230926514, TEST_LOSS = 0.42244091629981995\n",
      "dense_32_128_128_st_dense_128_128_128\n",
      "Model: \"dense_32_128_128_st_dense_128_128_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_32_128_128 [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_128_128 (Den (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_128_128 (Den (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_128_128 (Den (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_128_128_2nd (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_128_128_2nd (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_128_128_2nd (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_128_1 (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 70,529\n",
      "Trainable params: 70,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.42188912630081177, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotNormal\n",
      "For Dropouts D0 = 0, D1 = 0, TRAIN_LOSS = 0.36013907194137573, TEST_LOSS = 0.44343557953834534\n",
      "For Dropouts D0 = 0, D1 = 0.2, TRAIN_LOSS = 0.2611975073814392, TEST_LOSS = 0.386008083820343\n",
      "For Dropouts D0 = 0, D1 = 0.5, TRAIN_LOSS = 0.6133624315261841, TEST_LOSS = 0.6622427105903625\n",
      "For Dropouts D0 = 0.2, D1 = 0, TRAIN_LOSS = 1.2762222290039062, TEST_LOSS = 1.3132117986679077\n",
      "For Dropouts D0 = 0.2, D1 = 0.2, TRAIN_LOSS = 0.8223856687545776, TEST_LOSS = 0.9132741093635559\n",
      "For Dropouts D0 = 0.2, D1 = 0.5, TRAIN_LOSS = 1.3979532718658447, TEST_LOSS = 1.437237024307251\n",
      "For Dropouts D0 = 0.5, D1 = 0, TRAIN_LOSS = 2.850371837615967, TEST_LOSS = 2.890735149383545\n",
      "For Dropouts D0 = 0.5, D1 = 0.2, TRAIN_LOSS = 2.870826244354248, TEST_LOSS = 2.8993124961853027\n",
      "For Dropouts D0 = 0.5, D1 = 0.5, TRAIN_LOSS = 2.38096022605896, TEST_LOSS = 2.416376829147339\n",
      "TRAIN_LOSS = 0.6156607866287231, TEST_LOSS = 0.5982478857040405\n",
      "dense_32_128_128_st_dense_128_128\n",
      "Model: \"dense_32_128_128_st_dense_128_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_32_128_128 [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_128_128 (Den (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_128_128 (Den (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_128_128 (Den (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_128_2nd (De (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_128_2nd (De (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_128 ( (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 54,017\n",
      "Trainable params: 54,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.5374866724014282, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00025, BEST_BATCHSIZE : 16\n",
      "GlorotNormal\n",
      "For Dropouts D0 = 0, D1 = 0, TRAIN_LOSS = 0.25912317633628845, TEST_LOSS = 0.3943328857421875\n",
      "For Dropouts D0 = 0, D1 = 0.2, TRAIN_LOSS = 0.8961950540542603, TEST_LOSS = 0.878552258014679\n",
      "For Dropouts D0 = 0, D1 = 0.5, TRAIN_LOSS = 0.5071333050727844, TEST_LOSS = 0.5275432467460632\n",
      "For Dropouts D0 = 0.2, D1 = 0, TRAIN_LOSS = 1.6782783269882202, TEST_LOSS = 1.6440719366073608\n",
      "For Dropouts D0 = 0.2, D1 = 0.2, TRAIN_LOSS = 1.1511646509170532, TEST_LOSS = 1.2293386459350586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Dropouts D0 = 0.2, D1 = 0.5, TRAIN_LOSS = 1.327645182609558, TEST_LOSS = 1.3325620889663696\n",
      "For Dropouts D0 = 0.5, D1 = 0, TRAIN_LOSS = 3.423964262008667, TEST_LOSS = 3.4241814613342285\n",
      "For Dropouts D0 = 0.5, D1 = 0.2, TRAIN_LOSS = 3.4317193031311035, TEST_LOSS = 3.395698070526123\n",
      "For Dropouts D0 = 0.5, D1 = 0.5, TRAIN_LOSS = 2.635221481323242, TEST_LOSS = 2.6293885707855225\n",
      "TRAIN_LOSS = 0.1904647946357727, TEST_LOSS = 0.3351060748100281\n",
      "dense_32_128_128_st_dense_64_64_64\n",
      "Model: \"dense_32_128_128_st_dense_64_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_32_128_128 [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_128_128 (Den (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_128_128 (Den (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_128_128 (Den (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64_2nd (D (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64_2nd (D (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64_2nd (D (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 37,505\n",
      "Trainable params: 37,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.4679230749607086, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0002, BEST_BATCHSIZE : 16\n",
      "GlorotNormal\n",
      "For Dropouts D0 = 0, D1 = 0, TRAIN_LOSS = 0.26599425077438354, TEST_LOSS = 0.4032328724861145\n",
      "For Dropouts D0 = 0, D1 = 0.2, TRAIN_LOSS = 0.3326440453529358, TEST_LOSS = 0.47490158677101135\n",
      "For Dropouts D0 = 0, D1 = 0.5, TRAIN_LOSS = 0.7113784551620483, TEST_LOSS = 0.654770016670227\n",
      "For Dropouts D0 = 0.2, D1 = 0, TRAIN_LOSS = 0.7746800184249878, TEST_LOSS = 0.8367196321487427\n",
      "For Dropouts D0 = 0.2, D1 = 0.2, TRAIN_LOSS = 0.6486209630966187, TEST_LOSS = 0.6667314767837524\n",
      "For Dropouts D0 = 0.2, D1 = 0.5, TRAIN_LOSS = 0.710128128528595, TEST_LOSS = 0.7522541284561157\n",
      "For Dropouts D0 = 0.5, D1 = 0, TRAIN_LOSS = 1.9095662832260132, TEST_LOSS = 1.9556922912597656\n",
      "For Dropouts D0 = 0.5, D1 = 0.2, TRAIN_LOSS = 1.2599966526031494, TEST_LOSS = 1.3818198442459106\n",
      "For Dropouts D0 = 0.5, D1 = 0.5, TRAIN_LOSS = 1.8510974645614624, TEST_LOSS = 1.9253469705581665\n",
      "TRAIN_LOSS = 0.218800351023674, TEST_LOSS = 0.34499025344848633\n",
      "dense_32_128_128_st_dense_64_32\n",
      "Model: \"dense_32_128_128_st_dense_64_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_32_128_128 [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_128_128 (Den (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_128_128 (Den (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_128_128 (Den (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_32_2nd (Dens (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_32_2nd (Dens (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_32 (De (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 31,233\n",
      "Trainable params: 31,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstacked_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_stacked_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36mModel_Stacking2.optimize_stacked_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     53\u001b[0m h \u001b[38;5;241m=\u001b[39m hyp_opt\u001b[38;5;241m.\u001b[39mHyperparameter_Optimization([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_x], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_y], model, loss_fn, activation_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, initializer_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 54\u001b[0m best_lr, best_batch_size, _, best_initializer \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_initializer)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(model, best_initializer)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:107\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.get_best_hyperparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m initializer \u001b[38;5;129;01min\u001b[39;00m intializer_list[i]:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(initializer_str\u001b[38;5;241m=\u001b[39minitializer)\n\u001b[0;32m--> 107\u001b[0m     lr, batch_size, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_batch_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(best_loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m loss\u001b[38;5;241m<\u001b[39mbest_loss):\n\u001b[1;32m    109\u001b[0m         best_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:134\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.lr_batch_optimization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m     best_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lr_opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     best_lr, best_batch_size, best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_batch_size_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_lr, best_batch_size, best_loss\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:78\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.get_best_batch_size_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m best_loss_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m batch_size_list:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# print(f\"\\nSETTING BATCH SIZE TO {batch_size}\")\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     best_lr_batch, best_loss_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     best_lr_list\u001b[38;5;241m.\u001b[39mappend(best_lr_batch)\n\u001b[1;32m     80\u001b[0m     best_loss_list\u001b[38;5;241m.\u001b[39mappend(best_loss_batch)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:62\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.get_best_lr\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_fn, optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[1;32m     61\u001b[0m lr_schedule \u001b[38;5;241m=\u001b[39m LearningRateScheduler(\u001b[38;5;28;01mlambda\u001b[39;00m epoch : \u001b[38;5;241m1e-5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(epoch\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m---> 62\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mlr_schedule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Select best Learning Rate\u001b[39;00m\n\u001b[1;32m     65\u001b[0m lrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(epoch)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    885\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   _, _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    891\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    892\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2941\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2938\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m   2939\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2940\u001b[0m   (graph_function,\n\u001b[0;32m-> 2941\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m   2943\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:966\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 966\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m      \u001b[49m\u001b[43moriginal_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConversionOptions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m          \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m          \u001b[49m\u001b[43moptional_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m          \u001b[49m\u001b[43muser_requested\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/tmp6ayk0_jj.py:16\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:350\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    349\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 350\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    353\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:479\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    792\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m    794\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iterator)\n\u001b[0;32m--> 795\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    797\u001b[0m     outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    798\u001b[0m write_scalar_summaries(outputs, step\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_train_counter)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m   1255\u001b[0m   \u001b[38;5;66;03m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m   \u001b[38;5;66;03m# applied when when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   1258\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1259\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m   kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2729\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2730\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_for_each_replica\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_for_each_replica\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3416\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ReplicaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 3417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:667\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 667\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    669\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:396\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    393\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 396\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:478\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    475\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(data):\n\u001b[0;32m--> 788\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    789\u001b[0m   \u001b[38;5;66;03m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:754\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    751\u001b[0m x, y, sample_weight \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39munpack_x_y_sample_weight(data)\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backprop\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m--> 754\u001b[0m   y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_loss(\n\u001b[1;32m    756\u001b[0m       y, y_pred, sample_weight, regularization_losses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses)\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mminimize(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables, tape\u001b[38;5;241m=\u001b[39mtape)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1015\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:424\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    407\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \n\u001b[1;32m    409\u001b[0m \u001b[38;5;124;03m  In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py:560\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    557\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[0;32m--> 560\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39mflat_output_ids, nest\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1012\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1008\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1015\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/layers/core.py:1207\u001b[0m, in \u001b[0;36mDense.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m-> 1207\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_dtype_object\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/layers/ops/core.py:53\u001b[0m, in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m sparse_ops\u001b[38;5;241m.\u001b[39msparse_tensor_dense_matmul(inputs, kernel)\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmat_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Broadcast kernel to inputs.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m standard_ops\u001b[38;5;241m.\u001b[39mtensordot(inputs, kernel, [[rank \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:5548\u001b[0m, in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m   transpose_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   5547\u001b[0m transpose_b \u001b[38;5;241m=\u001b[39m _execute\u001b[38;5;241m.\u001b[39mmake_bool(transpose_b, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose_b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 5548\u001b[0m _, _, _op, _outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_op_def_library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_op_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5549\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMatMul\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranspose_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5550\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5551\u001b[0m _result \u001b[38;5;241m=\u001b[39m _outputs[:]\n\u001b[1;32m   5552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _execute\u001b[38;5;241m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:699\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    696\u001b[0m   attr_protos[key] \u001b[38;5;241m=\u001b[39m attr_value\n\u001b[1;32m    697\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m attr_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_to_attr_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_def\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr_def\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist(\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    701\u001b[0m   _SatisfiesLengthConstraint(\u001b[38;5;28mlen\u001b[39m(value), attr_def, key, op_type_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:803\u001b[0m, in \u001b[0;36mvalue_to_attr_value\u001b[0;34m(value, attr_type, arg_name)\u001b[0m\n\u001b[1;32m    801\u001b[0m   attr_value\u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m.\u001b[39mextend([_MakeBool(x, arg_name) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m value])\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attr_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 803\u001b[0m   attr_value\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m \u001b[43m_MakeType\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attr_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist(type)\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    805\u001b[0m   attr_value\u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mextend([_MakeType(x, arg_name) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m value])\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:198\u001b[0m, in \u001b[0;36m_MakeType\u001b[0;34m(v, arg_name)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_MakeType\u001b[39m(v, arg_name):\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbase_dtype\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected DataType for argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    201\u001b[0m                     (arg_name, \u001b[38;5;28mrepr\u001b[39m(v)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stacked_models.optimize_stacked_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"/home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_64/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selu\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "activation = model.layers[-2].get_config()[\"activation\"]\n",
    "print(activation)\n",
    "print(type(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_64  (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,641\n",
      "Trainable params: 8,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_64_64_64_reduced\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "=================================================================\n",
      "Total params: 8,576\n",
      "Trainable params: 8,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reduce_model = Model(name = model.name+\"_reduced\", inputs = model.input, outputs = model.layers[-2].output)\n",
    "print(reduce_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Flatten, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = Sequential()\n",
    "# new_model.add(Dropout(0.1))\n",
    "# new_model.add(reduce_model)\n",
    "# new_model.add(Dropout(0.2))\n",
    "# new_model.add(Dense(1024, activation = activation))\n",
    "# new_model.add(Dense(1024, activation = activation))\n",
    "# new_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = reduce_model.output\n",
    "x = last_layer\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1024, activation = activation)(x)\n",
    "x = Dense(1024, activation = activation)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(1)(x)\n",
    "new_model = Model(inputs = reduce_model.input, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_64_64 ( [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_326 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_327 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,125,761\n",
      "Trainable params: 1,125,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7]\n"
     ]
    }
   ],
   "source": [
    "dropout_ind = []\n",
    "ind = 0\n",
    "for layer in new_model.layers:\n",
    "    if layer.__class__.__name__ == \"Dropout\":\n",
    "        dropout_ind.append(ind)\n",
    "    ind = ind+1\n",
    "print(dropout_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.layers[4].rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.layers[4].rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 2)\n",
      "(63, 1) (63,)\n",
      "(42, 1) (21, 1) (42,) (21,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load the sonar dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "print(dataframe.shape)\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "data = data.astype('float32')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  564.4772338867188 , TEST :  696.4302978515625\n",
      "output_layer_dense_32_32_loss  :  77.97647094726562 , TEST :  102.96764373779297\n",
      "output_layer_dense_32_64_loss  :  72.4428939819336 , TEST :  94.78680419921875\n",
      "output_layer_dense_32_128_loss  :  43.49039840698242 , TEST :  50.427490234375\n",
      "output_layer_dense_32_1024_loss  :  32.640380859375 , TEST :  31.093881607055664\n",
      "output_layer_dense_64_32_loss  :  68.5215072631836 , TEST :  88.98941802978516\n",
      "output_layer_dense_64_64_loss  :  67.38311004638672 , TEST :  87.2926254272461\n",
      "output_layer_dense_64_128_loss  :  41.06880569458008 , TEST :  45.563011169433594\n",
      "output_layer_dense_64_1024_loss  :  32.03666687011719 , TEST :  28.78836441040039\n",
      "output_layer_dense_128_32_loss  :  72.19493103027344 , TEST :  94.40507507324219\n",
      "output_layer_dense_128_64_loss  :  56.72202682495117 , TEST :  72.11593627929688\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  204.6041717529297 , TEST :  193.50648498535156\n",
      "output_layer_dense_128_128_loss  :  43.74370574951172 , TEST :  50.91599655151367\n",
      "output_layer_dense_128_1024_loss  :  31.940673828125 , TEST :  27.309024810791016\n",
      "output_layer_dense_1024_32_loss  :  31.918380737304688 , TEST :  27.996408462524414\n",
      "output_layer_dense_1024_64_loss  :  33.159645080566406 , TEST :  34.39208984375\n",
      "output_layer_dense_1024_128_loss  :  31.97357177734375 , TEST :  25.20755386352539\n",
      "output_layer_dense_1024_1024_loss  :  31.868175506591797 , TEST :  27.685407638549805\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  396.1885681152344 , TEST :  412.23150634765625\n",
      "output_layer_dense_32_32_32_loss  :  67.75357818603516 , TEST :  87.86875915527344\n",
      "output_layer_dense_32_32_64_loss  :  55.70736312866211 , TEST :  70.67930603027344\n",
      "output_layer_dense_32_32_128_loss  :  33.16255569458008 , TEST :  25.683181762695312\n",
      "output_layer_dense_32_32_1024_loss  :  32.28651809692383 , TEST :  29.9041805267334\n",
      "output_layer_dense_32_64_32_loss  :  35.29856872558594 , TEST :  32.24654006958008\n",
      "output_layer_dense_32_64_64_loss  :  43.165130615234375 , TEST :  49.84916305541992\n",
      "output_layer_dense_32_64_128_loss  :  32.039371490478516 , TEST :  28.813858032226562\n",
      "output_layer_dense_32_64_1024_loss  :  31.844669342041016 , TEST :  27.289440155029297\n",
      "output_layer_dense_32_128_32_loss  :  31.92618179321289 , TEST :  27.147016525268555\n",
      "output_layer_dense_32_128_64_loss  :  33.00459671020508 , TEST :  32.75004959106445\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0a203ec700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  400.072998046875 , TEST :  415.59356689453125\n",
      "output_layer_dense_32_128_128_loss  :  33.348819732666016 , TEST :  35.67073440551758\n",
      "output_layer_dense_32_128_1024_loss  :  31.862337112426758 , TEST :  26.892961502075195\n",
      "output_layer_dense_32_1024_32_loss  :  32.63373565673828 , TEST :  31.09195327758789\n",
      "output_layer_dense_32_1024_64_loss  :  31.856761932373047 , TEST :  26.121145248413086\n",
      "output_layer_dense_32_1024_128_loss  :  31.77286148071289 , TEST :  26.318124771118164\n",
      "output_layer_dense_32_1024_1024_loss  :  31.885509490966797 , TEST :  25.188533782958984\n",
      "output_layer_dense_64_32_32_loss  :  63.9492301940918 , TEST :  82.36168670654297\n",
      "output_layer_dense_64_64_32_loss  :  72.885009765625 , TEST :  95.42500305175781\n",
      "output_layer_dense_64_64_64_loss  :  37.93951416015625 , TEST :  38.811222076416016\n",
      "output_layer_dense_64_64_128_loss  :  31.939241409301758 , TEST :  27.71219825744629\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d9f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  327.50689697265625 , TEST :  299.78814697265625\n",
      "output_layer_dense_64_64_1024_loss  :  31.8554630279541 , TEST :  25.88766098022461\n",
      "output_layer_dense_64_128_32_loss  :  31.906051635742188 , TEST :  25.64059066772461\n",
      "output_layer_dense_64_128_64_loss  :  33.201045989990234 , TEST :  34.193389892578125\n",
      "output_layer_dense_64_128_128_loss  :  32.75349426269531 , TEST :  31.522672653198242\n",
      "output_layer_dense_64_128_1024_loss  :  31.98941421508789 , TEST :  28.798473358154297\n",
      "output_layer_dense_64_1024_32_loss  :  33.3077278137207 , TEST :  35.31038284301758\n",
      "output_layer_dense_64_1024_64_loss  :  31.882036209106445 , TEST :  26.396068572998047\n",
      "output_layer_dense_64_1024_128_loss  :  32.024383544921875 , TEST :  28.8597354888916\n",
      "output_layer_dense_64_1024_1024_loss  :  31.849613189697266 , TEST :  27.19002914428711\n",
      "output_layer_dense_128_32_32_loss  :  36.737648010253906 , TEST :  35.98911666870117\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09813ad0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  342.26483154296875 , TEST :  328.2178039550781\n",
      "output_layer_dense_128_64_32_loss  :  48.028038024902344 , TEST :  58.27384567260742\n",
      "output_layer_dense_128_64_64_loss  :  35.14159393310547 , TEST :  31.83365821838379\n",
      "output_layer_dense_128_128_32_loss  :  33.40260696411133 , TEST :  35.939876556396484\n",
      "output_layer_dense_128_128_64_loss  :  33.0523796081543 , TEST :  33.2486572265625\n",
      "output_layer_dense_128_128_128_loss  :  32.45167922973633 , TEST :  30.385448455810547\n",
      "output_layer_dense_128_128_1024_loss  :  32.060020446777344 , TEST :  29.12714195251465\n",
      "output_layer_dense_128_1024_32_loss  :  32.3466796875 , TEST :  25.076053619384766\n",
      "output_layer_dense_128_1024_64_loss  :  31.98933982849121 , TEST :  28.839698791503906\n",
      "output_layer_dense_128_1024_128_loss  :  31.976551055908203 , TEST :  28.71439552307129\n",
      "output_layer_dense_128_1024_1024_loss  :  31.815929412841797 , TEST :  26.779003143310547\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  333.677490234375 , TEST :  306.97418212890625\n",
      "output_layer_dense_1024_32_32_loss  :  44.59679412841797 , TEST :  52.55773162841797\n",
      "output_layer_dense_1024_64_32_loss  :  33.508392333984375 , TEST :  36.54766082763672\n",
      "output_layer_dense_1024_64_64_loss  :  31.81412124633789 , TEST :  26.398746490478516\n",
      "output_layer_dense_1024_128_32_loss  :  32.89533233642578 , TEST :  32.505619049072266\n",
      "output_layer_dense_1024_128_64_loss  :  31.82064437866211 , TEST :  26.59869384765625\n",
      "output_layer_dense_1024_128_128_loss  :  31.81867027282715 , TEST :  26.49064064025879\n",
      "output_layer_dense_1024_1024_32_loss  :  31.895700454711914 , TEST :  27.852462768554688\n",
      "output_layer_dense_1024_1024_64_loss  :  31.739051818847656 , TEST :  26.053115844726562\n",
      "output_layer_dense_1024_1024_128_loss  :  31.811500549316406 , TEST :  26.66451072692871\n",
      "output_layer_dense_1024_1024_1024_loss  :  31.777271270751953 , TEST :  25.304996490478516\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "[{'model_name': 'dense_128_1024_32', 'score': 25.076053619384766, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_1024_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 128, 'layer2': 1024, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d1a7f0>}, {'model_name': 'dense_32_1024_1024', 'score': 25.188533782958984, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0988425a60>}, {'model_name': 'dense_1024_128', 'score': 25.20755386352539, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_128', 'model_conf': ['', 1, 2, 'relu', {'layer1': 1024, 'layer2': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d68220>}, {'model_name': 'dense_1024_1024_1024', 'score': 25.304996490478516, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f09807cc700>}, {'model_name': 'dense_64_128_32', 'score': 25.64059066772461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f098195ac70>}, {'model_name': 'dense_32_32_128', 'score': 25.683181762695312, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0980615580>}, {'model_name': 'dense_64_64_1024', 'score': 25.88766098022461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983a2b160>}, {'model_name': 'dense_1024_1024_64', 'score': 26.053115844726562, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983c1efa0>}, {'model_name': 'dense_32_1024_64', 'score': 26.121145248413086, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad7550>}, {'model_name': 'dense_32_1024_128', 'score': 26.318124771118164, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad70a0>}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_128_1024_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_128_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_32_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_64_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_128/assets\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Time Taken :  20.406763076782227\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 1, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = True)\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : dense_128_1024_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.345319747924805, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.02512, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981bbd700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.84622573852539, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00158, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0983e43d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.873470306396484 , TEST :  24.018808364868164\n",
      "Model Name : dense_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.384897232055664, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098847c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  32.86589050292969 , TEST :  32.15849685668945\n",
      "Model Name : dense_1024_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.181747436523438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098167b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.778873443603516 , TEST :  28.295467376708984\n",
      "Model Name : dense_64_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.6921329498291, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00398, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09838ab790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.848989486694336 , TEST :  24.678855895996094\n",
      "Model Name : dense_32_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.34592628479004, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fd4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.671247482299805 , TEST :  28.42959213256836\n",
      "Model Name : dense_64_64_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.222423553466797, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882c7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.99043846130371 , TEST :  26.99068832397461\n",
      "Model Name : dense_1024_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 27.45450210571289, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01585, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d19a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.205533981323242, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981f60b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.2604923248291 , TEST :  26.66190528869629\n",
      "Model Name : dense_32_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.960067749023438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.002, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09884280d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.737110137939453 , TEST :  25.75638198852539\n"
     ]
    }
   ],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list)\n",
    "opt.optimize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-GljDEx7Q8i"
   },
   "outputs": [],
   "source": [
    "search = StructuredDataRegressor(max_trials=15, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CF1WqFSj7TAN",
    "outputId": "022c0fdf-8cfd-45ed-ddce-e183911b0e99"
   },
   "outputs": [],
   "source": [
    "search.fit(x=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pJvdP_eb7vYp",
    "outputId": "15a9315a-a61d-4a11-ba0e-467eaafd7415"
   },
   "outputs": [],
   "source": [
    "train_mae, _ = search.evaluate(X_train, y_train, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(train_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ESltODdC8AO0",
    "outputId": "30d0352d-1ed0-40ca-bbe0-cfe17fe836cb"
   },
   "outputs": [],
   "source": [
    "test_mae, _ = search.evaluate(X_test, y_test, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vi_KQC2K8pzs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autokeras-regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
