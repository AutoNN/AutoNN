{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/anish/ASC_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 17:59:32.210846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from ASC_ML import dataframe_extractor as de\n",
    "from ASC_ML import model_generation as model_gen\n",
    "from ASC_ML import model_gen_train_test as testing\n",
    "from dask_ml.preprocessing import LabelEncoder\n",
    "# from dask_ml.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASC_ML import multiple_model_gen_v1 as multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "# import pandas as pd\n",
    "# data = dd.from_pandas(pd.Series(['a', 'a', 'b'], dtype='category'),\n",
    "#                      npartitions=1)\n",
    "# le = LabelEncoder()\n",
    "# le.fit_transform(data).compute()\n",
    "# print(type(le.fit_transform(data).compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading single csv from /home/anish/ASC-ML-EXP-DATASETS/LinReg-tabular/house-prices-advanced-regression-techniques/train.csv\n",
      "Train Dataset X Columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1.0        60.0       RL         65.0   8450.0   Pave   NaN      Reg   \n",
       "1  2.0        20.0       RL         80.0   9600.0   Pave   NaN      Reg   \n",
       "2  3.0        60.0       RL         68.0  11250.0   Pave   NaN      IR1   \n",
       "3  4.0        70.0       RL         60.0   9550.0   Pave   NaN      IR1   \n",
       "4  5.0        60.0       RL         84.0  14260.0   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "1         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "2         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "3         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "4         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0     0.0    2.0  2008.0        WD         Normal  \n",
       "1     0.0    5.0  2007.0        WD         Normal  \n",
       "2     0.0    9.0  2008.0        WD         Normal  \n",
       "3     0.0    2.0  2006.0        WD        Abnorml  \n",
       "4     0.0   12.0  2008.0        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For House Prediction Dataset https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data?select=train.csv\n",
    "directory1 = \"/home/anish/ASC-ML-EXP-DATASETS/LinReg-tabular/house-prices-advanced-regression-techniques/train.csv\"\n",
    "\n",
    "\n",
    "# returns list of dask dataframe [singular_df_x, singular_df_y] or [train_df_x, train_df_y, test_df_x, test_df_y]\n",
    "dataset_list = de.DataframeExtractor_csv(directory1, label_names = [\"SalePrice\"]).df_list\n",
    "\n",
    "print(\"Train Dataset X Columns\")\n",
    "dataset_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice\n",
       "0   208500.0\n",
       "1   181500.0\n",
       "2   223500.0\n",
       "3   140000.0\n",
       "4   250000.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dataset_list[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1.0        60.0       RL         65.0   8450.0   Pave     0      Reg   \n",
       "1  2.0        20.0       RL         80.0   9600.0   Pave     0      Reg   \n",
       "2  3.0        60.0       RL         68.0  11250.0   Pave     0      IR1   \n",
       "3  4.0        70.0       RL         60.0   9550.0   Pave     0      IR1   \n",
       "4  5.0        60.0       RL         84.0  14260.0   Pave     0      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "1         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "2         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "3         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "4         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0     0.0    2.0  2008.0        WD         Normal  \n",
       "1     0.0    5.0  2007.0        WD         Normal  \n",
       "2     0.0    9.0  2008.0        WD         Normal  \n",
       "3     0.0    2.0  2006.0        WD        Abnorml  \n",
       "4     0.0   12.0  2008.0        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/dask/dataframe/core.py:3946: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('MSSubClass', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1.0       60.0       RL         65.0   8450.0   Pave     0      Reg   \n",
       "1  2.0       20.0       RL         80.0   9600.0   Pave     0      Reg   \n",
       "2  3.0       60.0       RL         68.0  11250.0   Pave     0      IR1   \n",
       "3  4.0       70.0       RL         60.0   9550.0   Pave     0      IR1   \n",
       "4  5.0       60.0       RL         84.0  14260.0   Pave     0      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "1         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "2         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "3         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "4         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "\n",
       "  MiscVal MoSold  YrSold SaleType  SaleCondition  \n",
       "0     0.0    2.0  2008.0       WD         Normal  \n",
       "1     0.0    5.0  2007.0       WD         Normal  \n",
       "2     0.0    9.0  2008.0       WD         Normal  \n",
       "3     0.0    2.0  2006.0       WD        Abnorml  \n",
       "4     0.0   12.0  2008.0       WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['MSSubClass'] = train_x['MSSubClass'].apply(str)\n",
    "\n",
    "train_x['OverallCond'] = train_x['OverallCond'].astype(str)\n",
    "\n",
    "train_x['YrSold'] = train_x['YrSold'].astype(str)\n",
    "train_x['MoSold'] = train_x['MoSold'].astype(str)\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = train_x['LotShape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder() \n",
    "# le.fit_transform(a).compute()\n",
    "# train_x['LotShape'] = le.fit_transform(train_x['LotShape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyval(allkeys):\n",
    "    i = 0\n",
    "    keyvalpairs = list()\n",
    "    for key in allkeys:\n",
    "        keyvalpairs.append((key,i))\n",
    "        i+=1\n",
    "    return dict(keyvalpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['FireplaceQu', 'LotShape']\n",
    "cols = ['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold']\n",
    "keys = {}\n",
    "for col in cols:\n",
    "    key = train_x[col].unique()\n",
    "    keyvalpairs = keyval(key)\n",
    "    keys.update({col:keyvalpairs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FireplaceQu': {0: 0, 'TA': 1, 'Gd': 2, 'Fa': 3, 'Ex': 4, 'Po': 5},\n",
       " 'BsmtQual': {'Gd': 0, 'TA': 1, 'Ex': 2, 0: 3, 'Fa': 4},\n",
       " 'BsmtCond': {'TA': 0, 'Gd': 1, 0: 2, 'Fa': 3, 'Po': 4},\n",
       " 'GarageQual': {'TA': 0, 'Fa': 1, 'Gd': 2, 0: 3, 'Ex': 4, 'Po': 5},\n",
       " 'GarageCond': {'TA': 0, 'Fa': 1, 0: 2, 'Gd': 3, 'Po': 4, 'Ex': 5},\n",
       " 'ExterQual': {'Gd': 0, 'TA': 1, 'Ex': 2, 'Fa': 3},\n",
       " 'ExterCond': {'TA': 0, 'Gd': 1, 'Fa': 2, 'Po': 3, 'Ex': 4},\n",
       " 'HeatingQC': {'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4},\n",
       " 'PoolQC': {0: 0, 'Ex': 1, 'Fa': 2, 'Gd': 3},\n",
       " 'KitchenQual': {'Gd': 0, 'TA': 1, 'Ex': 2, 'Fa': 3},\n",
       " 'BsmtFinType1': {'GLQ': 0,\n",
       "  'ALQ': 1,\n",
       "  'Unf': 2,\n",
       "  'Rec': 3,\n",
       "  'BLQ': 4,\n",
       "  0: 5,\n",
       "  'LwQ': 6},\n",
       " 'BsmtFinType2': {'Unf': 0,\n",
       "  'BLQ': 1,\n",
       "  0: 2,\n",
       "  'ALQ': 3,\n",
       "  'Rec': 4,\n",
       "  'LwQ': 5,\n",
       "  'GLQ': 6},\n",
       " 'Functional': {'Typ': 0,\n",
       "  'Min1': 1,\n",
       "  'Maj1': 2,\n",
       "  'Min2': 3,\n",
       "  'Mod': 4,\n",
       "  'Maj2': 5,\n",
       "  'Sev': 6},\n",
       " 'Fence': {0: 0, 'MnPrv': 1, 'GdWo': 2, 'GdPrv': 3, 'MnWw': 4},\n",
       " 'BsmtExposure': {'No': 0, 'Gd': 1, 'Mn': 2, 'Av': 3, 0: 4},\n",
       " 'GarageFinish': {'RFn': 0, 'Unf': 1, 'Fin': 2, 0: 3},\n",
       " 'LandSlope': {'Gtl': 0, 'Mod': 1, 'Sev': 2},\n",
       " 'LotShape': {'Reg': 0, 'IR1': 1, 'IR2': 2, 'IR3': 3},\n",
       " 'PavedDrive': {'Y': 0, 'N': 1, 'P': 2},\n",
       " 'Street': {'Pave': 0, 'Grvl': 1},\n",
       " 'Alley': {0: 0, 'Grvl': 1, 'Pave': 2},\n",
       " 'CentralAir': {'Y': 0, 'N': 1},\n",
       " 'MSSubClass': {'60.0': 0,\n",
       "  '20.0': 1,\n",
       "  '70.0': 2,\n",
       "  '50.0': 3,\n",
       "  '190.0': 4,\n",
       "  '45.0': 5,\n",
       "  '90.0': 6,\n",
       "  '120.0': 7,\n",
       "  '30.0': 8,\n",
       "  '85.0': 9,\n",
       "  '80.0': 10,\n",
       "  '160.0': 11,\n",
       "  '75.0': 12,\n",
       "  '180.0': 13,\n",
       "  '40.0': 14},\n",
       " 'OverallCond': {'5.0': 0,\n",
       "  '8.0': 1,\n",
       "  '6.0': 2,\n",
       "  '7.0': 3,\n",
       "  '4.0': 4,\n",
       "  '2.0': 5,\n",
       "  '3.0': 6,\n",
       "  '9.0': 7,\n",
       "  '1.0': 8},\n",
       " 'YrSold': {'2008.0': 0, '2007.0': 1, '2006.0': 2, '2009.0': 3, '2010.0': 4},\n",
       " 'MoSold': {'2.0': 0,\n",
       "  '5.0': 1,\n",
       "  '9.0': 2,\n",
       "  '12.0': 3,\n",
       "  '10.0': 4,\n",
       "  '8.0': 5,\n",
       "  '11.0': 6,\n",
       "  '4.0': 7,\n",
       "  '1.0': 8,\n",
       "  '7.0': 9,\n",
       "  '3.0': 10,\n",
       "  '6.0': 11}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_x.replace(keys).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['FireplaceQu'].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
       "0  1.0           0       RL         65.0   8450.0       0      0         0   \n",
       "1  2.0           1       RL         80.0   9600.0       0      0         0   \n",
       "2  3.0           0       RL         68.0  11250.0       0      0         1   \n",
       "3  4.0           2       RL         60.0   9550.0       0      0         1   \n",
       "4  5.0           0       RL         84.0  14260.0       0      0         1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch  PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "1         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "2         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "3         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "4         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0     0.0      0       0        WD         Normal  \n",
       "1     0.0      1       1        WD         Normal  \n",
       "2     0.0      2       0        WD         Normal  \n",
       "3     0.0      0       2        WD        Abnorml  \n",
       "4     0.0      3       0        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = []\n",
    "for col in train_X.columns:\n",
    "#     print(type(col))\n",
    "    try:\n",
    "        a = train_X[col].astype(float).compute()\n",
    "    except ValueError:\n",
    "#         print('Couldn\\'t covert %s to float' % col)\n",
    "        cols_to_remove.append(col)\n",
    "        pass\n",
    "\n",
    "# keep only the columns in df that do not contain string\n",
    "train_X = train_X[[col for col in train_X.columns if col not in cols_to_remove]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'LandContour', 'Utilities', 'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'Electrical', 'GarageType', 'MiscFeature', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "print(cols_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.drop([\"Id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsklearn.preprocessing.MinMaxScalerrain_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_list[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_X)\n",
    "train_X_scaled = scaler_x.transform(train_X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(dataset_list[1])\n",
    "train_Y_scaled = scaler_y.transform(dataset_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = train_X.columns.to_list()\n",
    "# scaler_d = MinMaxScaler()\n",
    "# train_X.columns = list(train_X.columns)\n",
    "# scaled_train_X = scaler_d.fit_transform(train_X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.20766773, 0.0334198 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07142857, 0.25559105, 0.03879502, ..., 0.        , 0.09090909,\n",
       "        0.25      ],\n",
       "       [0.        , 0.2172524 , 0.04650728, ..., 0.        , 0.18181818,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.14285714, 0.21086262, 0.03618687, ..., 0.16129032, 0.09090909,\n",
       "        1.        ],\n",
       "       [0.07142857, 0.2172524 , 0.03934189, ..., 0.        , 0.63636364,\n",
       "        1.        ],\n",
       "       [0.07142857, 0.23961661, 0.04037019, ..., 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_scaled\n",
    "# train_Y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = testing.Model_Parallel_Train_Test(train_X_scaled, train_Y_scaled, 58, 1, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ASC_ML.model_gen_train_test.Model_Parallel_Train_Test at 0x7efd1a00d640>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_dense_4_4_4 (InputL [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_8_8_8 (InputL [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_16_16_16 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_32_32_32 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_64_64_64 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_128_128_128 ( [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_4_4_4 (Dense)      (None, 4)            236         input_layer_dense_4_4_4[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_8_8_8 (Dense)      (None, 8)            472         input_layer_dense_8_8_8[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_16_16_16 (Dense)   (None, 16)           944         input_layer_dense_16_16_16[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_32_32_32 (Dense)   (None, 32)           1888        input_layer_dense_32_32_32[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_64_64_64 (Dense)   (None, 64)           3776        input_layer_dense_64_64_64[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_128_128_128 (Dense (None, 128)          7552        input_layer_dense_128_128_128[0][\n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_4_4_4 (Dense)      (None, 4)            20          layer1_dense_4_4_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_8_8_8 (Dense)      (None, 8)            72          layer1_dense_8_8_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_16_16_16 (Dense)   (None, 16)           272         layer1_dense_16_16_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_32_32_32 (Dense)   (None, 32)           1056        layer1_dense_32_32_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_64_64_64 (Dense)   (None, 64)           4160        layer1_dense_64_64_64[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_128_128_128 (Dense (None, 128)          16512       layer1_dense_128_128_128[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_4_4_4 (Dense)      (None, 4)            20          layer2_dense_4_4_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_8_8_8 (Dense)      (None, 8)            72          layer2_dense_8_8_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_16_16_16 (Dense)   (None, 16)           272         layer2_dense_16_16_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_32_32_32 (Dense)   (None, 32)           1056        layer2_dense_32_32_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_64_64_64 (Dense)   (None, 64)           4160        layer2_dense_64_64_64[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_128_128_128 (Dense (None, 128)          16512       layer2_dense_128_128_128[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_4_4_4 (Dense (None, 1)            5           layer3_dense_4_4_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_8_8_8 (Dense (None, 1)            9           layer3_dense_8_8_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_16_16_16 (De (None, 1)            17          layer3_dense_16_16_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_32_32_32 (De (None, 1)            33          layer3_dense_32_32_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_64_64_64 (De (None, 1)            65          layer3_dense_64_64_64[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_128_128_128  (None, 1)            129         layer3_dense_128_128_128[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 59,310\n",
      "Trainable params: 59,310\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 17:59:42.486473: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-15 17:59:42.486699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-15 17:59:42.487084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 17:59:42.487820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-06-15 17:59:42.487926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-15 17:59:42.492615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-15 17:59:42.492753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-15 17:59:42.495920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-15 17:59:42.496503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-15 17:59:42.499503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-15 17:59:42.500902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-15 17:59:42.505976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-15 17:59:42.506131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 17:59:42.506397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 17:59:42.506554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-15 17:59:42.506981: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-15 17:59:42.507319: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-15 17:59:42.507459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 17:59:42.507643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-06-15 17:59:42.507684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-15 17:59:42.507718: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-15 17:59:42.507749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-15 17:59:42.507779: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-15 17:59:42.507809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-15 17:59:42.507839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-15 17:59:42.507871: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-15 17:59:42.507902: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-15 17:59:42.507985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 17:59:42.508208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 17:59:42.508360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-15 17:59:42.508418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-15 17:59:42.902497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-15 17:59:42.902522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-06-15 17:59:42.902527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-06-15 17:59:42.902680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 17:59:42.902827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 17:59:42.902941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-15 17:59:42.903034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5030 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "model = TRAIN.get_models()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 17:59:43.214602: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-15 17:59:43.231674: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/12 [=>............................] - ETA: 14s - loss: 0.4101 - output_layer_dense_4_4_4_loss: 0.0532 - output_layer_dense_8_8_8_loss: 0.0216 - output_layer_dense_16_16_16_loss: 0.1793 - output_layer_dense_32_32_32_loss: 0.0509 - output_layer_dense_64_64_64_loss: 0.0424 - output_layer_dense_128_128_128_loss: 0.0627 - output_layer_dense_4_4_4_mean_absolute_error: 0.1984 - output_layer_dense_8_8_8_mean_absolute_error: 0.1098 - output_layer_dense_16_16_16_mean_absolute_error: 0.3899 - output_layer_dense_32_32_32_mean_absolute_error: 0.1947 - output_layer_dense_64_64_64_mean_absolute_error: 0.1741 - output_layer_dense_128_128_128_mean_absolute_error: 0.2140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 17:59:44.431961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 4ms/step - loss: 0.2792 - output_layer_dense_4_4_4_loss: 0.0473 - output_layer_dense_8_8_8_loss: 0.0166 - output_layer_dense_16_16_16_loss: 0.1401 - output_layer_dense_32_32_32_loss: 0.0276 - output_layer_dense_64_64_64_loss: 0.0189 - output_layer_dense_128_128_128_loss: 0.0287 - output_layer_dense_4_4_4_mean_absolute_error: 0.1854 - output_layer_dense_8_8_8_mean_absolute_error: 0.0962 - output_layer_dense_16_16_16_mean_absolute_error: 0.3356 - output_layer_dense_32_32_32_mean_absolute_error: 0.1301 - output_layer_dense_64_64_64_mean_absolute_error: 0.1050 - output_layer_dense_128_128_128_mean_absolute_error: 0.1304\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.1045 - output_layer_dense_4_4_4_loss: 0.0288 - output_layer_dense_8_8_8_loss: 0.0111 - output_layer_dense_16_16_16_loss: 0.0438 - output_layer_dense_32_32_32_loss: 0.0093 - output_layer_dense_64_64_64_loss: 0.0064 - output_layer_dense_128_128_128_loss: 0.0053 - output_layer_dense_4_4_4_mean_absolute_error: 0.1312 - output_layer_dense_8_8_8_mean_absolute_error: 0.0749 - output_layer_dense_16_16_16_mean_absolute_error: 0.1643 - output_layer_dense_32_32_32_mean_absolute_error: 0.0733 - output_layer_dense_64_64_64_mean_absolute_error: 0.0581 - output_layer_dense_128_128_128_mean_absolute_error: 0.0506\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0541 - output_layer_dense_4_4_4_loss: 0.0148 - output_layer_dense_8_8_8_loss: 0.0084 - output_layer_dense_16_16_16_loss: 0.0153 - output_layer_dense_32_32_32_loss: 0.0068 - output_layer_dense_64_64_64_loss: 0.0043 - output_layer_dense_128_128_128_loss: 0.0045 - output_layer_dense_4_4_4_mean_absolute_error: 0.0828 - output_layer_dense_8_8_8_mean_absolute_error: 0.0660 - output_layer_dense_16_16_16_mean_absolute_error: 0.0933 - output_layer_dense_32_32_32_mean_absolute_error: 0.0547 - output_layer_dense_64_64_64_mean_absolute_error: 0.0466 - output_layer_dense_128_128_128_mean_absolute_error: 0.0473\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0412 - output_layer_dense_4_4_4_loss: 0.0101 - output_layer_dense_8_8_8_loss: 0.0074 - output_layer_dense_16_16_16_loss: 0.0122 - output_layer_dense_32_32_32_loss: 0.0054 - output_layer_dense_64_64_64_loss: 0.0033 - output_layer_dense_128_128_128_loss: 0.0028 - output_layer_dense_4_4_4_mean_absolute_error: 0.0748 - output_layer_dense_8_8_8_mean_absolute_error: 0.0620 - output_layer_dense_16_16_16_mean_absolute_error: 0.0836 - output_layer_dense_32_32_32_mean_absolute_error: 0.0533 - output_layer_dense_64_64_64_mean_absolute_error: 0.0411 - output_layer_dense_128_128_128_mean_absolute_error: 0.0363\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0399 - output_layer_dense_4_4_4_loss: 0.0101 - output_layer_dense_8_8_8_loss: 0.0076 - output_layer_dense_16_16_16_loss: 0.0101 - output_layer_dense_32_32_32_loss: 0.0058 - output_layer_dense_64_64_64_loss: 0.0033 - output_layer_dense_128_128_128_loss: 0.0030 - output_layer_dense_4_4_4_mean_absolute_error: 0.0743 - output_layer_dense_8_8_8_mean_absolute_error: 0.0609 - output_layer_dense_16_16_16_mean_absolute_error: 0.0685 - output_layer_dense_32_32_32_mean_absolute_error: 0.0494 - output_layer_dense_64_64_64_mean_absolute_error: 0.0377 - output_layer_dense_128_128_128_mean_absolute_error: 0.0362\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0322 - output_layer_dense_4_4_4_loss: 0.0087 - output_layer_dense_8_8_8_loss: 0.0063 - output_layer_dense_16_16_16_loss: 0.0078 - output_layer_dense_32_32_32_loss: 0.0046 - output_layer_dense_64_64_64_loss: 0.0025 - output_layer_dense_128_128_128_loss: 0.0023 - output_layer_dense_4_4_4_mean_absolute_error: 0.0689 - output_layer_dense_8_8_8_mean_absolute_error: 0.0552 - output_layer_dense_16_16_16_mean_absolute_error: 0.0589 - output_layer_dense_32_32_32_mean_absolute_error: 0.0459 - output_layer_dense_64_64_64_mean_absolute_error: 0.0343 - output_layer_dense_128_128_128_mean_absolute_error: 0.0330\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0275 - output_layer_dense_4_4_4_loss: 0.0079 - output_layer_dense_8_8_8_loss: 0.0055 - output_layer_dense_16_16_16_loss: 0.0063 - output_layer_dense_32_32_32_loss: 0.0040 - output_layer_dense_64_64_64_loss: 0.0021 - output_layer_dense_128_128_128_loss: 0.0017 - output_layer_dense_4_4_4_mean_absolute_error: 0.0626 - output_layer_dense_8_8_8_mean_absolute_error: 0.0532 - output_layer_dense_16_16_16_mean_absolute_error: 0.0539 - output_layer_dense_32_32_32_mean_absolute_error: 0.0442 - output_layer_dense_64_64_64_mean_absolute_error: 0.0325 - output_layer_dense_128_128_128_mean_absolute_error: 0.0290\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0251 - output_layer_dense_4_4_4_loss: 0.0072 - output_layer_dense_8_8_8_loss: 0.0051 - output_layer_dense_16_16_16_loss: 0.0056 - output_layer_dense_32_32_32_loss: 0.0035 - output_layer_dense_64_64_64_loss: 0.0020 - output_layer_dense_128_128_128_loss: 0.0017 - output_layer_dense_4_4_4_mean_absolute_error: 0.0620 - output_layer_dense_8_8_8_mean_absolute_error: 0.0502 - output_layer_dense_16_16_16_mean_absolute_error: 0.0519 - output_layer_dense_32_32_32_mean_absolute_error: 0.0408 - output_layer_dense_64_64_64_mean_absolute_error: 0.0315 - output_layer_dense_128_128_128_mean_absolute_error: 0.0280\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0243 - output_layer_dense_4_4_4_loss: 0.0070 - output_layer_dense_8_8_8_loss: 0.0048 - output_layer_dense_16_16_16_loss: 0.0055 - output_layer_dense_32_32_32_loss: 0.0035 - output_layer_dense_64_64_64_loss: 0.0019 - output_layer_dense_128_128_128_loss: 0.0015 - output_layer_dense_4_4_4_mean_absolute_error: 0.0606 - output_layer_dense_8_8_8_mean_absolute_error: 0.0494 - output_layer_dense_16_16_16_mean_absolute_error: 0.0518 - output_layer_dense_32_32_32_mean_absolute_error: 0.0408 - output_layer_dense_64_64_64_mean_absolute_error: 0.0307 - output_layer_dense_128_128_128_mean_absolute_error: 0.0264\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0224 - output_layer_dense_4_4_4_loss: 0.0067 - output_layer_dense_8_8_8_loss: 0.0046 - output_layer_dense_16_16_16_loss: 0.0048 - output_layer_dense_32_32_32_loss: 0.0032 - output_layer_dense_64_64_64_loss: 0.0018 - output_layer_dense_128_128_128_loss: 0.0013 - output_layer_dense_4_4_4_mean_absolute_error: 0.0581 - output_layer_dense_8_8_8_mean_absolute_error: 0.0473 - output_layer_dense_16_16_16_mean_absolute_error: 0.0474 - output_layer_dense_32_32_32_mean_absolute_error: 0.0386 - output_layer_dense_64_64_64_mean_absolute_error: 0.0303 - output_layer_dense_128_128_128_mean_absolute_error: 0.0255\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0223 - output_layer_dense_4_4_4_loss: 0.0065 - output_layer_dense_8_8_8_loss: 0.0046 - output_layer_dense_16_16_16_loss: 0.0048 - output_layer_dense_32_32_32_loss: 0.0032 - output_layer_dense_64_64_64_loss: 0.0018 - output_layer_dense_128_128_128_loss: 0.0014 - output_layer_dense_4_4_4_mean_absolute_error: 0.0557 - output_layer_dense_8_8_8_mean_absolute_error: 0.0475 - output_layer_dense_16_16_16_mean_absolute_error: 0.0481 - output_layer_dense_32_32_32_mean_absolute_error: 0.0383 - output_layer_dense_64_64_64_mean_absolute_error: 0.0291 - output_layer_dense_128_128_128_mean_absolute_error: 0.0250\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0218 - output_layer_dense_4_4_4_loss: 0.0061 - output_layer_dense_8_8_8_loss: 0.0046 - output_layer_dense_16_16_16_loss: 0.0046 - output_layer_dense_32_32_32_loss: 0.0033 - output_layer_dense_64_64_64_loss: 0.0018 - output_layer_dense_128_128_128_loss: 0.0014 - output_layer_dense_4_4_4_mean_absolute_error: 0.0531 - output_layer_dense_8_8_8_mean_absolute_error: 0.0458 - output_layer_dense_16_16_16_mean_absolute_error: 0.0444 - output_layer_dense_32_32_32_mean_absolute_error: 0.0372 - output_layer_dense_64_64_64_mean_absolute_error: 0.0282 - output_layer_dense_128_128_128_mean_absolute_error: 0.0238\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0202 - output_layer_dense_4_4_4_loss: 0.0059 - output_layer_dense_8_8_8_loss: 0.0043 - output_layer_dense_16_16_16_loss: 0.0043 - output_layer_dense_32_32_32_loss: 0.0029 - output_layer_dense_64_64_64_loss: 0.0016 - output_layer_dense_128_128_128_loss: 0.0013 - output_layer_dense_4_4_4_mean_absolute_error: 0.0533 - output_layer_dense_8_8_8_mean_absolute_error: 0.0454 - output_layer_dense_16_16_16_mean_absolute_error: 0.0449 - output_layer_dense_32_32_32_mean_absolute_error: 0.0358 - output_layer_dense_64_64_64_mean_absolute_error: 0.0269 - output_layer_dense_128_128_128_mean_absolute_error: 0.0236\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0157 - output_layer_dense_4_4_4_loss: 0.0048 - output_layer_dense_8_8_8_loss: 0.0032 - output_layer_dense_16_16_16_loss: 0.0034 - output_layer_dense_32_32_32_loss: 0.0022 - output_layer_dense_64_64_64_loss: 0.0012 - output_layer_dense_128_128_128_loss: 9.1856e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0489 - output_layer_dense_8_8_8_mean_absolute_error: 0.0404 - output_layer_dense_16_16_16_mean_absolute_error: 0.0404 - output_layer_dense_32_32_32_mean_absolute_error: 0.0335 - output_layer_dense_64_64_64_mean_absolute_error: 0.0245 - output_layer_dense_128_128_128_mean_absolute_error: 0.0209\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0173 - output_layer_dense_4_4_4_loss: 0.0051 - output_layer_dense_8_8_8_loss: 0.0037 - output_layer_dense_16_16_16_loss: 0.0037 - output_layer_dense_32_32_32_loss: 0.0024 - output_layer_dense_64_64_64_loss: 0.0013 - output_layer_dense_128_128_128_loss: 0.0010 - output_layer_dense_4_4_4_mean_absolute_error: 0.0496 - output_layer_dense_8_8_8_mean_absolute_error: 0.0422 - output_layer_dense_16_16_16_mean_absolute_error: 0.0418 - output_layer_dense_32_32_32_mean_absolute_error: 0.0332 - output_layer_dense_64_64_64_mean_absolute_error: 0.0255 - output_layer_dense_128_128_128_mean_absolute_error: 0.0220\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0193 - output_layer_dense_4_4_4_loss: 0.0056 - output_layer_dense_8_8_8_loss: 0.0040 - output_layer_dense_16_16_16_loss: 0.0041 - output_layer_dense_32_32_32_loss: 0.0027 - output_layer_dense_64_64_64_loss: 0.0017 - output_layer_dense_128_128_128_loss: 0.0012 - output_layer_dense_4_4_4_mean_absolute_error: 0.0495 - output_layer_dense_8_8_8_mean_absolute_error: 0.0414 - output_layer_dense_16_16_16_mean_absolute_error: 0.0412 - output_layer_dense_32_32_32_mean_absolute_error: 0.0332 - output_layer_dense_64_64_64_mean_absolute_error: 0.0270 - output_layer_dense_128_128_128_mean_absolute_error: 0.0228\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0185 - output_layer_dense_4_4_4_loss: 0.0052 - output_layer_dense_8_8_8_loss: 0.0038 - output_layer_dense_16_16_16_loss: 0.0039 - output_layer_dense_32_32_32_loss: 0.0027 - output_layer_dense_64_64_64_loss: 0.0017 - output_layer_dense_128_128_128_loss: 0.0012 - output_layer_dense_4_4_4_mean_absolute_error: 0.0480 - output_layer_dense_8_8_8_mean_absolute_error: 0.0415 - output_layer_dense_16_16_16_mean_absolute_error: 0.0419 - output_layer_dense_32_32_32_mean_absolute_error: 0.0332 - output_layer_dense_64_64_64_mean_absolute_error: 0.0263 - output_layer_dense_128_128_128_mean_absolute_error: 0.0219\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0143 - output_layer_dense_4_4_4_loss: 0.0041 - output_layer_dense_8_8_8_loss: 0.0030 - output_layer_dense_16_16_16_loss: 0.0030 - output_layer_dense_32_32_32_loss: 0.0021 - output_layer_dense_64_64_64_loss: 0.0012 - output_layer_dense_128_128_128_loss: 8.5963e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0439 - output_layer_dense_8_8_8_mean_absolute_error: 0.0381 - output_layer_dense_16_16_16_mean_absolute_error: 0.0380 - output_layer_dense_32_32_32_mean_absolute_error: 0.0301 - output_layer_dense_64_64_64_mean_absolute_error: 0.0233 - output_layer_dense_128_128_128_mean_absolute_error: 0.0199\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0149 - output_layer_dense_4_4_4_loss: 0.0041 - output_layer_dense_8_8_8_loss: 0.0032 - output_layer_dense_16_16_16_loss: 0.0032 - output_layer_dense_32_32_32_loss: 0.0024 - output_layer_dense_64_64_64_loss: 0.0012 - output_layer_dense_128_128_128_loss: 8.3230e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0432 - output_layer_dense_8_8_8_mean_absolute_error: 0.0375 - output_layer_dense_16_16_16_mean_absolute_error: 0.0387 - output_layer_dense_32_32_32_mean_absolute_error: 0.0315 - output_layer_dense_64_64_64_mean_absolute_error: 0.0235 - output_layer_dense_128_128_128_mean_absolute_error: 0.0198\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0137 - output_layer_dense_4_4_4_loss: 0.0037 - output_layer_dense_8_8_8_loss: 0.0032 - output_layer_dense_16_16_16_loss: 0.0029 - output_layer_dense_32_32_32_loss: 0.0022 - output_layer_dense_64_64_64_loss: 9.8772e-04 - output_layer_dense_128_128_128_loss: 7.4427e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0413 - output_layer_dense_8_8_8_mean_absolute_error: 0.0373 - output_layer_dense_16_16_16_mean_absolute_error: 0.0373 - output_layer_dense_32_32_32_mean_absolute_error: 0.0305 - output_layer_dense_64_64_64_mean_absolute_error: 0.0213 - output_layer_dense_128_128_128_mean_absolute_error: 0.0190\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0140 - output_layer_dense_4_4_4_loss: 0.0037 - output_layer_dense_8_8_8_loss: 0.0030 - output_layer_dense_16_16_16_loss: 0.0031 - output_layer_dense_32_32_32_loss: 0.0021 - output_layer_dense_64_64_64_loss: 0.0012 - output_layer_dense_128_128_128_loss: 7.4956e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0406 - output_layer_dense_8_8_8_mean_absolute_error: 0.0363 - output_layer_dense_16_16_16_mean_absolute_error: 0.0379 - output_layer_dense_32_32_32_mean_absolute_error: 0.0301 - output_layer_dense_64_64_64_mean_absolute_error: 0.0222 - output_layer_dense_128_128_128_mean_absolute_error: 0.0179\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0140 - output_layer_dense_4_4_4_loss: 0.0039 - output_layer_dense_8_8_8_loss: 0.0030 - output_layer_dense_16_16_16_loss: 0.0032 - output_layer_dense_32_32_32_loss: 0.0021 - output_layer_dense_64_64_64_loss: 0.0010 - output_layer_dense_128_128_128_loss: 7.0886e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0403 - output_layer_dense_8_8_8_mean_absolute_error: 0.0350 - output_layer_dense_16_16_16_mean_absolute_error: 0.0376 - output_layer_dense_32_32_32_mean_absolute_error: 0.0296 - output_layer_dense_64_64_64_mean_absolute_error: 0.0212 - output_layer_dense_128_128_128_mean_absolute_error: 0.0182\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0136 - output_layer_dense_4_4_4_loss: 0.0039 - output_layer_dense_8_8_8_loss: 0.0028 - output_layer_dense_16_16_16_loss: 0.0032 - output_layer_dense_32_32_32_loss: 0.0021 - output_layer_dense_64_64_64_loss: 9.3554e-04 - output_layer_dense_128_128_128_loss: 7.5754e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0402 - output_layer_dense_8_8_8_mean_absolute_error: 0.0336 - output_layer_dense_16_16_16_mean_absolute_error: 0.0369 - output_layer_dense_32_32_32_mean_absolute_error: 0.0293 - output_layer_dense_64_64_64_mean_absolute_error: 0.0212 - output_layer_dense_128_128_128_mean_absolute_error: 0.0200\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0119 - output_layer_dense_4_4_4_loss: 0.0029 - output_layer_dense_8_8_8_loss: 0.0027 - output_layer_dense_16_16_16_loss: 0.0027 - output_layer_dense_32_32_32_loss: 0.0019 - output_layer_dense_64_64_64_loss: 0.0011 - output_layer_dense_128_128_128_loss: 5.8594e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0362 - output_layer_dense_8_8_8_mean_absolute_error: 0.0326 - output_layer_dense_16_16_16_mean_absolute_error: 0.0344 - output_layer_dense_32_32_32_mean_absolute_error: 0.0287 - output_layer_dense_64_64_64_mean_absolute_error: 0.0211 - output_layer_dense_128_128_128_mean_absolute_error: 0.0164\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0110 - output_layer_dense_4_4_4_loss: 0.0030 - output_layer_dense_8_8_8_loss: 0.0023 - output_layer_dense_16_16_16_loss: 0.0025 - output_layer_dense_32_32_32_loss: 0.0017 - output_layer_dense_64_64_64_loss: 9.3974e-04 - output_layer_dense_128_128_128_loss: 5.3422e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0368 - output_layer_dense_8_8_8_mean_absolute_error: 0.0315 - output_layer_dense_16_16_16_mean_absolute_error: 0.0347 - output_layer_dense_32_32_32_mean_absolute_error: 0.0270 - output_layer_dense_64_64_64_mean_absolute_error: 0.0209 - output_layer_dense_128_128_128_mean_absolute_error: 0.0155\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0120 - output_layer_dense_4_4_4_loss: 0.0032 - output_layer_dense_8_8_8_loss: 0.0028 - output_layer_dense_16_16_16_loss: 0.0027 - output_layer_dense_32_32_32_loss: 0.0018 - output_layer_dense_64_64_64_loss: 8.7383e-04 - output_layer_dense_128_128_128_loss: 5.5606e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0366 - output_layer_dense_8_8_8_mean_absolute_error: 0.0333 - output_layer_dense_16_16_16_mean_absolute_error: 0.0351 - output_layer_dense_32_32_32_mean_absolute_error: 0.0281 - output_layer_dense_64_64_64_mean_absolute_error: 0.0197 - output_layer_dense_128_128_128_mean_absolute_error: 0.0168\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0117 - output_layer_dense_4_4_4_loss: 0.0032 - output_layer_dense_8_8_8_loss: 0.0027 - output_layer_dense_16_16_16_loss: 0.0028 - output_layer_dense_32_32_32_loss: 0.0018 - output_layer_dense_64_64_64_loss: 7.7195e-04 - output_layer_dense_128_128_128_loss: 4.9025e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0364 - output_layer_dense_8_8_8_mean_absolute_error: 0.0322 - output_layer_dense_16_16_16_mean_absolute_error: 0.0346 - output_layer_dense_32_32_32_mean_absolute_error: 0.0280 - output_layer_dense_64_64_64_mean_absolute_error: 0.0189 - output_layer_dense_128_128_128_mean_absolute_error: 0.0157\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0100 - output_layer_dense_4_4_4_loss: 0.0027 - output_layer_dense_8_8_8_loss: 0.0021 - output_layer_dense_16_16_16_loss: 0.0024 - output_layer_dense_32_32_32_loss: 0.0016 - output_layer_dense_64_64_64_loss: 8.1265e-04 - output_layer_dense_128_128_128_loss: 3.7925e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0353 - output_layer_dense_8_8_8_mean_absolute_error: 0.0301 - output_layer_dense_16_16_16_mean_absolute_error: 0.0340 - output_layer_dense_32_32_32_mean_absolute_error: 0.0269 - output_layer_dense_64_64_64_mean_absolute_error: 0.0187 - output_layer_dense_128_128_128_mean_absolute_error: 0.0139\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0102 - output_layer_dense_4_4_4_loss: 0.0027 - output_layer_dense_8_8_8_loss: 0.0022 - output_layer_dense_16_16_16_loss: 0.0025 - output_layer_dense_32_32_32_loss: 0.0016 - output_layer_dense_64_64_64_loss: 7.8429e-04 - output_layer_dense_128_128_128_loss: 4.0402e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0339 - output_layer_dense_8_8_8_mean_absolute_error: 0.0299 - output_layer_dense_16_16_16_mean_absolute_error: 0.0328 - output_layer_dense_32_32_32_mean_absolute_error: 0.0266 - output_layer_dense_64_64_64_mean_absolute_error: 0.0184 - output_layer_dense_128_128_128_mean_absolute_error: 0.0143\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0112 - output_layer_dense_4_4_4_loss: 0.0030 - output_layer_dense_8_8_8_loss: 0.0026 - output_layer_dense_16_16_16_loss: 0.0028 - output_layer_dense_32_32_32_loss: 0.0016 - output_layer_dense_64_64_64_loss: 8.0662e-04 - output_layer_dense_128_128_128_loss: 4.1681e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0352 - output_layer_dense_8_8_8_mean_absolute_error: 0.0309 - output_layer_dense_16_16_16_mean_absolute_error: 0.0345 - output_layer_dense_32_32_32_mean_absolute_error: 0.0265 - output_layer_dense_64_64_64_mean_absolute_error: 0.0190 - output_layer_dense_128_128_128_mean_absolute_error: 0.0145\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0100 - output_layer_dense_4_4_4_loss: 0.0027 - output_layer_dense_8_8_8_loss: 0.0022 - output_layer_dense_16_16_16_loss: 0.0024 - output_layer_dense_32_32_32_loss: 0.0016 - output_layer_dense_64_64_64_loss: 7.5076e-04 - output_layer_dense_128_128_128_loss: 3.6236e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0345 - output_layer_dense_8_8_8_mean_absolute_error: 0.0298 - output_layer_dense_16_16_16_mean_absolute_error: 0.0329 - output_layer_dense_32_32_32_mean_absolute_error: 0.0261 - output_layer_dense_64_64_64_mean_absolute_error: 0.0183 - output_layer_dense_128_128_128_mean_absolute_error: 0.0139\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0085 - output_layer_dense_4_4_4_loss: 0.0023 - output_layer_dense_8_8_8_loss: 0.0017 - output_layer_dense_16_16_16_loss: 0.0021 - output_layer_dense_32_32_32_loss: 0.0013 - output_layer_dense_64_64_64_loss: 5.9843e-04 - output_layer_dense_128_128_128_loss: 3.2267e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0326 - output_layer_dense_8_8_8_mean_absolute_error: 0.0275 - output_layer_dense_16_16_16_mean_absolute_error: 0.0311 - output_layer_dense_32_32_32_mean_absolute_error: 0.0249 - output_layer_dense_64_64_64_mean_absolute_error: 0.0174 - output_layer_dense_128_128_128_mean_absolute_error: 0.0128\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0104 - output_layer_dense_4_4_4_loss: 0.0028 - output_layer_dense_8_8_8_loss: 0.0023 - output_layer_dense_16_16_16_loss: 0.0026 - output_layer_dense_32_32_32_loss: 0.0016 - output_layer_dense_64_64_64_loss: 7.4354e-04 - output_layer_dense_128_128_128_loss: 3.7665e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0338 - output_layer_dense_8_8_8_mean_absolute_error: 0.0292 - output_layer_dense_16_16_16_mean_absolute_error: 0.0324 - output_layer_dense_32_32_32_mean_absolute_error: 0.0262 - output_layer_dense_64_64_64_mean_absolute_error: 0.0181 - output_layer_dense_128_128_128_mean_absolute_error: 0.0131\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0082 - output_layer_dense_4_4_4_loss: 0.0022 - output_layer_dense_8_8_8_loss: 0.0018 - output_layer_dense_16_16_16_loss: 0.0020 - output_layer_dense_32_32_32_loss: 0.0013 - output_layer_dense_64_64_64_loss: 6.2250e-04 - output_layer_dense_128_128_128_loss: 2.8994e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0309 - output_layer_dense_8_8_8_mean_absolute_error: 0.0269 - output_layer_dense_16_16_16_mean_absolute_error: 0.0298 - output_layer_dense_32_32_32_mean_absolute_error: 0.0241 - output_layer_dense_64_64_64_mean_absolute_error: 0.0172 - output_layer_dense_128_128_128_mean_absolute_error: 0.0122    \n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0088 - output_layer_dense_4_4_4_loss: 0.0024 - output_layer_dense_8_8_8_loss: 0.0020 - output_layer_dense_16_16_16_loss: 0.0022 - output_layer_dense_32_32_32_loss: 0.0013 - output_layer_dense_64_64_64_loss: 6.1501e-04 - output_layer_dense_128_128_128_loss: 2.6904e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0323 - output_layer_dense_8_8_8_mean_absolute_error: 0.0285 - output_layer_dense_16_16_16_mean_absolute_error: 0.0304 - output_layer_dense_32_32_32_mean_absolute_error: 0.0246 - output_layer_dense_64_64_64_mean_absolute_error: 0.0172 - output_layer_dense_128_128_128_mean_absolute_error: 0.0119\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0083 - output_layer_dense_4_4_4_loss: 0.0021 - output_layer_dense_8_8_8_loss: 0.0019 - output_layer_dense_16_16_16_loss: 0.0020 - output_layer_dense_32_32_32_loss: 0.0013 - output_layer_dense_64_64_64_loss: 6.9734e-04 - output_layer_dense_128_128_128_loss: 2.5146e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0312 - output_layer_dense_8_8_8_mean_absolute_error: 0.0274 - output_layer_dense_16_16_16_mean_absolute_error: 0.0303 - output_layer_dense_32_32_32_mean_absolute_error: 0.0243 - output_layer_dense_64_64_64_mean_absolute_error: 0.0187 - output_layer_dense_128_128_128_mean_absolute_error: 0.0115\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0090 - output_layer_dense_4_4_4_loss: 0.0023 - output_layer_dense_8_8_8_loss: 0.0020 - output_layer_dense_16_16_16_loss: 0.0022 - output_layer_dense_32_32_32_loss: 0.0014 - output_layer_dense_64_64_64_loss: 7.6581e-04 - output_layer_dense_128_128_128_loss: 2.3959e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0319 - output_layer_dense_8_8_8_mean_absolute_error: 0.0279 - output_layer_dense_16_16_16_mean_absolute_error: 0.0303 - output_layer_dense_32_32_32_mean_absolute_error: 0.0249 - output_layer_dense_64_64_64_mean_absolute_error: 0.0191 - output_layer_dense_128_128_128_mean_absolute_error: 0.0107\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0083 - output_layer_dense_4_4_4_loss: 0.0023 - output_layer_dense_8_8_8_loss: 0.0018 - output_layer_dense_16_16_16_loss: 0.0021 - output_layer_dense_32_32_32_loss: 0.0011 - output_layer_dense_64_64_64_loss: 7.1467e-04 - output_layer_dense_128_128_128_loss: 2.5717e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0319 - output_layer_dense_8_8_8_mean_absolute_error: 0.0277 - output_layer_dense_16_16_16_mean_absolute_error: 0.0308 - output_layer_dense_32_32_32_mean_absolute_error: 0.0235 - output_layer_dense_64_64_64_mean_absolute_error: 0.0197 - output_layer_dense_128_128_128_mean_absolute_error: 0.0113\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0081 - output_layer_dense_4_4_4_loss: 0.0021 - output_layer_dense_8_8_8_loss: 0.0018 - output_layer_dense_16_16_16_loss: 0.0020 - output_layer_dense_32_32_32_loss: 0.0013 - output_layer_dense_64_64_64_loss: 5.7444e-04 - output_layer_dense_128_128_128_loss: 2.4574e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0315 - output_layer_dense_8_8_8_mean_absolute_error: 0.0283 - output_layer_dense_16_16_16_mean_absolute_error: 0.0307 - output_layer_dense_32_32_32_mean_absolute_error: 0.0245 - output_layer_dense_64_64_64_mean_absolute_error: 0.0170 - output_layer_dense_128_128_128_mean_absolute_error: 0.0112\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0094 - output_layer_dense_4_4_4_loss: 0.0027 - output_layer_dense_8_8_8_loss: 0.0022 - output_layer_dense_16_16_16_loss: 0.0025 - output_layer_dense_32_32_32_loss: 0.0013 - output_layer_dense_64_64_64_loss: 4.9919e-04 - output_layer_dense_128_128_128_loss: 2.1086e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0328 - output_layer_dense_8_8_8_mean_absolute_error: 0.0276 - output_layer_dense_16_16_16_mean_absolute_error: 0.0311 - output_layer_dense_32_32_32_mean_absolute_error: 0.0237 - output_layer_dense_64_64_64_mean_absolute_error: 0.0151 - output_layer_dense_128_128_128_mean_absolute_error: 0.0104\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0075 - output_layer_dense_4_4_4_loss: 0.0020 - output_layer_dense_8_8_8_loss: 0.0017 - output_layer_dense_16_16_16_loss: 0.0019 - output_layer_dense_32_32_32_loss: 0.0012 - output_layer_dense_64_64_64_loss: 5.2791e-04 - output_layer_dense_128_128_128_loss: 2.1020e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0300 - output_layer_dense_8_8_8_mean_absolute_error: 0.0258 - output_layer_dense_16_16_16_mean_absolute_error: 0.0289 - output_layer_dense_32_32_32_mean_absolute_error: 0.0235 - output_layer_dense_64_64_64_mean_absolute_error: 0.0161 - output_layer_dense_128_128_128_mean_absolute_error: 0.0102\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0083 - output_layer_dense_4_4_4_loss: 0.0023 - output_layer_dense_8_8_8_loss: 0.0019 - output_layer_dense_16_16_16_loss: 0.0021 - output_layer_dense_32_32_32_loss: 0.0012 - output_layer_dense_64_64_64_loss: 4.9067e-04 - output_layer_dense_128_128_128_loss: 2.0620e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0316 - output_layer_dense_8_8_8_mean_absolute_error: 0.0271 - output_layer_dense_16_16_16_mean_absolute_error: 0.0297 - output_layer_dense_32_32_32_mean_absolute_error: 0.0234 - output_layer_dense_64_64_64_mean_absolute_error: 0.0155 - output_layer_dense_128_128_128_mean_absolute_error: 0.0106\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0067 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0015 - output_layer_dense_16_16_16_loss: 0.0017 - output_layer_dense_32_32_32_loss: 0.0010 - output_layer_dense_64_64_64_loss: 4.1450e-04 - output_layer_dense_128_128_128_loss: 2.0620e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0294 - output_layer_dense_8_8_8_mean_absolute_error: 0.0253 - output_layer_dense_16_16_16_mean_absolute_error: 0.0278 - output_layer_dense_32_32_32_mean_absolute_error: 0.0220 - output_layer_dense_64_64_64_mean_absolute_error: 0.0146 - output_layer_dense_128_128_128_mean_absolute_error: 0.0104\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0068 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0015 - output_layer_dense_16_16_16_loss: 0.0017 - output_layer_dense_32_32_32_loss: 0.0010 - output_layer_dense_64_64_64_loss: 4.1782e-04 - output_layer_dense_128_128_128_loss: 1.7178e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0297 - output_layer_dense_8_8_8_mean_absolute_error: 0.0257 - output_layer_dense_16_16_16_mean_absolute_error: 0.0283 - output_layer_dense_32_32_32_mean_absolute_error: 0.0220 - output_layer_dense_64_64_64_mean_absolute_error: 0.0144 - output_layer_dense_128_128_128_mean_absolute_error: 0.0089\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0072 - output_layer_dense_4_4_4_loss: 0.0020 - output_layer_dense_8_8_8_loss: 0.0017 - output_layer_dense_16_16_16_loss: 0.0018 - output_layer_dense_32_32_32_loss: 0.0010 - output_layer_dense_64_64_64_loss: 4.1910e-04 - output_layer_dense_128_128_128_loss: 1.6167e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0301 - output_layer_dense_8_8_8_mean_absolute_error: 0.0258 - output_layer_dense_16_16_16_mean_absolute_error: 0.0283 - output_layer_dense_32_32_32_mean_absolute_error: 0.0216 - output_layer_dense_64_64_64_mean_absolute_error: 0.0144 - output_layer_dense_128_128_128_mean_absolute_error: 0.0087\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0066 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0015 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 0.0010 - output_layer_dense_64_64_64_loss: 4.0118e-04 - output_layer_dense_128_128_128_loss: 1.6677e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0297 - output_layer_dense_8_8_8_mean_absolute_error: 0.0253 - output_layer_dense_16_16_16_mean_absolute_error: 0.0277 - output_layer_dense_32_32_32_mean_absolute_error: 0.0223 - output_layer_dense_64_64_64_mean_absolute_error: 0.0140 - output_layer_dense_128_128_128_mean_absolute_error: 0.0089\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0069 - output_layer_dense_4_4_4_loss: 0.0020 - output_layer_dense_8_8_8_loss: 0.0016 - output_layer_dense_16_16_16_loss: 0.0018 - output_layer_dense_32_32_32_loss: 9.6876e-04 - output_layer_dense_64_64_64_loss: 3.7099e-04 - output_layer_dense_128_128_128_loss: 1.5141e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0291 - output_layer_dense_8_8_8_mean_absolute_error: 0.0247 - output_layer_dense_16_16_16_mean_absolute_error: 0.0272 - output_layer_dense_32_32_32_mean_absolute_error: 0.0214 - output_layer_dense_64_64_64_mean_absolute_error: 0.0135 - output_layer_dense_128_128_128_mean_absolute_error: 0.0089        \n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0073 - output_layer_dense_4_4_4_loss: 0.0021 - output_layer_dense_8_8_8_loss: 0.0017 - output_layer_dense_16_16_16_loss: 0.0019 - output_layer_dense_32_32_32_loss: 0.0010 - output_layer_dense_64_64_64_loss: 3.6370e-04 - output_layer_dense_128_128_128_loss: 1.6842e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0297 - output_layer_dense_8_8_8_mean_absolute_error: 0.0252 - output_layer_dense_16_16_16_mean_absolute_error: 0.0277 - output_layer_dense_32_32_32_mean_absolute_error: 0.0217 - output_layer_dense_64_64_64_mean_absolute_error: 0.0133 - output_layer_dense_128_128_128_mean_absolute_error: 0.0094        \n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0080 - output_layer_dense_4_4_4_loss: 0.0024 - output_layer_dense_8_8_8_loss: 0.0018 - output_layer_dense_16_16_16_loss: 0.0021 - output_layer_dense_32_32_32_loss: 0.0011 - output_layer_dense_64_64_64_loss: 3.8478e-04 - output_layer_dense_128_128_128_loss: 1.6872e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0307 - output_layer_dense_8_8_8_mean_absolute_error: 0.0262 - output_layer_dense_16_16_16_mean_absolute_error: 0.0287 - output_layer_dense_32_32_32_mean_absolute_error: 0.0218 - output_layer_dense_64_64_64_mean_absolute_error: 0.0138 - output_layer_dense_128_128_128_mean_absolute_error: 0.0090\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0073 - output_layer_dense_4_4_4_loss: 0.0022 - output_layer_dense_8_8_8_loss: 0.0016 - output_layer_dense_16_16_16_loss: 0.0020 - output_layer_dense_32_32_32_loss: 9.9103e-04 - output_layer_dense_64_64_64_loss: 4.3167e-04 - output_layer_dense_128_128_128_loss: 1.6333e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0299 - output_layer_dense_8_8_8_mean_absolute_error: 0.0251 - output_layer_dense_16_16_16_mean_absolute_error: 0.0278 - output_layer_dense_32_32_32_mean_absolute_error: 0.0212 - output_layer_dense_64_64_64_mean_absolute_error: 0.0153 - output_layer_dense_128_128_128_mean_absolute_error: 0.0094\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0067 - output_layer_dense_4_4_4_loss: 0.0020 - output_layer_dense_8_8_8_loss: 0.0015 - output_layer_dense_16_16_16_loss: 0.0018 - output_layer_dense_32_32_32_loss: 9.6174e-04 - output_layer_dense_64_64_64_loss: 3.5956e-04 - output_layer_dense_128_128_128_loss: 1.3639e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0295 - output_layer_dense_8_8_8_mean_absolute_error: 0.0245 - output_layer_dense_16_16_16_mean_absolute_error: 0.0270 - output_layer_dense_32_32_32_mean_absolute_error: 0.0211 - output_layer_dense_64_64_64_mean_absolute_error: 0.0139 - output_layer_dense_128_128_128_mean_absolute_error: 0.0082\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0075 - output_layer_dense_4_4_4_loss: 0.0022 - output_layer_dense_8_8_8_loss: 0.0018 - output_layer_dense_16_16_16_loss: 0.0020 - output_layer_dense_32_32_32_loss: 9.8341e-04 - output_layer_dense_64_64_64_loss: 3.3666e-04 - output_layer_dense_128_128_128_loss: 1.8436e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0297 - output_layer_dense_8_8_8_mean_absolute_error: 0.0249 - output_layer_dense_16_16_16_mean_absolute_error: 0.0276 - output_layer_dense_32_32_32_mean_absolute_error: 0.0213 - output_layer_dense_64_64_64_mean_absolute_error: 0.0127 - output_layer_dense_128_128_128_mean_absolute_error: 0.0101\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0068 - output_layer_dense_4_4_4_loss: 0.0020 - output_layer_dense_8_8_8_loss: 0.0016 - output_layer_dense_16_16_16_loss: 0.0018 - output_layer_dense_32_32_32_loss: 9.1927e-04 - output_layer_dense_64_64_64_loss: 3.4517e-04 - output_layer_dense_128_128_128_loss: 1.5322e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0288 - output_layer_dense_8_8_8_mean_absolute_error: 0.0242 - output_layer_dense_16_16_16_mean_absolute_error: 0.0265 - output_layer_dense_32_32_32_mean_absolute_error: 0.0203 - output_layer_dense_64_64_64_mean_absolute_error: 0.0130 - output_layer_dense_128_128_128_mean_absolute_error: 0.0092    \n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0073 - output_layer_dense_4_4_4_loss: 0.0022 - output_layer_dense_8_8_8_loss: 0.0017 - output_layer_dense_16_16_16_loss: 0.0020 - output_layer_dense_32_32_32_loss: 9.8594e-04 - output_layer_dense_64_64_64_loss: 3.2111e-04 - output_layer_dense_128_128_128_loss: 1.3178e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0295 - output_layer_dense_8_8_8_mean_absolute_error: 0.0255 - output_layer_dense_16_16_16_mean_absolute_error: 0.0277 - output_layer_dense_32_32_32_mean_absolute_error: 0.0214 - output_layer_dense_64_64_64_mean_absolute_error: 0.0127 - output_layer_dense_128_128_128_mean_absolute_error: 0.0081\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0075 - output_layer_dense_4_4_4_loss: 0.0021 - output_layer_dense_8_8_8_loss: 0.0019 - output_layer_dense_16_16_16_loss: 0.0020 - output_layer_dense_32_32_32_loss: 0.0011 - output_layer_dense_64_64_64_loss: 3.3877e-04 - output_layer_dense_128_128_128_loss: 1.0466e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0291 - output_layer_dense_8_8_8_mean_absolute_error: 0.0262 - output_layer_dense_16_16_16_mean_absolute_error: 0.0278 - output_layer_dense_32_32_32_mean_absolute_error: 0.0221 - output_layer_dense_64_64_64_mean_absolute_error: 0.0130 - output_layer_dense_128_128_128_mean_absolute_error: 0.0073\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0068 - output_layer_dense_4_4_4_loss: 0.0020 - output_layer_dense_8_8_8_loss: 0.0016 - output_layer_dense_16_16_16_loss: 0.0018 - output_layer_dense_32_32_32_loss: 8.6693e-04 - output_layer_dense_64_64_64_loss: 3.0268e-04 - output_layer_dense_128_128_128_loss: 1.1738e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0286 - output_layer_dense_8_8_8_mean_absolute_error: 0.0248 - output_layer_dense_16_16_16_mean_absolute_error: 0.0262 - output_layer_dense_32_32_32_mean_absolute_error: 0.0202 - output_layer_dense_64_64_64_mean_absolute_error: 0.0120 - output_layer_dense_128_128_128_mean_absolute_error: 0.0072\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0060 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 8.5320e-04 - output_layer_dense_64_64_64_loss: 2.5346e-04 - output_layer_dense_128_128_128_loss: 9.7404e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0290 - output_layer_dense_8_8_8_mean_absolute_error: 0.0241 - output_layer_dense_16_16_16_mean_absolute_error: 0.0270 - output_layer_dense_32_32_32_mean_absolute_error: 0.0207 - output_layer_dense_64_64_64_mean_absolute_error: 0.0115 - output_layer_dense_128_128_128_mean_absolute_error: 0.0070\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0066 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0016 - output_layer_dense_16_16_16_loss: 0.0018 - output_layer_dense_32_32_32_loss: 8.9348e-04 - output_layer_dense_64_64_64_loss: 2.7133e-04 - output_layer_dense_128_128_128_loss: 9.6158e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0294 - output_layer_dense_8_8_8_mean_absolute_error: 0.0267 - output_layer_dense_16_16_16_mean_absolute_error: 0.0273 - output_layer_dense_32_32_32_mean_absolute_error: 0.0209 - output_layer_dense_64_64_64_mean_absolute_error: 0.0120 - output_layer_dense_128_128_128_mean_absolute_error: 0.0070\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0066 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0015 - output_layer_dense_16_16_16_loss: 0.0018 - output_layer_dense_32_32_32_loss: 9.3690e-04 - output_layer_dense_64_64_64_loss: 2.8363e-04 - output_layer_dense_128_128_128_loss: 1.2046e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0290 - output_layer_dense_8_8_8_mean_absolute_error: 0.0246 - output_layer_dense_16_16_16_mean_absolute_error: 0.0264 - output_layer_dense_32_32_32_mean_absolute_error: 0.0206 - output_layer_dense_64_64_64_mean_absolute_error: 0.0119 - output_layer_dense_128_128_128_mean_absolute_error: 0.0076\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0061 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0014 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 8.5295e-04 - output_layer_dense_64_64_64_loss: 2.9917e-04 - output_layer_dense_128_128_128_loss: 1.2921e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0281 - output_layer_dense_8_8_8_mean_absolute_error: 0.0240 - output_layer_dense_16_16_16_mean_absolute_error: 0.0255 - output_layer_dense_32_32_32_mean_absolute_error: 0.0202 - output_layer_dense_64_64_64_mean_absolute_error: 0.0124 - output_layer_dense_128_128_128_mean_absolute_error: 0.0079\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0057 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0015 - output_layer_dense_32_32_32_loss: 7.9140e-04 - output_layer_dense_64_64_64_loss: 2.4430e-04 - output_layer_dense_128_128_128_loss: 8.9667e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0274 - output_layer_dense_8_8_8_mean_absolute_error: 0.0227 - output_layer_dense_16_16_16_mean_absolute_error: 0.0248 - output_layer_dense_32_32_32_mean_absolute_error: 0.0198 - output_layer_dense_64_64_64_mean_absolute_error: 0.0115 - output_layer_dense_128_128_128_mean_absolute_error: 0.0068\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0070 - output_layer_dense_4_4_4_loss: 0.0021 - output_layer_dense_8_8_8_loss: 0.0018 - output_layer_dense_16_16_16_loss: 0.0019 - output_layer_dense_32_32_32_loss: 8.9421e-04 - output_layer_dense_64_64_64_loss: 2.1986e-04 - output_layer_dense_128_128_128_loss: 1.0551e-04 - output_layer_dense_4_4_4_mean_absolute_error: 0.0288 - output_layer_dense_8_8_8_mean_absolute_error: 0.0246 - output_layer_dense_16_16_16_mean_absolute_error: 0.0266 - output_layer_dense_32_32_32_mean_absolute_error: 0.0201 - output_layer_dense_64_64_64_mean_absolute_error: 0.0107 - output_layer_dense_128_128_128_mean_absolute_error: 0.0077\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0053 - output_layer_dense_4_4_4_loss: 0.0016 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0014 - output_layer_dense_32_32_32_loss: 7.6643e-04 - output_layer_dense_64_64_64_loss: 2.4812e-04 - output_layer_dense_128_128_128_loss: 8.8025e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0271 - output_layer_dense_8_8_8_mean_absolute_error: 0.0233 - output_layer_dense_16_16_16_mean_absolute_error: 0.0246 - output_layer_dense_32_32_32_mean_absolute_error: 0.0193 - output_layer_dense_64_64_64_mean_absolute_error: 0.0113 - output_layer_dense_128_128_128_mean_absolute_error: 0.0068\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0070 - output_layer_dense_4_4_4_loss: 0.0021 - output_layer_dense_8_8_8_loss: 0.0018 - output_layer_dense_16_16_16_loss: 0.0019 - output_layer_dense_32_32_32_loss: 8.9513e-04 - output_layer_dense_64_64_64_loss: 2.3768e-04 - output_layer_dense_128_128_128_loss: 7.4256e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0285 - output_layer_dense_8_8_8_mean_absolute_error: 0.0241 - output_layer_dense_16_16_16_mean_absolute_error: 0.0262 - output_layer_dense_32_32_32_mean_absolute_error: 0.0200 - output_layer_dense_64_64_64_mean_absolute_error: 0.0109 - output_layer_dense_128_128_128_mean_absolute_error: 0.0057\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0077 - output_layer_dense_4_4_4_loss: 0.0023 - output_layer_dense_8_8_8_loss: 0.0019 - output_layer_dense_16_16_16_loss: 0.0021 - output_layer_dense_32_32_32_loss: 9.6784e-04 - output_layer_dense_64_64_64_loss: 2.8652e-04 - output_layer_dense_128_128_128_loss: 8.5514e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0299 - output_layer_dense_8_8_8_mean_absolute_error: 0.0253 - output_layer_dense_16_16_16_mean_absolute_error: 0.0272 - output_layer_dense_32_32_32_mean_absolute_error: 0.0204 - output_layer_dense_64_64_64_mean_absolute_error: 0.0121 - output_layer_dense_128_128_128_mean_absolute_error: 0.0062\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0051 - output_layer_dense_4_4_4_loss: 0.0016 - output_layer_dense_8_8_8_loss: 0.0012 - output_layer_dense_16_16_16_loss: 0.0013 - output_layer_dense_32_32_32_loss: 6.8978e-04 - output_layer_dense_64_64_64_loss: 2.1681e-04 - output_layer_dense_128_128_128_loss: 6.4359e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0276 - output_layer_dense_8_8_8_mean_absolute_error: 0.0228 - output_layer_dense_16_16_16_mean_absolute_error: 0.0245 - output_layer_dense_32_32_32_mean_absolute_error: 0.0187 - output_layer_dense_64_64_64_mean_absolute_error: 0.0108 - output_layer_dense_128_128_128_mean_absolute_error: 0.0057    \n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0067 - output_layer_dense_4_4_4_loss: 0.0020 - output_layer_dense_8_8_8_loss: 0.0018 - output_layer_dense_16_16_16_loss: 0.0017 - output_layer_dense_32_32_32_loss: 8.7301e-04 - output_layer_dense_64_64_64_loss: 2.5060e-04 - output_layer_dense_128_128_128_loss: 8.1226e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0282 - output_layer_dense_8_8_8_mean_absolute_error: 0.0243 - output_layer_dense_16_16_16_mean_absolute_error: 0.0250 - output_layer_dense_32_32_32_mean_absolute_error: 0.0195 - output_layer_dense_64_64_64_mean_absolute_error: 0.0111 - output_layer_dense_128_128_128_mean_absolute_error: 0.0061\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0051 - output_layer_dense_4_4_4_loss: 0.0016 - output_layer_dense_8_8_8_loss: 0.0012 - output_layer_dense_16_16_16_loss: 0.0014 - output_layer_dense_32_32_32_loss: 6.9008e-04 - output_layer_dense_64_64_64_loss: 2.0175e-04 - output_layer_dense_128_128_128_loss: 6.2654e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0273 - output_layer_dense_8_8_8_mean_absolute_error: 0.0229 - output_layer_dense_16_16_16_mean_absolute_error: 0.0244 - output_layer_dense_32_32_32_mean_absolute_error: 0.0188 - output_layer_dense_64_64_64_mean_absolute_error: 0.0104 - output_layer_dense_128_128_128_mean_absolute_error: 0.0056\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0059 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0015 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 7.5113e-04 - output_layer_dense_64_64_64_loss: 2.0448e-04 - output_layer_dense_128_128_128_loss: 6.9436e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0279 - output_layer_dense_8_8_8_mean_absolute_error: 0.0236 - output_layer_dense_16_16_16_mean_absolute_error: 0.0249 - output_layer_dense_32_32_32_mean_absolute_error: 0.0186 - output_layer_dense_64_64_64_mean_absolute_error: 0.0102 - output_layer_dense_128_128_128_mean_absolute_error: 0.0058\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0059 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0015 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 6.8744e-04 - output_layer_dense_64_64_64_loss: 2.0079e-04 - output_layer_dense_128_128_128_loss: 5.7836e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0269 - output_layer_dense_8_8_8_mean_absolute_error: 0.0237 - output_layer_dense_16_16_16_mean_absolute_error: 0.0246 - output_layer_dense_32_32_32_mean_absolute_error: 0.0183 - output_layer_dense_64_64_64_mean_absolute_error: 0.0102 - output_layer_dense_128_128_128_mean_absolute_error: 0.0054\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0054 - output_layer_dense_4_4_4_loss: 0.0017 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0015 - output_layer_dense_32_32_32_loss: 6.9546e-04 - output_layer_dense_64_64_64_loss: 1.9072e-04 - output_layer_dense_128_128_128_loss: 5.3570e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0277 - output_layer_dense_8_8_8_mean_absolute_error: 0.0233 - output_layer_dense_16_16_16_mean_absolute_error: 0.0250 - output_layer_dense_32_32_32_mean_absolute_error: 0.0185 - output_layer_dense_64_64_64_mean_absolute_error: 0.0097 - output_layer_dense_128_128_128_mean_absolute_error: 0.0052\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - output_layer_dense_4_4_4_loss: 0.0017 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0014 - output_layer_dense_32_32_32_loss: 7.3937e-04 - output_layer_dense_64_64_64_loss: 1.8685e-04 - output_layer_dense_128_128_128_loss: 5.6922e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0277 - output_layer_dense_8_8_8_mean_absolute_error: 0.0231 - output_layer_dense_16_16_16_mean_absolute_error: 0.0242 - output_layer_dense_32_32_32_mean_absolute_error: 0.0191 - output_layer_dense_64_64_64_mean_absolute_error: 0.0098 - output_layer_dense_128_128_128_mean_absolute_error: 0.0053\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0057 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0014 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 6.7337e-04 - output_layer_dense_64_64_64_loss: 1.9597e-04 - output_layer_dense_128_128_128_loss: 5.1543e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0281 - output_layer_dense_8_8_8_mean_absolute_error: 0.0232 - output_layer_dense_16_16_16_mean_absolute_error: 0.0249 - output_layer_dense_32_32_32_mean_absolute_error: 0.0183 - output_layer_dense_64_64_64_mean_absolute_error: 0.0099 - output_layer_dense_128_128_128_mean_absolute_error: 0.0049\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0048 - output_layer_dense_4_4_4_loss: 0.0015 - output_layer_dense_8_8_8_loss: 0.0012 - output_layer_dense_16_16_16_loss: 0.0013 - output_layer_dense_32_32_32_loss: 6.1675e-04 - output_layer_dense_64_64_64_loss: 1.9354e-04 - output_layer_dense_128_128_128_loss: 5.2385e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0265 - output_layer_dense_8_8_8_mean_absolute_error: 0.0218 - output_layer_dense_16_16_16_mean_absolute_error: 0.0232 - output_layer_dense_32_32_32_mean_absolute_error: 0.0175 - output_layer_dense_64_64_64_mean_absolute_error: 0.0100 - output_layer_dense_128_128_128_mean_absolute_error: 0.0050\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0056 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 6.3598e-04 - output_layer_dense_64_64_64_loss: 1.5450e-04 - output_layer_dense_128_128_128_loss: 4.5846e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0267 - output_layer_dense_8_8_8_mean_absolute_error: 0.0221 - output_layer_dense_16_16_16_mean_absolute_error: 0.0243 - output_layer_dense_32_32_32_mean_absolute_error: 0.0178 - output_layer_dense_64_64_64_mean_absolute_error: 0.0091 - output_layer_dense_128_128_128_mean_absolute_error: 0.0046        \n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0047 - output_layer_dense_4_4_4_loss: 0.0015 - output_layer_dense_8_8_8_loss: 0.0011 - output_layer_dense_16_16_16_loss: 0.0013 - output_layer_dense_32_32_32_loss: 6.0694e-04 - output_layer_dense_64_64_64_loss: 1.6320e-04 - output_layer_dense_128_128_128_loss: 5.0546e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0266 - output_layer_dense_8_8_8_mean_absolute_error: 0.0225 - output_layer_dense_16_16_16_mean_absolute_error: 0.0238 - output_layer_dense_32_32_32_mean_absolute_error: 0.0176 - output_layer_dense_64_64_64_mean_absolute_error: 0.0093 - output_layer_dense_128_128_128_mean_absolute_error: 0.0051    \n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0050 - output_layer_dense_4_4_4_loss: 0.0015 - output_layer_dense_8_8_8_loss: 0.0012 - output_layer_dense_16_16_16_loss: 0.0014 - output_layer_dense_32_32_32_loss: 6.4016e-04 - output_layer_dense_64_64_64_loss: 1.8061e-04 - output_layer_dense_128_128_128_loss: 4.1741e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0268 - output_layer_dense_8_8_8_mean_absolute_error: 0.0226 - output_layer_dense_16_16_16_mean_absolute_error: 0.0239 - output_layer_dense_32_32_32_mean_absolute_error: 0.0179 - output_layer_dense_64_64_64_mean_absolute_error: 0.0094 - output_layer_dense_128_128_128_mean_absolute_error: 0.0043\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0057 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 6.1861e-04 - output_layer_dense_64_64_64_loss: 1.6260e-04 - output_layer_dense_128_128_128_loss: 3.7256e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0279 - output_layer_dense_8_8_8_mean_absolute_error: 0.0232 - output_layer_dense_16_16_16_mean_absolute_error: 0.0246 - output_layer_dense_32_32_32_mean_absolute_error: 0.0177 - output_layer_dense_64_64_64_mean_absolute_error: 0.0093 - output_layer_dense_128_128_128_mean_absolute_error: 0.0042\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0014 - output_layer_dense_32_32_32_loss: 6.1743e-04 - output_layer_dense_64_64_64_loss: 1.5690e-04 - output_layer_dense_128_128_128_loss: 4.2782e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0274 - output_layer_dense_8_8_8_mean_absolute_error: 0.0229 - output_layer_dense_16_16_16_mean_absolute_error: 0.0237 - output_layer_dense_32_32_32_mean_absolute_error: 0.0173 - output_layer_dense_64_64_64_mean_absolute_error: 0.0087 - output_layer_dense_128_128_128_mean_absolute_error: 0.0046    \n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0053 - output_layer_dense_4_4_4_loss: 0.0017 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0014 - output_layer_dense_32_32_32_loss: 6.4577e-04 - output_layer_dense_64_64_64_loss: 1.5125e-04 - output_layer_dense_128_128_128_loss: 4.8518e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0272 - output_layer_dense_8_8_8_mean_absolute_error: 0.0232 - output_layer_dense_16_16_16_mean_absolute_error: 0.0241 - output_layer_dense_32_32_32_mean_absolute_error: 0.0179 - output_layer_dense_64_64_64_mean_absolute_error: 0.0087 - output_layer_dense_128_128_128_mean_absolute_error: 0.0048    \n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0055 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0014 - output_layer_dense_16_16_16_loss: 0.0015 - output_layer_dense_32_32_32_loss: 6.2062e-04 - output_layer_dense_64_64_64_loss: 1.4379e-04 - output_layer_dense_128_128_128_loss: 4.1534e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0276 - output_layer_dense_8_8_8_mean_absolute_error: 0.0229 - output_layer_dense_16_16_16_mean_absolute_error: 0.0248 - output_layer_dense_32_32_32_mean_absolute_error: 0.0179 - output_layer_dense_64_64_64_mean_absolute_error: 0.0087 - output_layer_dense_128_128_128_mean_absolute_error: 0.0047\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0046 - output_layer_dense_4_4_4_loss: 0.0014 - output_layer_dense_8_8_8_loss: 0.0012 - output_layer_dense_16_16_16_loss: 0.0012 - output_layer_dense_32_32_32_loss: 5.9187e-04 - output_layer_dense_64_64_64_loss: 1.4809e-04 - output_layer_dense_128_128_128_loss: 5.9914e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0255 - output_layer_dense_8_8_8_mean_absolute_error: 0.0223 - output_layer_dense_16_16_16_mean_absolute_error: 0.0233 - output_layer_dense_32_32_32_mean_absolute_error: 0.0174 - output_layer_dense_64_64_64_mean_absolute_error: 0.0087 - output_layer_dense_128_128_128_mean_absolute_error: 0.0056        \n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0046 - output_layer_dense_4_4_4_loss: 0.0015 - output_layer_dense_8_8_8_loss: 0.0011 - output_layer_dense_16_16_16_loss: 0.0012 - output_layer_dense_32_32_32_loss: 5.8339e-04 - output_layer_dense_64_64_64_loss: 1.3244e-04 - output_layer_dense_128_128_128_loss: 5.4676e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0262 - output_layer_dense_8_8_8_mean_absolute_error: 0.0227 - output_layer_dense_16_16_16_mean_absolute_error: 0.0229 - output_layer_dense_32_32_32_mean_absolute_error: 0.0174 - output_layer_dense_64_64_64_mean_absolute_error: 0.0083 - output_layer_dense_128_128_128_mean_absolute_error: 0.0057    \n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - output_layer_dense_4_4_4_loss: 0.0017 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0015 - output_layer_dense_32_32_32_loss: 5.7712e-04 - output_layer_dense_64_64_64_loss: 1.4335e-04 - output_layer_dense_128_128_128_loss: 4.9478e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0270 - output_layer_dense_8_8_8_mean_absolute_error: 0.0229 - output_layer_dense_16_16_16_mean_absolute_error: 0.0241 - output_layer_dense_32_32_32_mean_absolute_error: 0.0170 - output_layer_dense_64_64_64_mean_absolute_error: 0.0086 - output_layer_dense_128_128_128_mean_absolute_error: 0.0050    \n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0057 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0014 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 6.4520e-04 - output_layer_dense_64_64_64_loss: 1.4520e-04 - output_layer_dense_128_128_128_loss: 4.5264e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0279 - output_layer_dense_8_8_8_mean_absolute_error: 0.0238 - output_layer_dense_16_16_16_mean_absolute_error: 0.0251 - output_layer_dense_32_32_32_mean_absolute_error: 0.0180 - output_layer_dense_64_64_64_mean_absolute_error: 0.0088 - output_layer_dense_128_128_128_mean_absolute_error: 0.0047\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0059 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0016 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 6.0313e-04 - output_layer_dense_64_64_64_loss: 1.4900e-04 - output_layer_dense_128_128_128_loss: 5.2042e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0278 - output_layer_dense_8_8_8_mean_absolute_error: 0.0231 - output_layer_dense_16_16_16_mean_absolute_error: 0.0237 - output_layer_dense_32_32_32_mean_absolute_error: 0.0167 - output_layer_dense_64_64_64_mean_absolute_error: 0.0087 - output_layer_dense_128_128_128_mean_absolute_error: 0.0051\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0049 - output_layer_dense_4_4_4_loss: 0.0017 - output_layer_dense_8_8_8_loss: 0.0011 - output_layer_dense_16_16_16_loss: 0.0014 - output_layer_dense_32_32_32_loss: 5.3826e-04 - output_layer_dense_64_64_64_loss: 1.4658e-04 - output_layer_dense_128_128_128_loss: 3.9574e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0265 - output_layer_dense_8_8_8_mean_absolute_error: 0.0224 - output_layer_dense_16_16_16_mean_absolute_error: 0.0234 - output_layer_dense_32_32_32_mean_absolute_error: 0.0169 - output_layer_dense_64_64_64_mean_absolute_error: 0.0089 - output_layer_dense_128_128_128_mean_absolute_error: 0.0044\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0015 - output_layer_dense_32_32_32_loss: 6.0636e-04 - output_layer_dense_64_64_64_loss: 1.4991e-04 - output_layer_dense_128_128_128_loss: 6.6843e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0273 - output_layer_dense_8_8_8_mean_absolute_error: 0.0231 - output_layer_dense_16_16_16_mean_absolute_error: 0.0235 - output_layer_dense_32_32_32_mean_absolute_error: 0.0176 - output_layer_dense_64_64_64_mean_absolute_error: 0.0090 - output_layer_dense_128_128_128_mean_absolute_error: 0.0062\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0015 - output_layer_dense_32_32_32_loss: 5.8576e-04 - output_layer_dense_64_64_64_loss: 1.5124e-04 - output_layer_dense_128_128_128_loss: 4.6797e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0275 - output_layer_dense_8_8_8_mean_absolute_error: 0.0236 - output_layer_dense_16_16_16_mean_absolute_error: 0.0244 - output_layer_dense_32_32_32_mean_absolute_error: 0.0171 - output_layer_dense_64_64_64_mean_absolute_error: 0.0090 - output_layer_dense_128_128_128_mean_absolute_error: 0.0050\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0059 - output_layer_dense_4_4_4_loss: 0.0019 - output_layer_dense_8_8_8_loss: 0.0015 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 5.6661e-04 - output_layer_dense_64_64_64_loss: 1.6007e-04 - output_layer_dense_128_128_128_loss: 4.7473e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0272 - output_layer_dense_8_8_8_mean_absolute_error: 0.0227 - output_layer_dense_16_16_16_mean_absolute_error: 0.0234 - output_layer_dense_32_32_32_mean_absolute_error: 0.0168 - output_layer_dense_64_64_64_mean_absolute_error: 0.0090 - output_layer_dense_128_128_128_mean_absolute_error: 0.0051\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0047 - output_layer_dense_4_4_4_loss: 0.0016 - output_layer_dense_8_8_8_loss: 0.0011 - output_layer_dense_16_16_16_loss: 0.0013 - output_layer_dense_32_32_32_loss: 5.4188e-04 - output_layer_dense_64_64_64_loss: 1.5339e-04 - output_layer_dense_128_128_128_loss: 4.2174e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0262 - output_layer_dense_8_8_8_mean_absolute_error: 0.0221 - output_layer_dense_16_16_16_mean_absolute_error: 0.0222 - output_layer_dense_32_32_32_mean_absolute_error: 0.0164 - output_layer_dense_64_64_64_mean_absolute_error: 0.0089 - output_layer_dense_128_128_128_mean_absolute_error: 0.0047        \n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0051 - output_layer_dense_4_4_4_loss: 0.0017 - output_layer_dense_8_8_8_loss: 0.0014 - output_layer_dense_16_16_16_loss: 0.0014 - output_layer_dense_32_32_32_loss: 5.3896e-04 - output_layer_dense_64_64_64_loss: 1.2017e-04 - output_layer_dense_128_128_128_loss: 3.3049e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0265 - output_layer_dense_8_8_8_mean_absolute_error: 0.0225 - output_layer_dense_16_16_16_mean_absolute_error: 0.0234 - output_layer_dense_32_32_32_mean_absolute_error: 0.0167 - output_layer_dense_64_64_64_mean_absolute_error: 0.0079 - output_layer_dense_128_128_128_mean_absolute_error: 0.0043\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0013 - output_layer_dense_16_16_16_loss: 0.0015 - output_layer_dense_32_32_32_loss: 5.3748e-04 - output_layer_dense_64_64_64_loss: 1.2207e-04 - output_layer_dense_128_128_128_loss: 2.8751e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0279 - output_layer_dense_8_8_8_mean_absolute_error: 0.0235 - output_layer_dense_16_16_16_mean_absolute_error: 0.0248 - output_layer_dense_32_32_32_mean_absolute_error: 0.0166 - output_layer_dense_64_64_64_mean_absolute_error: 0.0079 - output_layer_dense_128_128_128_mean_absolute_error: 0.0038\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0055 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0014 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 5.2274e-04 - output_layer_dense_64_64_64_loss: 1.1818e-04 - output_layer_dense_128_128_128_loss: 3.0027e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0277 - output_layer_dense_8_8_8_mean_absolute_error: 0.0234 - output_layer_dense_16_16_16_mean_absolute_error: 0.0244 - output_layer_dense_32_32_32_mean_absolute_error: 0.0161 - output_layer_dense_64_64_64_mean_absolute_error: 0.0076 - output_layer_dense_128_128_128_mean_absolute_error: 0.0039\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0051 - output_layer_dense_4_4_4_loss: 0.0017 - output_layer_dense_8_8_8_loss: 0.0012 - output_layer_dense_16_16_16_loss: 0.0015 - output_layer_dense_32_32_32_loss: 4.6083e-04 - output_layer_dense_64_64_64_loss: 1.1140e-04 - output_layer_dense_128_128_128_loss: 2.6998e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0263 - output_layer_dense_8_8_8_mean_absolute_error: 0.0226 - output_layer_dense_16_16_16_mean_absolute_error: 0.0233 - output_layer_dense_32_32_32_mean_absolute_error: 0.0156 - output_layer_dense_64_64_64_mean_absolute_error: 0.0077 - output_layer_dense_128_128_128_mean_absolute_error: 0.0036\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0044 - output_layer_dense_4_4_4_loss: 0.0015 - output_layer_dense_8_8_8_loss: 0.0011 - output_layer_dense_16_16_16_loss: 0.0012 - output_layer_dense_32_32_32_loss: 5.0348e-04 - output_layer_dense_64_64_64_loss: 1.1572e-04 - output_layer_dense_128_128_128_loss: 2.6105e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0263 - output_layer_dense_8_8_8_mean_absolute_error: 0.0225 - output_layer_dense_16_16_16_mean_absolute_error: 0.0224 - output_layer_dense_32_32_32_mean_absolute_error: 0.0164 - output_layer_dense_64_64_64_mean_absolute_error: 0.0079 - output_layer_dense_128_128_128_mean_absolute_error: 0.0036\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0043 - output_layer_dense_4_4_4_loss: 0.0014 - output_layer_dense_8_8_8_loss: 0.0011 - output_layer_dense_16_16_16_loss: 0.0012 - output_layer_dense_32_32_32_loss: 4.6583e-04 - output_layer_dense_64_64_64_loss: 1.0070e-04 - output_layer_dense_128_128_128_loss: 2.4246e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0255 - output_layer_dense_8_8_8_mean_absolute_error: 0.0219 - output_layer_dense_16_16_16_mean_absolute_error: 0.0222 - output_layer_dense_32_32_32_mean_absolute_error: 0.0153 - output_layer_dense_64_64_64_mean_absolute_error: 0.0073 - output_layer_dense_128_128_128_mean_absolute_error: 0.0035    \n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0054 - output_layer_dense_4_4_4_loss: 0.0018 - output_layer_dense_8_8_8_loss: 0.0014 - output_layer_dense_16_16_16_loss: 0.0016 - output_layer_dense_32_32_32_loss: 4.7647e-04 - output_layer_dense_64_64_64_loss: 1.0572e-04 - output_layer_dense_128_128_128_loss: 2.9398e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0270 - output_layer_dense_8_8_8_mean_absolute_error: 0.0230 - output_layer_dense_16_16_16_mean_absolute_error: 0.0235 - output_layer_dense_32_32_32_mean_absolute_error: 0.0158 - output_layer_dense_64_64_64_mean_absolute_error: 0.0075 - output_layer_dense_128_128_128_mean_absolute_error: 0.0038\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0044 - output_layer_dense_4_4_4_loss: 0.0015 - output_layer_dense_8_8_8_loss: 0.0010 - output_layer_dense_16_16_16_loss: 0.0012 - output_layer_dense_32_32_32_loss: 4.4880e-04 - output_layer_dense_64_64_64_loss: 1.0287e-04 - output_layer_dense_128_128_128_loss: 4.0080e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0263 - output_layer_dense_8_8_8_mean_absolute_error: 0.0224 - output_layer_dense_16_16_16_mean_absolute_error: 0.0225 - output_layer_dense_32_32_32_mean_absolute_error: 0.0154 - output_layer_dense_64_64_64_mean_absolute_error: 0.0072 - output_layer_dense_128_128_128_mean_absolute_error: 0.0047    \n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0042 - output_layer_dense_4_4_4_loss: 0.0014 - output_layer_dense_8_8_8_loss: 0.0010 - output_layer_dense_16_16_16_loss: 0.0012 - output_layer_dense_32_32_32_loss: 4.7179e-04 - output_layer_dense_64_64_64_loss: 9.7191e-05 - output_layer_dense_128_128_128_loss: 3.9830e-05 - output_layer_dense_4_4_4_mean_absolute_error: 0.0254 - output_layer_dense_8_8_8_mean_absolute_error: 0.0215 - output_layer_dense_16_16_16_mean_absolute_error: 0.0223 - output_layer_dense_32_32_32_mean_absolute_error: 0.0156 - output_layer_dense_64_64_64_mean_absolute_error: 0.0071 - output_layer_dense_128_128_128_mean_absolute_error: 0.0049\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "loss  :  0.004645986948162317\n",
      "output_layer_dense_4_4_4_loss  :  0.0015395345399156213\n",
      "output_layer_dense_8_8_8_loss  :  0.0011707185767591\n",
      "output_layer_dense_16_16_16_loss  :  0.0013013354036957026\n",
      "output_layer_dense_32_32_32_loss  :  0.00047933385940268636\n",
      "output_layer_dense_64_64_64_loss  :  0.00010526587720960379\n",
      "output_layer_dense_128_128_128_loss  :  4.979890582035296e-05\n",
      "output_layer_dense_4_4_4_mean_absolute_error  :  0.02588041126728058\n",
      "output_layer_dense_8_8_8_mean_absolute_error  :  0.022253287956118584\n",
      "output_layer_dense_16_16_16_mean_absolute_error  :  0.02253405936062336\n",
      "output_layer_dense_32_32_32_mean_absolute_error  :  0.015833618119359016\n",
      "output_layer_dense_64_64_64_mean_absolute_error  :  0.0073614236898720264\n",
      "output_layer_dense_128_128_128_mean_absolute_error  :  0.005735011771321297\n"
     ]
    }
   ],
   "source": [
    "TRAIN.train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = multiple.Multiple_Model_Gen(train_X_scaled, train_Y_scaled, 50, 128, input_shape = 58, min_no_layers = 3, max_no_layers = 3, model_per_batch = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_16_16_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_16_16_16 ( [(None, 58)]              0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_16_16_16 (Dense (None, 16)                944       \n",
      "_________________________________________________________________\n",
      "layer2_dense_16_16_16 (Dense (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "layer3_dense_16_16_16 (Dense (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "output_layer_dense_16_16_16  (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,505\n",
      "Trainable params: 1,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:204 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer dense_16_16_16 expects 1 input(s), but it received 5 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 58) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 58) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 58) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None, 58) dtype=float32>, <tf.Tensor 'IteratorGetNext:4' shape=(None, 58) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/multiple_model_gen_v1.py:40\u001b[0m, in \u001b[0;36mMultiple_Model_Gen.get_all_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m     input_x, input_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_lists(n)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# history = parallelModel.fit([self._train_x, self._train_x, self._train_x, self._train_x, self._train_x, self._train_x, self._train_x, self._train_x, self._train_x, self._train_x],\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#                         [self._train_y, self._train_y, self._train_y, self._train_y, self._train_y, self._train_y, self._train_y, self._train_y, self._train_y, self._train_y],\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#                         epochs=self._epochs, batch_size=self._batch_size\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#                         )\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mparallelModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Evaluate Best Running Model\u001b[39;00m\n\u001b[1;32m     42\u001b[0m scores \u001b[38;5;241m=\u001b[39m parallelModel\u001b[38;5;241m.\u001b[39mevaluate(input_x, input_labels, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1100\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1095\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1096\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1097\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1098\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1099\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1100\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1102\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:828\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name) \u001b[38;5;28;01mas\u001b[39;00m tm:\n\u001b[0;32m--> 828\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m   new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:871\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    869\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 871\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:725\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    729\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2969\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 2969\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3361\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3357\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3358\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3361\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3196\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3191\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3193\u001b[0m ]\n\u001b[1;32m   3194\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3195\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3204\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3205\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3208\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3209\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3210\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3211\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3212\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:990\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 990\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m    994\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m    995\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:634\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m     xla_context\u001b[38;5;241m.\u001b[39mExit()\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:977\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    976\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    978\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/input_spec.py:204 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer dense_16_16_16 expects 1 input(s), but it received 5 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 58) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 58) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, 58) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(None, 58) dtype=float32>, <tf.Tensor 'IteratorGetNext:4' shape=(None, 58) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "m.get_all_models()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "441a79e7978ad007ee49ac1a1197fffc94e685236b0df2483283c16abedd4251"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
