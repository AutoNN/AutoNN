{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/anish/ASC_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 11:38:23.078230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from ASC_ML import model_generation as model_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conf = {\"layer1\":8, \"layer2\":16, \"layer3\":32, \"layer4\":8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 11:38:24.184916: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-08 11:38:24.187381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-08 11:38:24.270468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 11:38:24.270801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-06-08 11:38:24.270847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-08 11:38:24.273589: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-08 11:38:24.273652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-08 11:38:24.275953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-08 11:38:24.276291: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-08 11:38:24.278553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-08 11:38:24.279857: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-08 11:38:24.284166: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-08 11:38:24.284298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 11:38:24.284521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 11:38:24.284647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-08 11:38:24.284968: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-08 11:38:24.285323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 11:38:24.285478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-06-08 11:38:24.285501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-08 11:38:24.285524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-08 11:38:24.285542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-08 11:38:24.285560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-08 11:38:24.285577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-08 11:38:24.285595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-08 11:38:24.285614: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-08 11:38:24.285633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-08 11:38:24.285697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 11:38:24.285878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 11:38:24.285982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-08 11:38:24.286009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-08 11:38:24.658347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-08 11:38:24.658372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-06-08 11:38:24.658378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-06-08 11:38:24.658518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 11:38:24.658658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 11:38:24.658771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 11:38:24.658863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4927 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-06-08 11:38:24.659062: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "nn_model_1 = model_gen.NN_ModelGeneration(model_name = \"model_X\", input_shape = 8, init_no_layers = 4, init_activation_fn = \"relu\", init_layer_conf = layer_conf, output_layer_conf = [1,\"softmax\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_8_16_32_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_8_16_32_8  [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_8_16_32_8 (Dens (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "layer2_dense_8_16_32_8 (Dens (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "layer3_dense_8_16_32_8 (Dens (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "layer4_dense_8_16_32_8 (Dens (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "output_layer_dense_8_16_32_8 (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,033\n",
      "Trainable params: 1,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model_1.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 4, 'relu', {'layer1': 8, 'layer2': 16, 'layer3': 32, 'layer4': 8}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model_1.model_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conf = {\"layer_append1\":8, \"layer_append2\":4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_1.append_model(no_layers = 2, layer_conf = layer_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_X\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "layer1 (Dense)               (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "layer4 (Dense)               (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "layer_append1 (Dense)        (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "layer_append2 (Dense)        (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,137\n",
      "Trainable params: 1,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model_1.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 6,\n",
       " 'relu',\n",
       " {'layer1': 8,\n",
       "  'layer2': 16,\n",
       "  'layer3': 32,\n",
       "  'layer4': 8,\n",
       "  'layer_append1': 8,\n",
       "  'layer_append2': 4}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model_1.model_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_options = [16,32,64,128,196,256]\n",
    "two_layer_possibilities = [node_options, node_options, node_options]https://meet.google.com/gyb-wcat-fpv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "all_layer_perm = []\n",
    "for i in range(2,4):\n",
    "    layer_choice = []\n",
    "    for j in range(i):\n",
    "        layer_choice.append(node_options)\n",
    "    all_layer_perm.append(list(itertools.product(*layer_choice)))\n",
    "print(len(all_layer_perm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "for lst in all_layer_perm:\n",
    "    print(len(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, 16, 16),\n",
       " (16, 16, 32),\n",
       " (16, 16, 64),\n",
       " (16, 16, 128),\n",
       " (16, 16, 196),\n",
       " (16, 16, 256),\n",
       " (16, 32, 16),\n",
       " (16, 32, 32),\n",
       " (16, 32, 64),\n",
       " (16, 32, 128),\n",
       " (16, 32, 196),\n",
       " (16, 32, 256),\n",
       " (16, 64, 16),\n",
       " (16, 64, 32),\n",
       " (16, 64, 64),\n",
       " (16, 64, 128),\n",
       " (16, 64, 196),\n",
       " (16, 64, 256),\n",
       " (16, 128, 16),\n",
       " (16, 128, 32),\n",
       " (16, 128, 64),\n",
       " (16, 128, 128),\n",
       " (16, 128, 196),\n",
       " (16, 128, 256),\n",
       " (16, 196, 16),\n",
       " (16, 196, 32),\n",
       " (16, 196, 64),\n",
       " (16, 196, 128),\n",
       " (16, 196, 196),\n",
       " (16, 196, 256),\n",
       " (16, 256, 16),\n",
       " (16, 256, 32),\n",
       " (16, 256, 64),\n",
       " (16, 256, 128),\n",
       " (16, 256, 196),\n",
       " (16, 256, 256),\n",
       " (32, 16, 16),\n",
       " (32, 16, 32),\n",
       " (32, 16, 64),\n",
       " (32, 16, 128),\n",
       " (32, 16, 196),\n",
       " (32, 16, 256),\n",
       " (32, 32, 16),\n",
       " (32, 32, 32),\n",
       " (32, 32, 64),\n",
       " (32, 32, 128),\n",
       " (32, 32, 196),\n",
       " (32, 32, 256),\n",
       " (32, 64, 16),\n",
       " (32, 64, 32),\n",
       " (32, 64, 64),\n",
       " (32, 64, 128),\n",
       " (32, 64, 196),\n",
       " (32, 64, 256),\n",
       " (32, 128, 16),\n",
       " (32, 128, 32),\n",
       " (32, 128, 64),\n",
       " (32, 128, 128),\n",
       " (32, 128, 196),\n",
       " (32, 128, 256),\n",
       " (32, 196, 16),\n",
       " (32, 196, 32),\n",
       " (32, 196, 64),\n",
       " (32, 196, 128),\n",
       " (32, 196, 196),\n",
       " (32, 196, 256),\n",
       " (32, 256, 16),\n",
       " (32, 256, 32),\n",
       " (32, 256, 64),\n",
       " (32, 256, 128),\n",
       " (32, 256, 196),\n",
       " (32, 256, 256),\n",
       " (64, 16, 16),\n",
       " (64, 16, 32),\n",
       " (64, 16, 64),\n",
       " (64, 16, 128),\n",
       " (64, 16, 196),\n",
       " (64, 16, 256),\n",
       " (64, 32, 16),\n",
       " (64, 32, 32),\n",
       " (64, 32, 64),\n",
       " (64, 32, 128),\n",
       " (64, 32, 196),\n",
       " (64, 32, 256),\n",
       " (64, 64, 16),\n",
       " (64, 64, 32),\n",
       " (64, 64, 64),\n",
       " (64, 64, 128),\n",
       " (64, 64, 196),\n",
       " (64, 64, 256),\n",
       " (64, 128, 16),\n",
       " (64, 128, 32),\n",
       " (64, 128, 64),\n",
       " (64, 128, 128),\n",
       " (64, 128, 196),\n",
       " (64, 128, 256),\n",
       " (64, 196, 16),\n",
       " (64, 196, 32),\n",
       " (64, 196, 64),\n",
       " (64, 196, 128),\n",
       " (64, 196, 196),\n",
       " (64, 196, 256),\n",
       " (64, 256, 16),\n",
       " (64, 256, 32),\n",
       " (64, 256, 64),\n",
       " (64, 256, 128),\n",
       " (64, 256, 196),\n",
       " (64, 256, 256),\n",
       " (128, 16, 16),\n",
       " (128, 16, 32),\n",
       " (128, 16, 64),\n",
       " (128, 16, 128),\n",
       " (128, 16, 196),\n",
       " (128, 16, 256),\n",
       " (128, 32, 16),\n",
       " (128, 32, 32),\n",
       " (128, 32, 64),\n",
       " (128, 32, 128),\n",
       " (128, 32, 196),\n",
       " (128, 32, 256),\n",
       " (128, 64, 16),\n",
       " (128, 64, 32),\n",
       " (128, 64, 64),\n",
       " (128, 64, 128),\n",
       " (128, 64, 196),\n",
       " (128, 64, 256),\n",
       " (128, 128, 16),\n",
       " (128, 128, 32),\n",
       " (128, 128, 64),\n",
       " (128, 128, 128),\n",
       " (128, 128, 196),\n",
       " (128, 128, 256),\n",
       " (128, 196, 16),\n",
       " (128, 196, 32),\n",
       " (128, 196, 64),\n",
       " (128, 196, 128),\n",
       " (128, 196, 196),\n",
       " (128, 196, 256),\n",
       " (128, 256, 16),\n",
       " (128, 256, 32),\n",
       " (128, 256, 64),\n",
       " (128, 256, 128),\n",
       " (128, 256, 196),\n",
       " (128, 256, 256),\n",
       " (196, 16, 16),\n",
       " (196, 16, 32),\n",
       " (196, 16, 64),\n",
       " (196, 16, 128),\n",
       " (196, 16, 196),\n",
       " (196, 16, 256),\n",
       " (196, 32, 16),\n",
       " (196, 32, 32),\n",
       " (196, 32, 64),\n",
       " (196, 32, 128),\n",
       " (196, 32, 196),\n",
       " (196, 32, 256),\n",
       " (196, 64, 16),\n",
       " (196, 64, 32),\n",
       " (196, 64, 64),\n",
       " (196, 64, 128),\n",
       " (196, 64, 196),\n",
       " (196, 64, 256),\n",
       " (196, 128, 16),\n",
       " (196, 128, 32),\n",
       " (196, 128, 64),\n",
       " (196, 128, 128),\n",
       " (196, 128, 196),\n",
       " (196, 128, 256),\n",
       " (196, 196, 16),\n",
       " (196, 196, 32),\n",
       " (196, 196, 64),\n",
       " (196, 196, 128),\n",
       " (196, 196, 196),\n",
       " (196, 196, 256),\n",
       " (196, 256, 16),\n",
       " (196, 256, 32),\n",
       " (196, 256, 64),\n",
       " (196, 256, 128),\n",
       " (196, 256, 196),\n",
       " (196, 256, 256),\n",
       " (256, 16, 16),\n",
       " (256, 16, 32),\n",
       " (256, 16, 64),\n",
       " (256, 16, 128),\n",
       " (256, 16, 196),\n",
       " (256, 16, 256),\n",
       " (256, 32, 16),\n",
       " (256, 32, 32),\n",
       " (256, 32, 64),\n",
       " (256, 32, 128),\n",
       " (256, 32, 196),\n",
       " (256, 32, 256),\n",
       " (256, 64, 16),\n",
       " (256, 64, 32),\n",
       " (256, 64, 64),\n",
       " (256, 64, 128),\n",
       " (256, 64, 196),\n",
       " (256, 64, 256),\n",
       " (256, 128, 16),\n",
       " (256, 128, 32),\n",
       " (256, 128, 64),\n",
       " (256, 128, 128),\n",
       " (256, 128, 196),\n",
       " (256, 128, 256),\n",
       " (256, 196, 16),\n",
       " (256, 196, 32),\n",
       " (256, 196, 64),\n",
       " (256, 196, 128),\n",
       " (256, 196, 196),\n",
       " (256, 196, 256),\n",
       " (256, 256, 16),\n",
       " (256, 256, 32),\n",
       " (256, 256, 64),\n",
       " (256, 256, 128),\n",
       " (256, 256, 196),\n",
       " (256, 256, 256)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "list(itertools.product(*two_layer_possibilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
