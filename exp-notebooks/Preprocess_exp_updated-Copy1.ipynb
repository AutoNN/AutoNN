{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/anish/ASC_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 17:03:36.432879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from ASC_ML import dataframe_extractor as de\n",
    "from ASC_ML import model_generation as model_gen\n",
    "from ASC_ML import model_gen_train_test as testing\n",
    "from dask_ml.preprocessing import LabelEncoder\n",
    "# from dask_ml.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASC_ML import multiple_model_gen_v1 as multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "# import pandas as pd\n",
    "# data = dd.from_pandas(pd.Series(['a', 'a', 'b'], dtype='category'),\n",
    "#                      npartitions=1)\n",
    "# le = LabelEncoder()\n",
    "# le.fit_transform(data).compute()\n",
    "# print(type(le.fit_transform(data).compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading single csv from /home/anish/ASC-ML-EXP-DATASETS/LinReg-tabular/house-prices-advanced-regression-techniques/train.csv\n",
      "Train Dataset X Columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1.0        60.0       RL         65.0   8450.0   Pave   NaN      Reg   \n",
       "1  2.0        20.0       RL         80.0   9600.0   Pave   NaN      Reg   \n",
       "2  3.0        60.0       RL         68.0  11250.0   Pave   NaN      IR1   \n",
       "3  4.0        70.0       RL         60.0   9550.0   Pave   NaN      IR1   \n",
       "4  5.0        60.0       RL         84.0  14260.0   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "1         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "2         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "3         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "4         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0     0.0    2.0  2008.0        WD         Normal  \n",
       "1     0.0    5.0  2007.0        WD         Normal  \n",
       "2     0.0    9.0  2008.0        WD         Normal  \n",
       "3     0.0    2.0  2006.0        WD        Abnorml  \n",
       "4     0.0   12.0  2008.0        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For House Prediction Dataset https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data?select=train.csv\n",
    "directory1 = \"/home/anish/ASC-ML-EXP-DATASETS/LinReg-tabular/house-prices-advanced-regression-techniques/train.csv\"\n",
    "\n",
    "\n",
    "# returns list of dask dataframe [singular_df_x, singular_df_y] or [train_df_x, train_df_y, test_df_x, test_df_y]\n",
    "dataset_list = de.DataframeExtractor_csv(directory1, label_names = [\"SalePrice\"]).df_list\n",
    "\n",
    "print(\"Train Dataset X Columns\")\n",
    "dataset_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice\n",
       "0   208500.0\n",
       "1   181500.0\n",
       "2   223500.0\n",
       "3   140000.0\n",
       "4   250000.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dataset_list[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1.0        60.0       RL         65.0   8450.0   Pave     0      Reg   \n",
       "1  2.0        20.0       RL         80.0   9600.0   Pave     0      Reg   \n",
       "2  3.0        60.0       RL         68.0  11250.0   Pave     0      IR1   \n",
       "3  4.0        70.0       RL         60.0   9550.0   Pave     0      IR1   \n",
       "4  5.0        60.0       RL         84.0  14260.0   Pave     0      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "1         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "2         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "3         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "4         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0     0.0    2.0  2008.0        WD         Normal  \n",
       "1     0.0    5.0  2007.0        WD         Normal  \n",
       "2     0.0    9.0  2008.0        WD         Normal  \n",
       "3     0.0    2.0  2006.0        WD        Abnorml  \n",
       "4     0.0   12.0  2008.0        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/dask/dataframe/core.py:3946: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('MSSubClass', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1.0       60.0       RL         65.0   8450.0   Pave     0      Reg   \n",
       "1  2.0       20.0       RL         80.0   9600.0   Pave     0      Reg   \n",
       "2  3.0       60.0       RL         68.0  11250.0   Pave     0      IR1   \n",
       "3  4.0       70.0       RL         60.0   9550.0   Pave     0      IR1   \n",
       "4  5.0       60.0       RL         84.0  14260.0   Pave     0      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "1         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "2         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "3         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "4         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "\n",
       "  MiscVal MoSold  YrSold SaleType  SaleCondition  \n",
       "0     0.0    2.0  2008.0       WD         Normal  \n",
       "1     0.0    5.0  2007.0       WD         Normal  \n",
       "2     0.0    9.0  2008.0       WD         Normal  \n",
       "3     0.0    2.0  2006.0       WD        Abnorml  \n",
       "4     0.0   12.0  2008.0       WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['MSSubClass'] = train_x['MSSubClass'].apply(str)\n",
    "\n",
    "train_x['OverallCond'] = train_x['OverallCond'].astype(str)\n",
    "\n",
    "train_x['YrSold'] = train_x['YrSold'].astype(str)\n",
    "train_x['MoSold'] = train_x['MoSold'].astype(str)\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = train_x['LotShape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder() \n",
    "# le.fit_transform(a).compute()\n",
    "# train_x['LotShape'] = le.fit_transform(train_x['LotShape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyval(allkeys):\n",
    "    i = 0\n",
    "    keyvalpairs = list()\n",
    "    for key in allkeys:\n",
    "        keyvalpairs.append((key,i))\n",
    "        i+=1\n",
    "    return dict(keyvalpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['FireplaceQu', 'LotShape']\n",
    "cols = ['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold']\n",
    "keys = {}\n",
    "for col in cols:\n",
    "    key = train_x[col].unique()\n",
    "    keyvalpairs = keyval(key)\n",
    "    keys.update({col:keyvalpairs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FireplaceQu': {0: 0, 'TA': 1, 'Gd': 2, 'Fa': 3, 'Ex': 4, 'Po': 5},\n",
       " 'BsmtQual': {'Gd': 0, 'TA': 1, 'Ex': 2, 0: 3, 'Fa': 4},\n",
       " 'BsmtCond': {'TA': 0, 'Gd': 1, 0: 2, 'Fa': 3, 'Po': 4},\n",
       " 'GarageQual': {'TA': 0, 'Fa': 1, 'Gd': 2, 0: 3, 'Ex': 4, 'Po': 5},\n",
       " 'GarageCond': {'TA': 0, 'Fa': 1, 0: 2, 'Gd': 3, 'Po': 4, 'Ex': 5},\n",
       " 'ExterQual': {'Gd': 0, 'TA': 1, 'Ex': 2, 'Fa': 3},\n",
       " 'ExterCond': {'TA': 0, 'Gd': 1, 'Fa': 2, 'Po': 3, 'Ex': 4},\n",
       " 'HeatingQC': {'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4},\n",
       " 'PoolQC': {0: 0, 'Ex': 1, 'Fa': 2, 'Gd': 3},\n",
       " 'KitchenQual': {'Gd': 0, 'TA': 1, 'Ex': 2, 'Fa': 3},\n",
       " 'BsmtFinType1': {'GLQ': 0,\n",
       "  'ALQ': 1,\n",
       "  'Unf': 2,\n",
       "  'Rec': 3,\n",
       "  'BLQ': 4,\n",
       "  0: 5,\n",
       "  'LwQ': 6},\n",
       " 'BsmtFinType2': {'Unf': 0,\n",
       "  'BLQ': 1,\n",
       "  0: 2,\n",
       "  'ALQ': 3,\n",
       "  'Rec': 4,\n",
       "  'LwQ': 5,\n",
       "  'GLQ': 6},\n",
       " 'Functional': {'Typ': 0,\n",
       "  'Min1': 1,\n",
       "  'Maj1': 2,\n",
       "  'Min2': 3,\n",
       "  'Mod': 4,\n",
       "  'Maj2': 5,\n",
       "  'Sev': 6},\n",
       " 'Fence': {0: 0, 'MnPrv': 1, 'GdWo': 2, 'GdPrv': 3, 'MnWw': 4},\n",
       " 'BsmtExposure': {'No': 0, 'Gd': 1, 'Mn': 2, 'Av': 3, 0: 4},\n",
       " 'GarageFinish': {'RFn': 0, 'Unf': 1, 'Fin': 2, 0: 3},\n",
       " 'LandSlope': {'Gtl': 0, 'Mod': 1, 'Sev': 2},\n",
       " 'LotShape': {'Reg': 0, 'IR1': 1, 'IR2': 2, 'IR3': 3},\n",
       " 'PavedDrive': {'Y': 0, 'N': 1, 'P': 2},\n",
       " 'Street': {'Pave': 0, 'Grvl': 1},\n",
       " 'Alley': {0: 0, 'Grvl': 1, 'Pave': 2},\n",
       " 'CentralAir': {'Y': 0, 'N': 1},\n",
       " 'MSSubClass': {'60.0': 0,\n",
       "  '20.0': 1,\n",
       "  '70.0': 2,\n",
       "  '50.0': 3,\n",
       "  '190.0': 4,\n",
       "  '45.0': 5,\n",
       "  '90.0': 6,\n",
       "  '120.0': 7,\n",
       "  '30.0': 8,\n",
       "  '85.0': 9,\n",
       "  '80.0': 10,\n",
       "  '160.0': 11,\n",
       "  '75.0': 12,\n",
       "  '180.0': 13,\n",
       "  '40.0': 14},\n",
       " 'OverallCond': {'5.0': 0,\n",
       "  '8.0': 1,\n",
       "  '6.0': 2,\n",
       "  '7.0': 3,\n",
       "  '4.0': 4,\n",
       "  '2.0': 5,\n",
       "  '3.0': 6,\n",
       "  '9.0': 7,\n",
       "  '1.0': 8},\n",
       " 'YrSold': {'2008.0': 0, '2007.0': 1, '2006.0': 2, '2009.0': 3, '2010.0': 4},\n",
       " 'MoSold': {'2.0': 0,\n",
       "  '5.0': 1,\n",
       "  '9.0': 2,\n",
       "  '12.0': 3,\n",
       "  '10.0': 4,\n",
       "  '8.0': 5,\n",
       "  '11.0': 6,\n",
       "  '4.0': 7,\n",
       "  '1.0': 8,\n",
       "  '7.0': 9,\n",
       "  '3.0': 10,\n",
       "  '6.0': 11}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_x.replace(keys).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['FireplaceQu'].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
       "0  1.0           0       RL         65.0   8450.0       0      0         0   \n",
       "1  2.0           1       RL         80.0   9600.0       0      0         0   \n",
       "2  3.0           0       RL         68.0  11250.0       0      0         1   \n",
       "3  4.0           2       RL         60.0   9550.0       0      0         1   \n",
       "4  5.0           0       RL         84.0  14260.0       0      0         1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch  PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "1         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "2         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "3         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "4         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0     0.0      0       0        WD         Normal  \n",
       "1     0.0      1       1        WD         Normal  \n",
       "2     0.0      2       0        WD         Normal  \n",
       "3     0.0      0       2        WD        Abnorml  \n",
       "4     0.0      3       0        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = []\n",
    "for col in train_X.columns:\n",
    "#     print(type(col))\n",
    "    try:\n",
    "        a = train_X[col].astype(float).compute()\n",
    "    except ValueError:\n",
    "#         print('Couldn\\'t covert %s to float' % col)\n",
    "        cols_to_remove.append(col)\n",
    "        pass\n",
    "\n",
    "# keep only the columns in df that do not contain string\n",
    "train_X = train_X[[col for col in train_X.columns if col not in cols_to_remove]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'LandContour', 'Utilities', 'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'Electrical', 'GarageType', 'MiscFeature', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "print(cols_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.drop([\"Id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsklearn.preprocessing.MinMaxScalerrain_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_list[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_X)\n",
    "train_X_scaled = scaler_x.transform(train_X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(dataset_list[1])\n",
    "train_Y_scaled = scaler_y.transform(dataset_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = train_X.columns.to_list()\n",
    "# scaler_d = MinMaxScaler()\n",
    "# train_X.columns = list(train_X.columns)\n",
    "# scaled_train_X = scaler_d.fit_transform(train_X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.20766773, 0.0334198 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07142857, 0.25559105, 0.03879502, ..., 0.        , 0.09090909,\n",
       "        0.25      ],\n",
       "       [0.        , 0.2172524 , 0.04650728, ..., 0.        , 0.18181818,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.14285714, 0.21086262, 0.03618687, ..., 0.16129032, 0.09090909,\n",
       "        1.        ],\n",
       "       [0.07142857, 0.2172524 , 0.03934189, ..., 0.        , 0.63636364,\n",
       "        1.        ],\n",
       "       [0.07142857, 0.23961661, 0.04037019, ..., 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_scaled\n",
    "# train_Y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN = multiple.Multiple_Model_Gen(train_X_scaled, train_Y_scaled, 58, 1, None, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = TRAIN.get_models()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN.get_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = multiple.Multiple_Model_Gen(train_X_scaled, train_Y_scaled, 50, 128, input_shape = 58, min_no_layers = 3, max_no_layers = 3, model_per_batch = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 17:03:49.286864: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-18 17:03:49.287069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-06-18 17:03:49.287448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-18 17:03:49.287934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-06-18 17:03:49.288013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-18 17:03:49.292548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-18 17:03:49.292685: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-18 17:03:49.296396: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-18 17:03:49.297203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-18 17:03:49.300267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-18 17:03:49.302059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-18 17:03:49.307519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-18 17:03:49.307662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-18 17:03:49.307931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-18 17:03:49.308087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-18 17:03:49.308502: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-18 17:03:49.308848: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-06-18 17:03:49.308976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-18 17:03:49.309159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-06-18 17:03:49.309198: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-18 17:03:49.309231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-06-18 17:03:49.309260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-06-18 17:03:49.309290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-06-18 17:03:49.309319: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-06-18 17:03:49.309349: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-06-18 17:03:49.309380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-06-18 17:03:49.309411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-06-18 17:03:49.309491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-18 17:03:49.309728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-18 17:03:49.309883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-06-18 17:03:49.309937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-06-18 17:03:49.708974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-06-18 17:03:49.709000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-06-18 17:03:49.709006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-06-18 17:03:49.709155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-18 17:03:49.709303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-18 17:03:49.709419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-18 17:03:49.709514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4993 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-06-18 17:03:49.888929: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-06-18 17:03:49.905961: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_dense_16_16_16 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_16_16_32 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_16_32_16 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_16_32_32 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_32_16_16 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_16_16_16 (Dense)   (None, 16)           944         input_layer_dense_16_16_16[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_16_16_32 (Dense)   (None, 16)           944         input_layer_dense_16_16_32[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_16_32_16 (Dense)   (None, 16)           944         input_layer_dense_16_32_16[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_16_32_32 (Dense)   (None, 16)           944         input_layer_dense_16_32_32[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_32_16_16 (Dense)   (None, 32)           1888        input_layer_dense_32_16_16[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_16_16_16 (Dense)   (None, 16)           272         layer1_dense_16_16_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_16_16_32 (Dense)   (None, 16)           272         layer1_dense_16_16_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_16_32_16 (Dense)   (None, 32)           544         layer1_dense_16_32_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_16_32_32 (Dense)   (None, 32)           544         layer1_dense_16_32_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_32_16_16 (Dense)   (None, 16)           528         layer1_dense_32_16_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_16_16_16 (Dense)   (None, 16)           272         layer2_dense_16_16_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_16_16_32 (Dense)   (None, 32)           544         layer2_dense_16_16_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_16_32_16 (Dense)   (None, 16)           528         layer2_dense_16_32_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_16_32_32 (Dense)   (None, 32)           1056        layer2_dense_16_32_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_32_16_16 (Dense)   (None, 16)           272         layer2_dense_32_16_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_16_16_16 (De (None, 1)            17          layer3_dense_16_16_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_16_16_32 (De (None, 1)            33          layer3_dense_16_16_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_16_32_16 (De (None, 1)            17          layer3_dense_16_32_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_16_32_32 (De (None, 1)            33          layer3_dense_16_32_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_32_16_16 (De (None, 1)            17          layer3_dense_32_16_16[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 10,613\n",
      "Trainable params: 10,613\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-18 17:03:54.947494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 7s 4ms/step - loss: 3.2404 - output_layer_dense_16_16_16_loss: 0.6481 - output_layer_dense_16_16_32_loss: 0.6481 - output_layer_dense_16_32_16_loss: 0.6481 - output_layer_dense_16_32_32_loss: 0.6481 - output_layer_dense_32_16_16_loss: 0.6481 - output_layer_dense_16_16_16_mean_absolute_error: 0.7975 - output_layer_dense_16_16_32_mean_absolute_error: 0.7975 - output_layer_dense_16_32_16_mean_absolute_error: 0.7975 - output_layer_dense_16_32_32_mean_absolute_error: 0.7975 - output_layer_dense_32_16_16_mean_absolute_error: 0.7975\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2282 - output_layer_dense_16_16_16_loss: 0.6456 - output_layer_dense_16_16_32_loss: 0.6456 - output_layer_dense_16_32_16_loss: 0.6456 - output_layer_dense_16_32_32_loss: 0.6456 - output_layer_dense_32_16_16_loss: 0.6456 - output_layer_dense_16_16_16_mean_absolute_error: 0.7962 - output_layer_dense_16_16_32_mean_absolute_error: 0.7962 - output_layer_dense_16_32_16_mean_absolute_error: 0.7962 - output_layer_dense_16_32_32_mean_absolute_error: 0.7962 - output_layer_dense_32_16_16_mean_absolute_error: 0.7962\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2159 - output_layer_dense_16_16_16_loss: 0.6432 - output_layer_dense_16_16_32_loss: 0.6432 - output_layer_dense_16_32_16_loss: 0.6432 - output_layer_dense_16_32_32_loss: 0.6432 - output_layer_dense_32_16_16_loss: 0.6432 - output_layer_dense_16_16_16_mean_absolute_error: 0.7938 - output_layer_dense_16_16_32_mean_absolute_error: 0.7938 - output_layer_dense_16_32_16_mean_absolute_error: 0.7938 - output_layer_dense_16_32_32_mean_absolute_error: 0.7938 - output_layer_dense_32_16_16_mean_absolute_error: 0.7938\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2519 - output_layer_dense_16_16_16_loss: 0.6504 - output_layer_dense_16_16_32_loss: 0.6504 - output_layer_dense_16_32_16_loss: 0.6504 - output_layer_dense_16_32_32_loss: 0.6504 - output_layer_dense_32_16_16_loss: 0.6504 - output_layer_dense_16_16_16_mean_absolute_error: 0.7995 - output_layer_dense_16_16_32_mean_absolute_error: 0.7995 - output_layer_dense_16_32_16_mean_absolute_error: 0.7995 - output_layer_dense_16_32_32_mean_absolute_error: 0.7995 - output_layer_dense_32_16_16_mean_absolute_error: 0.7995\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2452 - output_layer_dense_16_16_16_loss: 0.6490 - output_layer_dense_16_16_32_loss: 0.6490 - output_layer_dense_16_32_16_loss: 0.6490 - output_layer_dense_16_32_32_loss: 0.6490 - output_layer_dense_32_16_16_loss: 0.6490 - output_layer_dense_16_16_16_mean_absolute_error: 0.7984 - output_layer_dense_16_16_32_mean_absolute_error: 0.7984 - output_layer_dense_16_32_16_mean_absolute_error: 0.7984 - output_layer_dense_16_32_32_mean_absolute_error: 0.7984 - output_layer_dense_32_16_16_mean_absolute_error: 0.7984\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2433 - output_layer_dense_16_16_16_loss: 0.6487 - output_layer_dense_16_16_32_loss: 0.6487 - output_layer_dense_16_32_16_loss: 0.6487 - output_layer_dense_16_32_32_loss: 0.6487 - output_layer_dense_32_16_16_loss: 0.6487 - output_layer_dense_16_16_16_mean_absolute_error: 0.7979 - output_layer_dense_16_16_32_mean_absolute_error: 0.7979 - output_layer_dense_16_32_16_mean_absolute_error: 0.7979 - output_layer_dense_16_32_32_mean_absolute_error: 0.7979 - output_layer_dense_32_16_16_mean_absolute_error: 0.7979\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2316 - output_layer_dense_16_16_16_loss: 0.6463 - output_layer_dense_16_16_32_loss: 0.6463 - output_layer_dense_16_32_16_loss: 0.6463 - output_layer_dense_16_32_32_loss: 0.6463 - output_layer_dense_32_16_16_loss: 0.6463 - output_layer_dense_16_16_16_mean_absolute_error: 0.7967 - output_layer_dense_16_16_32_mean_absolute_error: 0.7967 - output_layer_dense_16_32_16_mean_absolute_error: 0.7967 - output_layer_dense_16_32_32_mean_absolute_error: 0.7967 - output_layer_dense_32_16_16_mean_absolute_error: 0.7967\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2345 - output_layer_dense_16_16_16_loss: 0.6469 - output_layer_dense_16_16_32_loss: 0.6469 - output_layer_dense_16_32_16_loss: 0.6469 - output_layer_dense_16_32_32_loss: 0.6469 - output_layer_dense_32_16_16_loss: 0.6469 - output_layer_dense_16_16_16_mean_absolute_error: 0.7966 - output_layer_dense_16_16_32_mean_absolute_error: 0.7966 - output_layer_dense_16_32_16_mean_absolute_error: 0.7966 - output_layer_dense_16_32_32_mean_absolute_error: 0.7966 - output_layer_dense_32_16_16_mean_absolute_error: 0.7966\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2529 - output_layer_dense_16_16_16_loss: 0.6506 - output_layer_dense_16_16_32_loss: 0.6506 - output_layer_dense_16_32_16_loss: 0.6506 - output_layer_dense_16_32_32_loss: 0.6506 - output_layer_dense_32_16_16_loss: 0.6506 - output_layer_dense_16_16_16_mean_absolute_error: 0.7997 - output_layer_dense_16_16_32_mean_absolute_error: 0.7997 - output_layer_dense_16_32_16_mean_absolute_error: 0.7997 - output_layer_dense_16_32_32_mean_absolute_error: 0.7997 - output_layer_dense_32_16_16_mean_absolute_error: 0.7997\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2248 - output_layer_dense_16_16_16_loss: 0.6450 - output_layer_dense_16_16_32_loss: 0.6450 - output_layer_dense_16_32_16_loss: 0.6450 - output_layer_dense_16_32_32_loss: 0.6450 - output_layer_dense_32_16_16_loss: 0.6450 - output_layer_dense_16_16_16_mean_absolute_error: 0.7945 - output_layer_dense_16_16_32_mean_absolute_error: 0.7945 - output_layer_dense_16_32_16_mean_absolute_error: 0.7945 - output_layer_dense_16_32_32_mean_absolute_error: 0.7945 - output_layer_dense_32_16_16_mean_absolute_error: 0.7945\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2489 - output_layer_dense_16_16_16_loss: 0.6498 - output_layer_dense_16_16_32_loss: 0.6498 - output_layer_dense_16_32_16_loss: 0.6498 - output_layer_dense_16_32_32_loss: 0.6498 - output_layer_dense_32_16_16_loss: 0.6498 - output_layer_dense_16_16_16_mean_absolute_error: 0.7983 - output_layer_dense_16_16_32_mean_absolute_error: 0.7983 - output_layer_dense_16_32_16_mean_absolute_error: 0.7983 - output_layer_dense_16_32_32_mean_absolute_error: 0.7983 - output_layer_dense_32_16_16_mean_absolute_error: 0.7983\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2214 - output_layer_dense_16_16_16_loss: 0.6443 - output_layer_dense_16_16_32_loss: 0.6443 - output_layer_dense_16_32_16_loss: 0.6443 - output_layer_dense_16_32_32_loss: 0.6443 - output_layer_dense_32_16_16_loss: 0.6443 - output_layer_dense_16_16_16_mean_absolute_error: 0.7946 - output_layer_dense_16_16_32_mean_absolute_error: 0.7946 - output_layer_dense_16_32_16_mean_absolute_error: 0.7946 - output_layer_dense_16_32_32_mean_absolute_error: 0.7946 - output_layer_dense_32_16_16_mean_absolute_error: 0.7946\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2432 - output_layer_dense_16_16_16_loss: 0.6486 - output_layer_dense_16_16_32_loss: 0.6486 - output_layer_dense_16_32_16_loss: 0.6486 - output_layer_dense_16_32_32_loss: 0.6486 - output_layer_dense_32_16_16_loss: 0.6486 - output_layer_dense_16_16_16_mean_absolute_error: 0.7982 - output_layer_dense_16_16_32_mean_absolute_error: 0.7982 - output_layer_dense_16_32_16_mean_absolute_error: 0.7982 - output_layer_dense_16_32_32_mean_absolute_error: 0.7982 - output_layer_dense_32_16_16_mean_absolute_error: 0.7982\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2276 - output_layer_dense_16_16_16_loss: 0.6455 - output_layer_dense_16_16_32_loss: 0.6455 - output_layer_dense_16_32_16_loss: 0.6455 - output_layer_dense_16_32_32_loss: 0.6455 - output_layer_dense_32_16_16_loss: 0.6455 - output_layer_dense_16_16_16_mean_absolute_error: 0.7961 - output_layer_dense_16_16_32_mean_absolute_error: 0.7961 - output_layer_dense_16_32_16_mean_absolute_error: 0.7961 - output_layer_dense_16_32_32_mean_absolute_error: 0.7961 - output_layer_dense_32_16_16_mean_absolute_error: 0.7961\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2456 - output_layer_dense_16_16_16_loss: 0.6491 - output_layer_dense_16_16_32_loss: 0.6491 - output_layer_dense_16_32_16_loss: 0.6491 - output_layer_dense_16_32_32_loss: 0.6491 - output_layer_dense_32_16_16_loss: 0.6491 - output_layer_dense_16_16_16_mean_absolute_error: 0.7983 - output_layer_dense_16_16_32_mean_absolute_error: 0.7983 - output_layer_dense_16_32_16_mean_absolute_error: 0.7983 - output_layer_dense_16_32_32_mean_absolute_error: 0.7983 - output_layer_dense_32_16_16_mean_absolute_error: 0.7983\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2471 - output_layer_dense_16_16_16_loss: 0.6494 - output_layer_dense_16_16_32_loss: 0.6494 - output_layer_dense_16_32_16_loss: 0.6494 - output_layer_dense_16_32_32_loss: 0.6494 - output_layer_dense_32_16_16_loss: 0.6494 - output_layer_dense_16_16_16_mean_absolute_error: 0.7983 - output_layer_dense_16_16_32_mean_absolute_error: 0.7983 - output_layer_dense_16_32_16_mean_absolute_error: 0.7983 - output_layer_dense_16_32_32_mean_absolute_error: 0.7983 - output_layer_dense_32_16_16_mean_absolute_error: 0.7983\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2292 - output_layer_dense_16_16_16_loss: 0.6458 - output_layer_dense_16_16_32_loss: 0.6458 - output_layer_dense_16_32_16_loss: 0.6458 - output_layer_dense_16_32_32_loss: 0.6458 - output_layer_dense_32_16_16_loss: 0.6458 - output_layer_dense_16_16_16_mean_absolute_error: 0.7953 - output_layer_dense_16_16_32_mean_absolute_error: 0.7953 - output_layer_dense_16_32_16_mean_absolute_error: 0.7953 - output_layer_dense_16_32_32_mean_absolute_error: 0.7953 - output_layer_dense_32_16_16_mean_absolute_error: 0.7953\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2291 - output_layer_dense_16_16_16_loss: 0.6458 - output_layer_dense_16_16_32_loss: 0.6458 - output_layer_dense_16_32_16_loss: 0.6458 - output_layer_dense_16_32_32_loss: 0.6458 - output_layer_dense_32_16_16_loss: 0.6458 - output_layer_dense_16_16_16_mean_absolute_error: 0.7964 - output_layer_dense_16_16_32_mean_absolute_error: 0.7964 - output_layer_dense_16_32_16_mean_absolute_error: 0.7964 - output_layer_dense_16_32_32_mean_absolute_error: 0.7964 - output_layer_dense_32_16_16_mean_absolute_error: 0.7964\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2524 - output_layer_dense_16_16_16_loss: 0.6505 - output_layer_dense_16_16_32_loss: 0.6505 - output_layer_dense_16_32_16_loss: 0.6505 - output_layer_dense_16_32_32_loss: 0.6505 - output_layer_dense_32_16_16_loss: 0.6505 - output_layer_dense_16_16_16_mean_absolute_error: 0.7992 - output_layer_dense_16_16_32_mean_absolute_error: 0.7992 - output_layer_dense_16_32_16_mean_absolute_error: 0.7992 - output_layer_dense_16_32_32_mean_absolute_error: 0.7992 - output_layer_dense_32_16_16_mean_absolute_error: 0.7992\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2263 - output_layer_dense_16_16_16_loss: 0.6453 - output_layer_dense_16_16_32_loss: 0.6453 - output_layer_dense_16_32_16_loss: 0.6453 - output_layer_dense_16_32_32_loss: 0.6453 - output_layer_dense_32_16_16_loss: 0.6453 - output_layer_dense_16_16_16_mean_absolute_error: 0.7960 - output_layer_dense_16_16_32_mean_absolute_error: 0.7960 - output_layer_dense_16_32_16_mean_absolute_error: 0.7960 - output_layer_dense_16_32_32_mean_absolute_error: 0.7960 - output_layer_dense_32_16_16_mean_absolute_error: 0.7960\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2617 - output_layer_dense_16_16_16_loss: 0.6523 - output_layer_dense_16_16_32_loss: 0.6523 - output_layer_dense_16_32_16_loss: 0.6523 - output_layer_dense_16_32_32_loss: 0.6523 - output_layer_dense_32_16_16_loss: 0.6523 - output_layer_dense_16_16_16_mean_absolute_error: 0.8001 - output_layer_dense_16_16_32_mean_absolute_error: 0.8001 - output_layer_dense_16_32_16_mean_absolute_error: 0.8001 - output_layer_dense_16_32_32_mean_absolute_error: 0.8001 - output_layer_dense_32_16_16_mean_absolute_error: 0.8001\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2065 - output_layer_dense_16_16_16_loss: 0.6413 - output_layer_dense_16_16_32_loss: 0.6413 - output_layer_dense_16_32_16_loss: 0.6413 - output_layer_dense_16_32_32_loss: 0.6413 - output_layer_dense_32_16_16_loss: 0.6413 - output_layer_dense_16_16_16_mean_absolute_error: 0.7921 - output_layer_dense_16_16_32_mean_absolute_error: 0.7921 - output_layer_dense_16_32_16_mean_absolute_error: 0.7921 - output_layer_dense_16_32_32_mean_absolute_error: 0.7921 - output_layer_dense_32_16_16_mean_absolute_error: 0.7921\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2172 - output_layer_dense_16_16_16_loss: 0.6434 - output_layer_dense_16_16_32_loss: 0.6434 - output_layer_dense_16_32_16_loss: 0.6434 - output_layer_dense_16_32_32_loss: 0.6434 - output_layer_dense_32_16_16_loss: 0.6434 - output_layer_dense_16_16_16_mean_absolute_error: 0.7943 - output_layer_dense_16_16_32_mean_absolute_error: 0.7943 - output_layer_dense_16_32_16_mean_absolute_error: 0.7943 - output_layer_dense_16_32_32_mean_absolute_error: 0.7943 - output_layer_dense_32_16_16_mean_absolute_error: 0.7943\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2488 - output_layer_dense_16_16_16_loss: 0.6498 - output_layer_dense_16_16_32_loss: 0.6498 - output_layer_dense_16_32_16_loss: 0.6498 - output_layer_dense_16_32_32_loss: 0.6498 - output_layer_dense_32_16_16_loss: 0.6498 - output_layer_dense_16_16_16_mean_absolute_error: 0.7989 - output_layer_dense_16_16_32_mean_absolute_error: 0.7989 - output_layer_dense_16_32_16_mean_absolute_error: 0.7989 - output_layer_dense_16_32_32_mean_absolute_error: 0.7989 - output_layer_dense_32_16_16_mean_absolute_error: 0.7989\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2328 - output_layer_dense_16_16_16_loss: 0.6466 - output_layer_dense_16_16_32_loss: 0.6466 - output_layer_dense_16_32_16_loss: 0.6466 - output_layer_dense_16_32_32_loss: 0.6466 - output_layer_dense_32_16_16_loss: 0.6466 - output_layer_dense_16_16_16_mean_absolute_error: 0.7968 - output_layer_dense_16_16_32_mean_absolute_error: 0.7968 - output_layer_dense_16_32_16_mean_absolute_error: 0.7968 - output_layer_dense_16_32_32_mean_absolute_error: 0.7968 - output_layer_dense_32_16_16_mean_absolute_error: 0.7968\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2400 - output_layer_dense_16_16_16_loss: 0.6480 - output_layer_dense_16_16_32_loss: 0.6480 - output_layer_dense_16_32_16_loss: 0.6480 - output_layer_dense_16_32_32_loss: 0.6480 - output_layer_dense_32_16_16_loss: 0.6480 - output_layer_dense_16_16_16_mean_absolute_error: 0.7986 - output_layer_dense_16_16_32_mean_absolute_error: 0.7986 - output_layer_dense_16_32_16_mean_absolute_error: 0.7986 - output_layer_dense_16_32_32_mean_absolute_error: 0.7986 - output_layer_dense_32_16_16_mean_absolute_error: 0.7986\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2175 - output_layer_dense_16_16_16_loss: 0.6435 - output_layer_dense_16_16_32_loss: 0.6435 - output_layer_dense_16_32_16_loss: 0.6435 - output_layer_dense_16_32_32_loss: 0.6435 - output_layer_dense_32_16_16_loss: 0.6435 - output_layer_dense_16_16_16_mean_absolute_error: 0.7944 - output_layer_dense_16_16_32_mean_absolute_error: 0.7944 - output_layer_dense_16_32_16_mean_absolute_error: 0.7944 - output_layer_dense_16_32_32_mean_absolute_error: 0.7944 - output_layer_dense_32_16_16_mean_absolute_error: 0.7944\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2554 - output_layer_dense_16_16_16_loss: 0.6511 - output_layer_dense_16_16_32_loss: 0.6511 - output_layer_dense_16_32_16_loss: 0.6511 - output_layer_dense_16_32_32_loss: 0.6511 - output_layer_dense_32_16_16_loss: 0.6511 - output_layer_dense_16_16_16_mean_absolute_error: 0.7991 - output_layer_dense_16_16_32_mean_absolute_error: 0.7991 - output_layer_dense_16_32_16_mean_absolute_error: 0.7991 - output_layer_dense_16_32_32_mean_absolute_error: 0.7991 - output_layer_dense_32_16_16_mean_absolute_error: 0.7991\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2447 - output_layer_dense_16_16_16_loss: 0.6489 - output_layer_dense_16_16_32_loss: 0.6489 - output_layer_dense_16_32_16_loss: 0.6489 - output_layer_dense_16_32_32_loss: 0.6489 - output_layer_dense_32_16_16_loss: 0.6489 - output_layer_dense_16_16_16_mean_absolute_error: 0.7979 - output_layer_dense_16_16_32_mean_absolute_error: 0.7979 - output_layer_dense_16_32_16_mean_absolute_error: 0.7979 - output_layer_dense_16_32_32_mean_absolute_error: 0.7979 - output_layer_dense_32_16_16_mean_absolute_error: 0.7979\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2340 - output_layer_dense_16_16_16_loss: 0.6468 - output_layer_dense_16_16_32_loss: 0.6468 - output_layer_dense_16_32_16_loss: 0.6468 - output_layer_dense_16_32_32_loss: 0.6468 - output_layer_dense_32_16_16_loss: 0.6468 - output_layer_dense_16_16_16_mean_absolute_error: 0.7963 - output_layer_dense_16_16_32_mean_absolute_error: 0.7963 - output_layer_dense_16_32_16_mean_absolute_error: 0.7963 - output_layer_dense_16_32_32_mean_absolute_error: 0.7963 - output_layer_dense_32_16_16_mean_absolute_error: 0.7963\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2580 - output_layer_dense_16_16_16_loss: 0.6516 - output_layer_dense_16_16_32_loss: 0.6516 - output_layer_dense_16_32_16_loss: 0.6516 - output_layer_dense_16_32_32_loss: 0.6516 - output_layer_dense_32_16_16_loss: 0.6516 - output_layer_dense_16_16_16_mean_absolute_error: 0.7997 - output_layer_dense_16_16_32_mean_absolute_error: 0.7997 - output_layer_dense_16_32_16_mean_absolute_error: 0.7997 - output_layer_dense_16_32_32_mean_absolute_error: 0.7997 - output_layer_dense_32_16_16_mean_absolute_error: 0.7997\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2354 - output_layer_dense_16_16_16_loss: 0.6471 - output_layer_dense_16_16_32_loss: 0.6471 - output_layer_dense_16_32_16_loss: 0.6471 - output_layer_dense_16_32_32_loss: 0.6471 - output_layer_dense_32_16_16_loss: 0.6471 - output_layer_dense_16_16_16_mean_absolute_error: 0.7967 - output_layer_dense_16_16_32_mean_absolute_error: 0.7967 - output_layer_dense_16_32_16_mean_absolute_error: 0.7967 - output_layer_dense_16_32_32_mean_absolute_error: 0.7967 - output_layer_dense_32_16_16_mean_absolute_error: 0.7967\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2447 - output_layer_dense_16_16_16_loss: 0.6489 - output_layer_dense_16_16_32_loss: 0.6489 - output_layer_dense_16_32_16_loss: 0.6489 - output_layer_dense_16_32_32_loss: 0.6489 - output_layer_dense_32_16_16_loss: 0.6489 - output_layer_dense_16_16_16_mean_absolute_error: 0.7985 - output_layer_dense_16_16_32_mean_absolute_error: 0.7985 - output_layer_dense_16_32_16_mean_absolute_error: 0.7985 - output_layer_dense_16_32_32_mean_absolute_error: 0.7985 - output_layer_dense_32_16_16_mean_absolute_error: 0.7985\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2470 - output_layer_dense_16_16_16_loss: 0.6494 - output_layer_dense_16_16_32_loss: 0.6494 - output_layer_dense_16_32_16_loss: 0.6494 - output_layer_dense_16_32_32_loss: 0.6494 - output_layer_dense_32_16_16_loss: 0.6494 - output_layer_dense_16_16_16_mean_absolute_error: 0.7981 - output_layer_dense_16_16_32_mean_absolute_error: 0.7981 - output_layer_dense_16_32_16_mean_absolute_error: 0.7981 - output_layer_dense_16_32_32_mean_absolute_error: 0.7981 - output_layer_dense_32_16_16_mean_absolute_error: 0.7981\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2466 - output_layer_dense_16_16_16_loss: 0.6493 - output_layer_dense_16_16_32_loss: 0.6493 - output_layer_dense_16_32_16_loss: 0.6493 - output_layer_dense_16_32_32_loss: 0.6493 - output_layer_dense_32_16_16_loss: 0.6493 - output_layer_dense_16_16_16_mean_absolute_error: 0.7989 - output_layer_dense_16_16_32_mean_absolute_error: 0.7989 - output_layer_dense_16_32_16_mean_absolute_error: 0.7989 - output_layer_dense_16_32_32_mean_absolute_error: 0.7989 - output_layer_dense_32_16_16_mean_absolute_error: 0.7989\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2568 - output_layer_dense_16_16_16_loss: 0.6514 - output_layer_dense_16_16_32_loss: 0.6514 - output_layer_dense_16_32_16_loss: 0.6514 - output_layer_dense_16_32_32_loss: 0.6514 - output_layer_dense_32_16_16_loss: 0.6514 - output_layer_dense_16_16_16_mean_absolute_error: 0.7979 - output_layer_dense_16_16_32_mean_absolute_error: 0.7979 - output_layer_dense_16_32_16_mean_absolute_error: 0.7979 - output_layer_dense_16_32_32_mean_absolute_error: 0.7979 - output_layer_dense_32_16_16_mean_absolute_error: 0.7979\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2299 - output_layer_dense_16_16_16_loss: 0.6460 - output_layer_dense_16_16_32_loss: 0.6460 - output_layer_dense_16_32_16_loss: 0.6460 - output_layer_dense_16_32_32_loss: 0.6460 - output_layer_dense_32_16_16_loss: 0.6460 - output_layer_dense_16_16_16_mean_absolute_error: 0.7963 - output_layer_dense_16_16_32_mean_absolute_error: 0.7963 - output_layer_dense_16_32_16_mean_absolute_error: 0.7963 - output_layer_dense_16_32_32_mean_absolute_error: 0.7963 - output_layer_dense_32_16_16_mean_absolute_error: 0.7963\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2353 - output_layer_dense_16_16_16_loss: 0.6471 - output_layer_dense_16_16_32_loss: 0.6471 - output_layer_dense_16_32_16_loss: 0.6471 - output_layer_dense_16_32_32_loss: 0.6471 - output_layer_dense_32_16_16_loss: 0.6471 - output_layer_dense_16_16_16_mean_absolute_error: 0.7972 - output_layer_dense_16_16_32_mean_absolute_error: 0.7972 - output_layer_dense_16_32_16_mean_absolute_error: 0.7972 - output_layer_dense_16_32_32_mean_absolute_error: 0.7972 - output_layer_dense_32_16_16_mean_absolute_error: 0.7972\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2357 - output_layer_dense_16_16_16_loss: 0.6471 - output_layer_dense_16_16_32_loss: 0.6471 - output_layer_dense_16_32_16_loss: 0.6471 - output_layer_dense_16_32_32_loss: 0.6471 - output_layer_dense_32_16_16_loss: 0.6471 - output_layer_dense_16_16_16_mean_absolute_error: 0.7960 - output_layer_dense_16_16_32_mean_absolute_error: 0.7960 - output_layer_dense_16_32_16_mean_absolute_error: 0.7960 - output_layer_dense_16_32_32_mean_absolute_error: 0.7960 - output_layer_dense_32_16_16_mean_absolute_error: 0.7960\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2340 - output_layer_dense_16_16_16_loss: 0.6468 - output_layer_dense_16_16_32_loss: 0.6468 - output_layer_dense_16_32_16_loss: 0.6468 - output_layer_dense_16_32_32_loss: 0.6468 - output_layer_dense_32_16_16_loss: 0.6468 - output_layer_dense_16_16_16_mean_absolute_error: 0.7964 - output_layer_dense_16_16_32_mean_absolute_error: 0.7964 - output_layer_dense_16_32_16_mean_absolute_error: 0.7964 - output_layer_dense_16_32_32_mean_absolute_error: 0.7964 - output_layer_dense_32_16_16_mean_absolute_error: 0.7964\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2465 - output_layer_dense_16_16_16_loss: 0.6493 - output_layer_dense_16_16_32_loss: 0.6493 - output_layer_dense_16_32_16_loss: 0.6493 - output_layer_dense_16_32_32_loss: 0.6493 - output_layer_dense_32_16_16_loss: 0.6493 - output_layer_dense_16_16_16_mean_absolute_error: 0.7989 - output_layer_dense_16_16_32_mean_absolute_error: 0.7989 - output_layer_dense_16_32_16_mean_absolute_error: 0.7989 - output_layer_dense_16_32_32_mean_absolute_error: 0.7989 - output_layer_dense_32_16_16_mean_absolute_error: 0.7989\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 3.2288 - output_layer_dense_16_16_16_loss: 0.6458 - output_layer_dense_16_16_32_loss: 0.6458 - output_layer_dense_16_32_16_loss: 0.6458 - output_layer_dense_16_32_32_loss: 0.6458 - output_layer_dense_32_16_16_loss: 0.6458 - output_layer_dense_16_16_16_mean_absolute_error: 0.7954 - output_layer_dense_16_16_32_mean_absolute_error: 0.7954 - output_layer_dense_16_32_16_mean_absolute_error: 0.7954 - output_layer_dense_16_32_32_mean_absolute_error: 0.7954 - output_layer_dense_32_16_16_mean_absolute_error: 0.7954\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2303 - output_layer_dense_16_16_16_loss: 0.6461 - output_layer_dense_16_16_32_loss: 0.6461 - output_layer_dense_16_32_16_loss: 0.6461 - output_layer_dense_16_32_32_loss: 0.6461 - output_layer_dense_32_16_16_loss: 0.6461 - output_layer_dense_16_16_16_mean_absolute_error: 0.7958 - output_layer_dense_16_16_32_mean_absolute_error: 0.7958 - output_layer_dense_16_32_16_mean_absolute_error: 0.7958 - output_layer_dense_16_32_32_mean_absolute_error: 0.7958 - output_layer_dense_32_16_16_mean_absolute_error: 0.7958\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2328 - output_layer_dense_16_16_16_loss: 0.6466 - output_layer_dense_16_16_32_loss: 0.6466 - output_layer_dense_16_32_16_loss: 0.6466 - output_layer_dense_16_32_32_loss: 0.6466 - output_layer_dense_32_16_16_loss: 0.6466 - output_layer_dense_16_16_16_mean_absolute_error: 0.7968 - output_layer_dense_16_16_32_mean_absolute_error: 0.7968 - output_layer_dense_16_32_16_mean_absolute_error: 0.7968 - output_layer_dense_16_32_32_mean_absolute_error: 0.7968 - output_layer_dense_32_16_16_mean_absolute_error: 0.7968\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2168 - output_layer_dense_16_16_16_loss: 0.6434 - output_layer_dense_16_16_32_loss: 0.6434 - output_layer_dense_16_32_16_loss: 0.6434 - output_layer_dense_16_32_32_loss: 0.6434 - output_layer_dense_32_16_16_loss: 0.6434 - output_layer_dense_16_16_16_mean_absolute_error: 0.7943 - output_layer_dense_16_16_32_mean_absolute_error: 0.7943 - output_layer_dense_16_32_16_mean_absolute_error: 0.7943 - output_layer_dense_16_32_32_mean_absolute_error: 0.7943 - output_layer_dense_32_16_16_mean_absolute_error: 0.7943\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2485 - output_layer_dense_16_16_16_loss: 0.6497 - output_layer_dense_16_16_32_loss: 0.6497 - output_layer_dense_16_32_16_loss: 0.6497 - output_layer_dense_16_32_32_loss: 0.6497 - output_layer_dense_32_16_16_loss: 0.6497 - output_layer_dense_16_16_16_mean_absolute_error: 0.7990 - output_layer_dense_16_16_32_mean_absolute_error: 0.7990 - output_layer_dense_16_32_16_mean_absolute_error: 0.7990 - output_layer_dense_16_32_32_mean_absolute_error: 0.7990 - output_layer_dense_32_16_16_mean_absolute_error: 0.7990\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2388 - output_layer_dense_16_16_16_loss: 0.6478 - output_layer_dense_16_16_32_loss: 0.6478 - output_layer_dense_16_32_16_loss: 0.6478 - output_layer_dense_16_32_32_loss: 0.6478 - output_layer_dense_32_16_16_loss: 0.6478 - output_layer_dense_16_16_16_mean_absolute_error: 0.7973 - output_layer_dense_16_16_32_mean_absolute_error: 0.7973 - output_layer_dense_16_32_16_mean_absolute_error: 0.7973 - output_layer_dense_16_32_32_mean_absolute_error: 0.7973 - output_layer_dense_32_16_16_mean_absolute_error: 0.7973\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2261 - output_layer_dense_16_16_16_loss: 0.6452 - output_layer_dense_16_16_32_loss: 0.6452 - output_layer_dense_16_32_16_loss: 0.6452 - output_layer_dense_16_32_32_loss: 0.6452 - output_layer_dense_32_16_16_loss: 0.6452 - output_layer_dense_16_16_16_mean_absolute_error: 0.7957 - output_layer_dense_16_16_32_mean_absolute_error: 0.7957 - output_layer_dense_16_32_16_mean_absolute_error: 0.7957 - output_layer_dense_16_32_32_mean_absolute_error: 0.7957 - output_layer_dense_32_16_16_mean_absolute_error: 0.7957\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.2379 - output_layer_dense_16_16_16_loss: 0.6476 - output_layer_dense_16_16_32_loss: 0.6476 - output_layer_dense_16_32_16_loss: 0.6476 - output_layer_dense_16_32_32_loss: 0.6476 - output_layer_dense_32_16_16_loss: 0.6476 - output_layer_dense_16_16_16_mean_absolute_error: 0.7972 - output_layer_dense_16_16_32_mean_absolute_error: 0.7972 - output_layer_dense_16_32_16_mean_absolute_error: 0.7972 - output_layer_dense_16_32_32_mean_absolute_error: 0.7972 - output_layer_dense_32_16_16_mean_absolute_error: 0.7972\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 3.1951 - output_layer_dense_16_16_16_loss: 0.6390 - output_layer_dense_16_16_32_loss: 0.6390 - output_layer_dense_16_32_16_loss: 0.6390 - output_layer_dense_16_32_32_loss: 0.6390 - output_layer_dense_32_16_16_loss: 0.6390 - output_layer_dense_16_16_16_mean_absolute_error: 0.7907 - output_layer_dense_16_16_32_mean_absolute_error: 0.7907 - output_layer_dense_16_32_16_mean_absolute_error: 0.7907 - output_layer_dense_16_32_32_mean_absolute_error: 0.7907 - output_layer_dense_32_16_16_mean_absolute_error: 0.7907\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "loss  :  3.2386183738708496\n",
      "output_layer_dense_16_16_16_loss  :  0.647723913192749\n",
      "output_layer_dense_16_16_32_loss  :  0.647723913192749\n",
      "output_layer_dense_16_32_16_loss  :  0.647723913192749\n",
      "output_layer_dense_16_32_32_loss  :  0.647723913192749\n",
      "output_layer_dense_32_16_16_loss  :  0.647723913192749\n",
      "output_layer_dense_16_16_16_mean_absolute_error  :  0.7972210049629211\n",
      "output_layer_dense_16_16_32_mean_absolute_error  :  0.7972210049629211\n",
      "output_layer_dense_16_32_16_mean_absolute_error  :  0.7972210049629211\n",
      "output_layer_dense_16_32_32_mean_absolute_error  :  0.7972210049629211\n",
      "output_layer_dense_32_16_16_mean_absolute_error  :  0.7972210049629211\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer_dense_32_16_32 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_32_32_16 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_layer_dense_32_32_32 (Inp [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_32_16_32 (Dense)   (None, 32)           1888        input_layer_dense_32_16_32[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_32_32_16 (Dense)   (None, 32)           1888        input_layer_dense_32_32_16[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1_dense_32_32_32 (Dense)   (None, 32)           1888        input_layer_dense_32_32_32[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_32_16_32 (Dense)   (None, 16)           528         layer1_dense_32_16_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_32_32_16 (Dense)   (None, 32)           1056        layer1_dense_32_32_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer2_dense_32_32_32 (Dense)   (None, 32)           1056        layer1_dense_32_32_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_32_16_32 (Dense)   (None, 32)           544         layer2_dense_32_16_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_32_32_16 (Dense)   (None, 16)           528         layer2_dense_32_32_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer3_dense_32_32_32 (Dense)   (None, 32)           1056        layer2_dense_32_32_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_32_16_32 (De (None, 1)            33          layer3_dense_32_16_32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_32_32_16 (De (None, 1)            17          layer3_dense_32_32_16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "output_layer_dense_32_32_32 (De (None, 1)            33          layer3_dense_32_32_32[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 10,515\n",
      "Trainable params: 10,515\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 2ms/step - loss: 1.9304 - output_layer_dense_32_16_32_loss: 0.6435 - output_layer_dense_32_32_16_loss: 0.6435 - output_layer_dense_32_32_32_loss: 0.6435 - output_layer_dense_32_16_32_mean_absolute_error: 0.7948 - output_layer_dense_32_32_16_mean_absolute_error: 0.7948 - output_layer_dense_32_32_32_mean_absolute_error: 0.7948\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9330 - output_layer_dense_32_16_32_loss: 0.6443 - output_layer_dense_32_32_16_loss: 0.6443 - output_layer_dense_32_32_32_loss: 0.6443 - output_layer_dense_32_16_32_mean_absolute_error: 0.7953 - output_layer_dense_32_32_16_mean_absolute_error: 0.7953 - output_layer_dense_32_32_32_mean_absolute_error: 0.7953\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9416 - output_layer_dense_32_16_32_loss: 0.6472 - output_layer_dense_32_32_16_loss: 0.6472 - output_layer_dense_32_32_32_loss: 0.6472 - output_layer_dense_32_16_32_mean_absolute_error: 0.7959 - output_layer_dense_32_32_16_mean_absolute_error: 0.7959 - output_layer_dense_32_32_32_mean_absolute_error: 0.7959\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9382 - output_layer_dense_32_16_32_loss: 0.6461 - output_layer_dense_32_32_16_loss: 0.6461 - output_layer_dense_32_32_32_loss: 0.6461 - output_layer_dense_32_16_32_mean_absolute_error: 0.7961 - output_layer_dense_32_32_16_mean_absolute_error: 0.7961 - output_layer_dense_32_32_32_mean_absolute_error: 0.7961\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9381 - output_layer_dense_32_16_32_loss: 0.6460 - output_layer_dense_32_32_16_loss: 0.6460 - output_layer_dense_32_32_32_loss: 0.6460 - output_layer_dense_32_16_32_mean_absolute_error: 0.7963 - output_layer_dense_32_32_16_mean_absolute_error: 0.7963 - output_layer_dense_32_32_32_mean_absolute_error: 0.7963\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9430 - output_layer_dense_32_16_32_loss: 0.6477 - output_layer_dense_32_32_16_loss: 0.6477 - output_layer_dense_32_32_32_loss: 0.6477 - output_layer_dense_32_16_32_mean_absolute_error: 0.7969 - output_layer_dense_32_32_16_mean_absolute_error: 0.7969 - output_layer_dense_32_32_32_mean_absolute_error: 0.7969\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9489 - output_layer_dense_32_16_32_loss: 0.6496 - output_layer_dense_32_32_16_loss: 0.6496 - output_layer_dense_32_32_32_loss: 0.6496 - output_layer_dense_32_16_32_mean_absolute_error: 0.7983 - output_layer_dense_32_32_16_mean_absolute_error: 0.7983 - output_layer_dense_32_32_32_mean_absolute_error: 0.7983\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9575 - output_layer_dense_32_16_32_loss: 0.6525 - output_layer_dense_32_32_16_loss: 0.6525 - output_layer_dense_32_32_32_loss: 0.6525 - output_layer_dense_32_16_32_mean_absolute_error: 0.8006 - output_layer_dense_32_32_16_mean_absolute_error: 0.8006 - output_layer_dense_32_32_32_mean_absolute_error: 0.8006\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9482 - output_layer_dense_32_16_32_loss: 0.6494 - output_layer_dense_32_32_16_loss: 0.6494 - output_layer_dense_32_32_32_loss: 0.6494 - output_layer_dense_32_16_32_mean_absolute_error: 0.7983 - output_layer_dense_32_32_16_mean_absolute_error: 0.7983 - output_layer_dense_32_32_32_mean_absolute_error: 0.7983\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9405 - output_layer_dense_32_16_32_loss: 0.6468 - output_layer_dense_32_32_16_loss: 0.6468 - output_layer_dense_32_32_32_loss: 0.6468 - output_layer_dense_32_16_32_mean_absolute_error: 0.7967 - output_layer_dense_32_32_16_mean_absolute_error: 0.7967 - output_layer_dense_32_32_32_mean_absolute_error: 0.7967\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9591 - output_layer_dense_32_16_32_loss: 0.6530 - output_layer_dense_32_32_16_loss: 0.6530 - output_layer_dense_32_32_32_loss: 0.6530 - output_layer_dense_32_16_32_mean_absolute_error: 0.8013 - output_layer_dense_32_32_16_mean_absolute_error: 0.8013 - output_layer_dense_32_32_32_mean_absolute_error: 0.8013\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9487 - output_layer_dense_32_16_32_loss: 0.6496 - output_layer_dense_32_32_16_loss: 0.6496 - output_layer_dense_32_32_32_loss: 0.6496 - output_layer_dense_32_16_32_mean_absolute_error: 0.7980 - output_layer_dense_32_32_16_mean_absolute_error: 0.7980 - output_layer_dense_32_32_32_mean_absolute_error: 0.7980\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9463 - output_layer_dense_32_16_32_loss: 0.6488 - output_layer_dense_32_32_16_loss: 0.6488 - output_layer_dense_32_32_32_loss: 0.6488 - output_layer_dense_32_16_32_mean_absolute_error: 0.7981 - output_layer_dense_32_32_16_mean_absolute_error: 0.7981 - output_layer_dense_32_32_32_mean_absolute_error: 0.7981\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9490 - output_layer_dense_32_16_32_loss: 0.6497 - output_layer_dense_32_32_16_loss: 0.6497 - output_layer_dense_32_32_32_loss: 0.6497 - output_layer_dense_32_16_32_mean_absolute_error: 0.7986 - output_layer_dense_32_32_16_mean_absolute_error: 0.7986 - output_layer_dense_32_32_32_mean_absolute_error: 0.7986\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9316 - output_layer_dense_32_16_32_loss: 0.6439 - output_layer_dense_32_32_16_loss: 0.6439 - output_layer_dense_32_32_32_loss: 0.6439 - output_layer_dense_32_16_32_mean_absolute_error: 0.7943 - output_layer_dense_32_32_16_mean_absolute_error: 0.7943 - output_layer_dense_32_32_32_mean_absolute_error: 0.7943\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9371 - output_layer_dense_32_16_32_loss: 0.6457 - output_layer_dense_32_32_16_loss: 0.6457 - output_layer_dense_32_32_32_loss: 0.6457 - output_layer_dense_32_16_32_mean_absolute_error: 0.7963 - output_layer_dense_32_32_16_mean_absolute_error: 0.7963 - output_layer_dense_32_32_32_mean_absolute_error: 0.7963\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9483 - output_layer_dense_32_16_32_loss: 0.6494 - output_layer_dense_32_32_16_loss: 0.6494 - output_layer_dense_32_32_32_loss: 0.6494 - output_layer_dense_32_16_32_mean_absolute_error: 0.7987 - output_layer_dense_32_32_16_mean_absolute_error: 0.7987 - output_layer_dense_32_32_32_mean_absolute_error: 0.7987\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9574 - output_layer_dense_32_16_32_loss: 0.6525 - output_layer_dense_32_32_16_loss: 0.6525 - output_layer_dense_32_32_32_loss: 0.6525 - output_layer_dense_32_16_32_mean_absolute_error: 0.8001 - output_layer_dense_32_32_16_mean_absolute_error: 0.8001 - output_layer_dense_32_32_32_mean_absolute_error: 0.8001\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9298 - output_layer_dense_32_16_32_loss: 0.6433 - output_layer_dense_32_32_16_loss: 0.6433 - output_layer_dense_32_32_32_loss: 0.6433 - output_layer_dense_32_16_32_mean_absolute_error: 0.7942 - output_layer_dense_32_32_16_mean_absolute_error: 0.7942 - output_layer_dense_32_32_32_mean_absolute_error: 0.7942\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9550 - output_layer_dense_32_16_32_loss: 0.6517 - output_layer_dense_32_32_16_loss: 0.6517 - output_layer_dense_32_32_32_loss: 0.6517 - output_layer_dense_32_16_32_mean_absolute_error: 0.7998 - output_layer_dense_32_32_16_mean_absolute_error: 0.7998 - output_layer_dense_32_32_32_mean_absolute_error: 0.7998\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9470 - output_layer_dense_32_16_32_loss: 0.6490 - output_layer_dense_32_32_16_loss: 0.6490 - output_layer_dense_32_32_32_loss: 0.6490 - output_layer_dense_32_16_32_mean_absolute_error: 0.7977 - output_layer_dense_32_32_16_mean_absolute_error: 0.7977 - output_layer_dense_32_32_32_mean_absolute_error: 0.7977\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9422 - output_layer_dense_32_16_32_loss: 0.6474 - output_layer_dense_32_32_16_loss: 0.6474 - output_layer_dense_32_32_32_loss: 0.6474 - output_layer_dense_32_16_32_mean_absolute_error: 0.7972 - output_layer_dense_32_32_16_mean_absolute_error: 0.7972 - output_layer_dense_32_32_32_mean_absolute_error: 0.7972\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9400 - output_layer_dense_32_16_32_loss: 0.6467 - output_layer_dense_32_32_16_loss: 0.6467 - output_layer_dense_32_32_32_loss: 0.6467 - output_layer_dense_32_16_32_mean_absolute_error: 0.7960 - output_layer_dense_32_32_16_mean_absolute_error: 0.7960 - output_layer_dense_32_32_32_mean_absolute_error: 0.7960\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9392 - output_layer_dense_32_16_32_loss: 0.6464 - output_layer_dense_32_32_16_loss: 0.6464 - output_layer_dense_32_32_32_loss: 0.6464 - output_layer_dense_32_16_32_mean_absolute_error: 0.7968 - output_layer_dense_32_32_16_mean_absolute_error: 0.7968 - output_layer_dense_32_32_32_mean_absolute_error: 0.7968\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9486 - output_layer_dense_32_16_32_loss: 0.6495 - output_layer_dense_32_32_16_loss: 0.6495 - output_layer_dense_32_32_32_loss: 0.6495 - output_layer_dense_32_16_32_mean_absolute_error: 0.7985 - output_layer_dense_32_32_16_mean_absolute_error: 0.7985 - output_layer_dense_32_32_32_mean_absolute_error: 0.7985\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9562 - output_layer_dense_32_16_32_loss: 0.6521 - output_layer_dense_32_32_16_loss: 0.6521 - output_layer_dense_32_32_32_loss: 0.6521 - output_layer_dense_32_16_32_mean_absolute_error: 0.8006 - output_layer_dense_32_32_16_mean_absolute_error: 0.8006 - output_layer_dense_32_32_32_mean_absolute_error: 0.8006\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9390 - output_layer_dense_32_16_32_loss: 0.6463 - output_layer_dense_32_32_16_loss: 0.6463 - output_layer_dense_32_32_32_loss: 0.6463 - output_layer_dense_32_16_32_mean_absolute_error: 0.7959 - output_layer_dense_32_32_16_mean_absolute_error: 0.7959 - output_layer_dense_32_32_32_mean_absolute_error: 0.7959\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9680 - output_layer_dense_32_16_32_loss: 0.6560 - output_layer_dense_32_32_16_loss: 0.6560 - output_layer_dense_32_32_32_loss: 0.6560 - output_layer_dense_32_16_32_mean_absolute_error: 0.8026 - output_layer_dense_32_32_16_mean_absolute_error: 0.8026 - output_layer_dense_32_32_32_mean_absolute_error: 0.8026\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9305 - output_layer_dense_32_16_32_loss: 0.6435 - output_layer_dense_32_32_16_loss: 0.6435 - output_layer_dense_32_32_32_loss: 0.6435 - output_layer_dense_32_16_32_mean_absolute_error: 0.7938 - output_layer_dense_32_32_16_mean_absolute_error: 0.7938 - output_layer_dense_32_32_32_mean_absolute_error: 0.7938\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9470 - output_layer_dense_32_16_32_loss: 0.6490 - output_layer_dense_32_32_16_loss: 0.6490 - output_layer_dense_32_32_32_loss: 0.6490 - output_layer_dense_32_16_32_mean_absolute_error: 0.7978 - output_layer_dense_32_32_16_mean_absolute_error: 0.7978 - output_layer_dense_32_32_32_mean_absolute_error: 0.7978\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9517 - output_layer_dense_32_16_32_loss: 0.6506 - output_layer_dense_32_32_16_loss: 0.6506 - output_layer_dense_32_32_32_loss: 0.6506 - output_layer_dense_32_16_32_mean_absolute_error: 0.7989 - output_layer_dense_32_32_16_mean_absolute_error: 0.7989 - output_layer_dense_32_32_32_mean_absolute_error: 0.7989\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9421 - output_layer_dense_32_16_32_loss: 0.6474 - output_layer_dense_32_32_16_loss: 0.6474 - output_layer_dense_32_32_32_loss: 0.6474 - output_layer_dense_32_16_32_mean_absolute_error: 0.7970 - output_layer_dense_32_32_16_mean_absolute_error: 0.7970 - output_layer_dense_32_32_32_mean_absolute_error: 0.7970\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9435 - output_layer_dense_32_16_32_loss: 0.6478 - output_layer_dense_32_32_16_loss: 0.6478 - output_layer_dense_32_32_32_loss: 0.6478 - output_layer_dense_32_16_32_mean_absolute_error: 0.7975 - output_layer_dense_32_32_16_mean_absolute_error: 0.7975 - output_layer_dense_32_32_32_mean_absolute_error: 0.7975\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9374 - output_layer_dense_32_16_32_loss: 0.6458 - output_layer_dense_32_32_16_loss: 0.6458 - output_layer_dense_32_32_32_loss: 0.6458 - output_layer_dense_32_16_32_mean_absolute_error: 0.7959 - output_layer_dense_32_32_16_mean_absolute_error: 0.7959 - output_layer_dense_32_32_32_mean_absolute_error: 0.7959\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9362 - output_layer_dense_32_16_32_loss: 0.6454 - output_layer_dense_32_32_16_loss: 0.6454 - output_layer_dense_32_32_32_loss: 0.6454 - output_layer_dense_32_16_32_mean_absolute_error: 0.7948 - output_layer_dense_32_32_16_mean_absolute_error: 0.7948 - output_layer_dense_32_32_32_mean_absolute_error: 0.7948\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9371 - output_layer_dense_32_16_32_loss: 0.6457 - output_layer_dense_32_32_16_loss: 0.6457 - output_layer_dense_32_32_32_loss: 0.6457 - output_layer_dense_32_16_32_mean_absolute_error: 0.7967 - output_layer_dense_32_32_16_mean_absolute_error: 0.7967 - output_layer_dense_32_32_32_mean_absolute_error: 0.7967\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9461 - output_layer_dense_32_16_32_loss: 0.6487 - output_layer_dense_32_32_16_loss: 0.6487 - output_layer_dense_32_32_32_loss: 0.6487 - output_layer_dense_32_16_32_mean_absolute_error: 0.7975 - output_layer_dense_32_32_16_mean_absolute_error: 0.7975 - output_layer_dense_32_32_32_mean_absolute_error: 0.7975\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9284 - output_layer_dense_32_16_32_loss: 0.6428 - output_layer_dense_32_32_16_loss: 0.6428 - output_layer_dense_32_32_32_loss: 0.6428 - output_layer_dense_32_16_32_mean_absolute_error: 0.7934 - output_layer_dense_32_32_16_mean_absolute_error: 0.7934 - output_layer_dense_32_32_32_mean_absolute_error: 0.7934\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.9460 - output_layer_dense_32_16_32_loss: 0.6487 - output_layer_dense_32_32_16_loss: 0.6487 - output_layer_dense_32_32_32_loss: 0.6487 - output_layer_dense_32_16_32_mean_absolute_error: 0.7984 - output_layer_dense_32_32_16_mean_absolute_error: 0.7984 - output_layer_dense_32_32_32_mean_absolute_error: 0.7984\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9467 - output_layer_dense_32_16_32_loss: 0.6489 - output_layer_dense_32_32_16_loss: 0.6489 - output_layer_dense_32_32_32_loss: 0.6489 - output_layer_dense_32_16_32_mean_absolute_error: 0.7979 - output_layer_dense_32_32_16_mean_absolute_error: 0.7979 - output_layer_dense_32_32_32_mean_absolute_error: 0.7979\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9367 - output_layer_dense_32_16_32_loss: 0.6456 - output_layer_dense_32_32_16_loss: 0.6456 - output_layer_dense_32_32_32_loss: 0.6456 - output_layer_dense_32_16_32_mean_absolute_error: 0.7957 - output_layer_dense_32_32_16_mean_absolute_error: 0.7957 - output_layer_dense_32_32_32_mean_absolute_error: 0.7957\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9416 - output_layer_dense_32_16_32_loss: 0.6472 - output_layer_dense_32_32_16_loss: 0.6472 - output_layer_dense_32_32_32_loss: 0.6472 - output_layer_dense_32_16_32_mean_absolute_error: 0.7974 - output_layer_dense_32_32_16_mean_absolute_error: 0.7974 - output_layer_dense_32_32_32_mean_absolute_error: 0.7974\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9244 - output_layer_dense_32_16_32_loss: 0.6415 - output_layer_dense_32_32_16_loss: 0.6415 - output_layer_dense_32_32_32_loss: 0.6415 - output_layer_dense_32_16_32_mean_absolute_error: 0.7931 - output_layer_dense_32_32_16_mean_absolute_error: 0.7931 - output_layer_dense_32_32_32_mean_absolute_error: 0.7931\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9536 - output_layer_dense_32_16_32_loss: 0.6512 - output_layer_dense_32_32_16_loss: 0.6512 - output_layer_dense_32_32_32_loss: 0.6512 - output_layer_dense_32_16_32_mean_absolute_error: 0.7994 - output_layer_dense_32_32_16_mean_absolute_error: 0.7994 - output_layer_dense_32_32_32_mean_absolute_error: 0.7994\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9511 - output_layer_dense_32_16_32_loss: 0.6504 - output_layer_dense_32_32_16_loss: 0.6504 - output_layer_dense_32_32_32_loss: 0.6504 - output_layer_dense_32_16_32_mean_absolute_error: 0.7984 - output_layer_dense_32_32_16_mean_absolute_error: 0.7984 - output_layer_dense_32_32_32_mean_absolute_error: 0.7984\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9195 - output_layer_dense_32_16_32_loss: 0.6398 - output_layer_dense_32_32_16_loss: 0.6398 - output_layer_dense_32_32_32_loss: 0.6398 - output_layer_dense_32_16_32_mean_absolute_error: 0.7914 - output_layer_dense_32_32_16_mean_absolute_error: 0.7914 - output_layer_dense_32_32_32_mean_absolute_error: 0.7914\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9310 - output_layer_dense_32_16_32_loss: 0.6437 - output_layer_dense_32_32_16_loss: 0.6437 - output_layer_dense_32_32_32_loss: 0.6437 - output_layer_dense_32_16_32_mean_absolute_error: 0.7944 - output_layer_dense_32_32_16_mean_absolute_error: 0.7944 - output_layer_dense_32_32_32_mean_absolute_error: 0.7944\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9530 - output_layer_dense_32_16_32_loss: 0.6510 - output_layer_dense_32_32_16_loss: 0.6510 - output_layer_dense_32_32_32_loss: 0.6510 - output_layer_dense_32_16_32_mean_absolute_error: 0.7994 - output_layer_dense_32_32_16_mean_absolute_error: 0.7994 - output_layer_dense_32_32_32_mean_absolute_error: 0.7994\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9468 - output_layer_dense_32_16_32_loss: 0.6489 - output_layer_dense_32_32_16_loss: 0.6489 - output_layer_dense_32_32_32_loss: 0.6489 - output_layer_dense_32_16_32_mean_absolute_error: 0.7980 - output_layer_dense_32_32_16_mean_absolute_error: 0.7980 - output_layer_dense_32_32_32_mean_absolute_error: 0.7980\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 1.9273 - output_layer_dense_32_16_32_loss: 0.6424 - output_layer_dense_32_32_16_loss: 0.6424 - output_layer_dense_32_32_32_loss: 0.6424 - output_layer_dense_32_16_32_mean_absolute_error: 0.7931 - output_layer_dense_32_32_16_mean_absolute_error: 0.7931 - output_layer_dense_32_32_32_mean_absolute_error: 0.7931\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "loss  :  1.9431711435317993\n",
      "output_layer_dense_32_16_32_loss  :  0.647723913192749\n",
      "output_layer_dense_32_32_16_loss  :  0.647723913192749\n",
      "output_layer_dense_32_32_32_loss  :  0.647723913192749\n",
      "output_layer_dense_32_16_32_mean_absolute_error  :  0.7972210049629211\n",
      "output_layer_dense_32_32_16_mean_absolute_error  :  0.7972210049629211\n",
      "output_layer_dense_32_32_32_mean_absolute_error  :  0.7972210049629211\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m.get_all_models()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "441a79e7978ad007ee49ac1a1197fffc94e685236b0df2483283c16abedd4251"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
