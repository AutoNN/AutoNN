{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b73c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, '/home/anish/ASC_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226d408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 12:05:03.466169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "from ASC_ML import multiple_model_gen_v3 as multiple\n",
    "from ASC_ML import dataframe_extractor as de\n",
    "from ASC_ML import model_generation as model_gen\n",
    "# from ASC_ML import model_gen_train_test as testing\n",
    "from dask_ml.preprocessing import LabelEncoder\n",
    "# from dask_ml.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b709ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = multiple.Multiple_Model_Gen(max_no_layers = 2, model_per_batch = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c356ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "# import pandas as pd\n",
    "# data = dd.from_pandas(pd.Series(['a', 'a', 'b'], dtype='category'),\n",
    "#                      npartitions=1)\n",
    "# le = LabelEncoder()\n",
    "# le.fit_transform(data).compute()\n",
    "# print(type(le.fit_transform(data).compute()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e8faf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading single csv from /home/anish/ASC-ML-EXP-DATASETS/LinReg-tabular/house-prices-advanced-regression-techniques/train.csv\n",
      "Train Dataset X Columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1.0        60.0       RL         65.0   8450.0   Pave   NaN      Reg   \n",
       "1  2.0        20.0       RL         80.0   9600.0   Pave   NaN      Reg   \n",
       "2  3.0        60.0       RL         68.0  11250.0   Pave   NaN      IR1   \n",
       "3  4.0        70.0       RL         60.0   9550.0   Pave   NaN      IR1   \n",
       "4  5.0        60.0       RL         84.0  14260.0   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "1         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "2         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "3         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "4         Lvl    AllPub  ...         0.0      0.0    NaN   NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0     0.0    2.0  2008.0        WD         Normal  \n",
       "1     0.0    5.0  2007.0        WD         Normal  \n",
       "2     0.0    9.0  2008.0        WD         Normal  \n",
       "3     0.0    2.0  2006.0        WD        Abnorml  \n",
       "4     0.0   12.0  2008.0        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For House Prediction Dataset https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data?select=train.csv\n",
    "directory1 = \"/home/anish/ASC-ML-EXP-DATASETS/LinReg-tabular/house-prices-advanced-regression-techniques/train.csv\"\n",
    "\n",
    "\n",
    "# returns list of dask dataframe [singular_df_x, singular_df_y] or [train_df_x, train_df_y, test_df_x, test_df_y]\n",
    "dataset_list = de.DataframeExtractor_csv(directory1, label_names = [\"SalePrice\"]).df_list\n",
    "\n",
    "print(\"Train Dataset X Columns\")\n",
    "dataset_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2faff3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice\n",
       "0   208500.0\n",
       "1   181500.0\n",
       "2   223500.0\n",
       "3   140000.0\n",
       "4   250000.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba39374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dataset_list[0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17da251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80b3956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1.0        60.0       RL         65.0   8450.0   Pave     0      Reg   \n",
       "1  2.0        20.0       RL         80.0   9600.0   Pave     0      Reg   \n",
       "2  3.0        60.0       RL         68.0  11250.0   Pave     0      IR1   \n",
       "3  4.0        70.0       RL         60.0   9550.0   Pave     0      IR1   \n",
       "4  5.0        60.0       RL         84.0  14260.0   Pave     0      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "1         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "2         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "3         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "4         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0     0.0    2.0  2008.0        WD         Normal  \n",
       "1     0.0    5.0  2007.0        WD         Normal  \n",
       "2     0.0    9.0  2008.0        WD         Normal  \n",
       "3     0.0    2.0  2006.0        WD        Abnorml  \n",
       "4     0.0   12.0  2008.0        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c2b0130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anish/anaconda3/envs/tfgpu/lib/python3.9/site-packages/dask/dataframe/core.py:3946: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('MSSubClass', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1.0       60.0       RL         65.0   8450.0   Pave     0      Reg   \n",
       "1  2.0       20.0       RL         80.0   9600.0   Pave     0      Reg   \n",
       "2  3.0       60.0       RL         68.0  11250.0   Pave     0      IR1   \n",
       "3  4.0       70.0       RL         60.0   9550.0   Pave     0      IR1   \n",
       "4  5.0       60.0       RL         84.0  14260.0   Pave     0      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "1         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "2         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "3         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "4         Lvl    AllPub  ...         0.0      0.0      0     0           0   \n",
       "\n",
       "  MiscVal MoSold  YrSold SaleType  SaleCondition  \n",
       "0     0.0    2.0  2008.0       WD         Normal  \n",
       "1     0.0    5.0  2007.0       WD         Normal  \n",
       "2     0.0    9.0  2008.0       WD         Normal  \n",
       "3     0.0    2.0  2006.0       WD        Abnorml  \n",
       "4     0.0   12.0  2008.0       WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x['MSSubClass'] = train_x['MSSubClass'].apply(str)\n",
    "\n",
    "train_x['OverallCond'] = train_x['OverallCond'].astype(str)\n",
    "\n",
    "train_x['YrSold'] = train_x['YrSold'].astype(str)\n",
    "train_x['MoSold'] = train_x['MoSold'].astype(str)\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e3cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = train_x['LotShape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26e217e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = LabelEncoder() \n",
    "# le.fit_transform(a).compute()\n",
    "# train_x['LotShape'] = le.fit_transform(train_x['LotShape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b03357de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18b5c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyval(allkeys):\n",
    "    i = 0\n",
    "    keyvalpairs = list()\n",
    "    for key in allkeys:\n",
    "        keyvalpairs.append((key,i))\n",
    "        i+=1\n",
    "    return dict(keyvalpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85582bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['FireplaceQu', 'LotShape']\n",
    "cols = ['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold']\n",
    "keys = {}\n",
    "for col in cols:\n",
    "    key = train_x[col].unique()\n",
    "    keyvalpairs = keyval(key)\n",
    "    keys.update({col:keyvalpairs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e27019f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FireplaceQu': {0: 0, 'TA': 1, 'Gd': 2, 'Fa': 3, 'Ex': 4, 'Po': 5},\n",
       " 'BsmtQual': {'Gd': 0, 'TA': 1, 'Ex': 2, 0: 3, 'Fa': 4},\n",
       " 'BsmtCond': {'TA': 0, 'Gd': 1, 0: 2, 'Fa': 3, 'Po': 4},\n",
       " 'GarageQual': {'TA': 0, 'Fa': 1, 'Gd': 2, 0: 3, 'Ex': 4, 'Po': 5},\n",
       " 'GarageCond': {'TA': 0, 'Fa': 1, 0: 2, 'Gd': 3, 'Po': 4, 'Ex': 5},\n",
       " 'ExterQual': {'Gd': 0, 'TA': 1, 'Ex': 2, 'Fa': 3},\n",
       " 'ExterCond': {'TA': 0, 'Gd': 1, 'Fa': 2, 'Po': 3, 'Ex': 4},\n",
       " 'HeatingQC': {'Ex': 0, 'Gd': 1, 'TA': 2, 'Fa': 3, 'Po': 4},\n",
       " 'PoolQC': {0: 0, 'Ex': 1, 'Fa': 2, 'Gd': 3},\n",
       " 'KitchenQual': {'Gd': 0, 'TA': 1, 'Ex': 2, 'Fa': 3},\n",
       " 'BsmtFinType1': {'GLQ': 0,\n",
       "  'ALQ': 1,\n",
       "  'Unf': 2,\n",
       "  'Rec': 3,\n",
       "  'BLQ': 4,\n",
       "  0: 5,\n",
       "  'LwQ': 6},\n",
       " 'BsmtFinType2': {'Unf': 0,\n",
       "  'BLQ': 1,\n",
       "  0: 2,\n",
       "  'ALQ': 3,\n",
       "  'Rec': 4,\n",
       "  'LwQ': 5,\n",
       "  'GLQ': 6},\n",
       " 'Functional': {'Typ': 0,\n",
       "  'Min1': 1,\n",
       "  'Maj1': 2,\n",
       "  'Min2': 3,\n",
       "  'Mod': 4,\n",
       "  'Maj2': 5,\n",
       "  'Sev': 6},\n",
       " 'Fence': {0: 0, 'MnPrv': 1, 'GdWo': 2, 'GdPrv': 3, 'MnWw': 4},\n",
       " 'BsmtExposure': {'No': 0, 'Gd': 1, 'Mn': 2, 'Av': 3, 0: 4},\n",
       " 'GarageFinish': {'RFn': 0, 'Unf': 1, 'Fin': 2, 0: 3},\n",
       " 'LandSlope': {'Gtl': 0, 'Mod': 1, 'Sev': 2},\n",
       " 'LotShape': {'Reg': 0, 'IR1': 1, 'IR2': 2, 'IR3': 3},\n",
       " 'PavedDrive': {'Y': 0, 'N': 1, 'P': 2},\n",
       " 'Street': {'Pave': 0, 'Grvl': 1},\n",
       " 'Alley': {0: 0, 'Grvl': 1, 'Pave': 2},\n",
       " 'CentralAir': {'Y': 0, 'N': 1},\n",
       " 'MSSubClass': {'60.0': 0,\n",
       "  '20.0': 1,\n",
       "  '70.0': 2,\n",
       "  '50.0': 3,\n",
       "  '190.0': 4,\n",
       "  '45.0': 5,\n",
       "  '90.0': 6,\n",
       "  '120.0': 7,\n",
       "  '30.0': 8,\n",
       "  '85.0': 9,\n",
       "  '80.0': 10,\n",
       "  '160.0': 11,\n",
       "  '75.0': 12,\n",
       "  '180.0': 13,\n",
       "  '40.0': 14},\n",
       " 'OverallCond': {'5.0': 0,\n",
       "  '8.0': 1,\n",
       "  '6.0': 2,\n",
       "  '7.0': 3,\n",
       "  '4.0': 4,\n",
       "  '2.0': 5,\n",
       "  '3.0': 6,\n",
       "  '9.0': 7,\n",
       "  '1.0': 8},\n",
       " 'YrSold': {'2008.0': 0, '2007.0': 1, '2006.0': 2, '2009.0': 3, '2010.0': 4},\n",
       " 'MoSold': {'2.0': 0,\n",
       "  '5.0': 1,\n",
       "  '9.0': 2,\n",
       "  '12.0': 3,\n",
       "  '10.0': 4,\n",
       "  '8.0': 5,\n",
       "  '11.0': 6,\n",
       "  '4.0': 7,\n",
       "  '1.0': 8,\n",
       "  '7.0': 9,\n",
       "  '3.0': 10,\n",
       "  '6.0': 11}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b866ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_x.replace(keys).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beed42ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "Name: FireplaceQu, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X['FireplaceQu'].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2244a3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
       "0  1.0           0       RL         65.0   8450.0       0      0         0   \n",
       "1  2.0           1       RL         80.0   9600.0       0      0         0   \n",
       "2  3.0           0       RL         68.0  11250.0       0      0         1   \n",
       "3  4.0           2       RL         60.0   9550.0       0      0         1   \n",
       "4  5.0           0       RL         84.0  14260.0       0      0         1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch  PoolArea PoolQC Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "1         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "2         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "3         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "4         Lvl    AllPub  ...         0.0       0.0      0     0           0   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0     0.0      0       0        WD         Normal  \n",
       "1     0.0      1       1        WD         Normal  \n",
       "2     0.0      2       0        WD         Normal  \n",
       "3     0.0      0       2        WD        Abnorml  \n",
       "4     0.0      3       0        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a98174b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = []\n",
    "for col in train_X.columns:\n",
    "#     print(type(col))\n",
    "    try:\n",
    "        a = train_X[col].astype(float).compute()\n",
    "    except ValueError:\n",
    "#         print('Couldn\\'t covert %s to float' % col)\n",
    "        cols_to_remove.append(col)\n",
    "        pass\n",
    "\n",
    "# keep only the columns in df that do not contain string\n",
    "train_X = train_X[[col for col in train_X.columns if col not in cols_to_remove]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa2c3b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'LandContour', 'Utilities', 'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'Electrical', 'GarageType', 'MiscFeature', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "print(cols_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecf3891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.drop([\"Id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eff4a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsklearn.preprocessing.MinMaxScalerrain_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb1c660c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e66f991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_list[1].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6455e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(train_X)\n",
    "train_X_scaled = scaler_x.transform(train_X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "scaler_y.fit(dataset_list[1])\n",
    "train_Y_scaled = scaler_y.transform(dataset_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdc2d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = train_X.columns.to_list()\n",
    "# scaler_d = MinMaxScaler()\n",
    "# train_X.columns = list(train_X.columns)\n",
    "# scaled_train_X = scaler_d.fit_transform(train_X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f430d875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.20766773, 0.0334198 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07142857, 0.25559105, 0.03879502, ..., 0.        , 0.09090909,\n",
       "        0.25      ],\n",
       "       [0.        , 0.2172524 , 0.04650728, ..., 0.        , 0.18181818,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.14285714, 0.21086262, 0.03618687, ..., 0.16129032, 0.09090909,\n",
       "        1.        ],\n",
       "       [0.07142857, 0.2172524 , 0.03934189, ..., 0.        , 0.63636364,\n",
       "        1.        ],\n",
       "       [0.07142857, 0.23961661, 0.04037019, ..., 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_scaled\n",
    "# train_Y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e295c810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24107763],\n",
       "       [0.20358284],\n",
       "       [0.26190807],\n",
       "       ...,\n",
       "       [0.321622  ],\n",
       "       [0.14890293],\n",
       "       [0.15636717]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f65360e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 58)\n",
      "(1460, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_X_scaled.shape)\n",
    "print(train_Y_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64a87105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "total_data = np.append(train_X_scaled, train_Y_scaled, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cced174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 59)\n"
     ]
    }
   ],
   "source": [
    "print(total_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41b333f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(train, test) = train_test_split(total_data, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23f66f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 58)\n",
      "(1095,)\n"
     ]
    }
   ],
   "source": [
    "trainX = train[:,:58]\n",
    "trainY = train[:,-1]\n",
    "testX = test[:,:58]\n",
    "testY = test[:,-1]\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb7e0b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24107763],\n",
       "       [0.20358284],\n",
       "       [0.26190807],\n",
       "       ...,\n",
       "       [0.321622  ],\n",
       "       [0.14890293],\n",
       "       [0.15636717]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46b0bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 1)\n"
     ]
    }
   ],
   "source": [
    "trainY = trainY.reshape((trainY.shape[0],1))\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fb86d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = testY.reshape((testY.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaaa596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90d8e9d1",
   "metadata": {},
   "source": [
    "## 2,3 Hidden Layers, 100 epochs, time taken = 147s (model saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e021759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 12:05:18.598365: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-12 12:05:18.599706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-12 12:05:18.668972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 12:05:18.669271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-12 12:05:18.669308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-12 12:05:18.672152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-12 12:05:18.672232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-12 12:05:18.674579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-12 12:05:18.674960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-12 12:05:18.677423: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-12 12:05:18.678776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-12 12:05:18.683095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-12 12:05:18.683253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 12:05:18.683506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 12:05:18.683627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-12 12:05:18.683912: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-12 12:05:18.684163: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-12 12:05:18.684264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 12:05:18.684400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-12 12:05:18.684421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-12 12:05:18.684445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-12 12:05:18.684465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-12 12:05:18.684485: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-12 12:05:18.684504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-12 12:05:18.684523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-12 12:05:18.684544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-12 12:05:18.684564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-12 12:05:18.684630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 12:05:18.684805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 12:05:18.684924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-12 12:05:18.684956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-12 12:05:19.060639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-12 12:05:19.060666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-08-12 12:05:19.060671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-08-12 12:05:19.060831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 12:05:19.060988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 12:05:19.061106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-12 12:05:19.061199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4999 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2022-08-12 12:05:19.289314: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-08-12 12:05:19.289701: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 2.8045 - output_layer_dense_16_16_loss: 0.1512 - output_layer_dense_16_32_loss: 0.2114 - output_layer_dense_16_64_loss: 0.3138 - output_layer_dense_16_128_loss: 0.1810 - output_layer_dense_16_196_loss: 0.2467 - output_layer_dense_16_256_loss: 0.2658 - output_layer_dense_32_16_loss: 0.6010 - output_layer_dense_32_32_loss: 0.4143 - output_layer_dense_32_64_loss: 0.3092 - output_layer_dense_32_128_loss: 0.1103\n",
      "Epoch 2/10\n",
      "1/9 [==>...........................] - ETA: 0s - loss: 1.4479 - output_layer_dense_16_16_loss: 0.0919 - output_layer_dense_16_32_loss: 0.1427 - output_layer_dense_16_64_loss: 0.1824 - output_layer_dense_16_128_loss: 0.1033 - output_layer_dense_16_196_loss: 0.0955 - output_layer_dense_16_256_loss: 0.1595 - output_layer_dense_32_16_loss: 0.3390 - output_layer_dense_32_32_loss: 0.1280 - output_layer_dense_32_64_loss: 0.1170 - output_layer_dense_32_128_loss: 0.0887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 12:05:20.719489: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step - loss: 1.4245 - output_layer_dense_16_16_loss: 0.1104 - output_layer_dense_16_32_loss: 0.1350 - output_layer_dense_16_64_loss: 0.1779 - output_layer_dense_16_128_loss: 0.1032 - output_layer_dense_16_196_loss: 0.1099 - output_layer_dense_16_256_loss: 0.1311 - output_layer_dense_32_16_loss: 0.2964 - output_layer_dense_32_32_loss: 0.1478 - output_layer_dense_32_64_loss: 0.1281 - output_layer_dense_32_128_loss: 0.0849\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.0487 - output_layer_dense_16_16_loss: 0.0971 - output_layer_dense_16_32_loss: 0.1078 - output_layer_dense_16_64_loss: 0.1230 - output_layer_dense_16_128_loss: 0.0767 - output_layer_dense_16_196_loss: 0.0820 - output_layer_dense_16_256_loss: 0.0870 - output_layer_dense_32_16_loss: 0.1972 - output_layer_dense_32_32_loss: 0.1229 - output_layer_dense_32_64_loss: 0.0878 - output_layer_dense_32_128_loss: 0.0671\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8889 - output_layer_dense_16_16_loss: 0.0846 - output_layer_dense_16_32_loss: 0.0930 - output_layer_dense_16_64_loss: 0.1022 - output_layer_dense_16_128_loss: 0.0737 - output_layer_dense_16_196_loss: 0.0744 - output_layer_dense_16_256_loss: 0.0755 - output_layer_dense_32_16_loss: 0.1467 - output_layer_dense_32_32_loss: 0.1033 - output_layer_dense_32_64_loss: 0.0732 - output_layer_dense_32_128_loss: 0.0624\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8167 - output_layer_dense_16_16_loss: 0.0816 - output_layer_dense_16_32_loss: 0.0817 - output_layer_dense_16_64_loss: 0.0892 - output_layer_dense_16_128_loss: 0.0652 - output_layer_dense_16_196_loss: 0.0753 - output_layer_dense_16_256_loss: 0.0702 - output_layer_dense_32_16_loss: 0.1227 - output_layer_dense_32_32_loss: 0.0965 - output_layer_dense_32_64_loss: 0.0722 - output_layer_dense_32_128_loss: 0.0622\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7337 - output_layer_dense_16_16_loss: 0.0715 - output_layer_dense_16_32_loss: 0.0710 - output_layer_dense_16_64_loss: 0.0801 - output_layer_dense_16_128_loss: 0.0649 - output_layer_dense_16_196_loss: 0.0701 - output_layer_dense_16_256_loss: 0.0630 - output_layer_dense_32_16_loss: 0.1026 - output_layer_dense_32_32_loss: 0.0879 - output_layer_dense_32_64_loss: 0.0637 - output_layer_dense_32_128_loss: 0.0589\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7184 - output_layer_dense_16_16_loss: 0.0712 - output_layer_dense_16_32_loss: 0.0725 - output_layer_dense_16_64_loss: 0.0776 - output_layer_dense_16_128_loss: 0.0639 - output_layer_dense_16_196_loss: 0.0708 - output_layer_dense_16_256_loss: 0.0622 - output_layer_dense_32_16_loss: 0.0920 - output_layer_dense_32_32_loss: 0.0854 - output_layer_dense_32_64_loss: 0.0630 - output_layer_dense_32_128_loss: 0.0597\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6467 - output_layer_dense_16_16_loss: 0.0660 - output_layer_dense_16_32_loss: 0.0653 - output_layer_dense_16_64_loss: 0.0694 - output_layer_dense_16_128_loss: 0.0610 - output_layer_dense_16_196_loss: 0.0647 - output_layer_dense_16_256_loss: 0.0568 - output_layer_dense_32_16_loss: 0.0801 - output_layer_dense_32_32_loss: 0.0754 - output_layer_dense_32_64_loss: 0.0560 - output_layer_dense_32_128_loss: 0.0519\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6166 - output_layer_dense_16_16_loss: 0.0644 - output_layer_dense_16_32_loss: 0.0615 - output_layer_dense_16_64_loss: 0.0678 - output_layer_dense_16_128_loss: 0.0541 - output_layer_dense_16_196_loss: 0.0640 - output_layer_dense_16_256_loss: 0.0539 - output_layer_dense_32_16_loss: 0.0747 - output_layer_dense_32_32_loss: 0.0720 - output_layer_dense_32_64_loss: 0.0541 - output_layer_dense_32_128_loss: 0.0501\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6300 - output_layer_dense_16_16_loss: 0.0646 - output_layer_dense_16_32_loss: 0.0642 - output_layer_dense_16_64_loss: 0.0687 - output_layer_dense_16_128_loss: 0.0597 - output_layer_dense_16_196_loss: 0.0651 - output_layer_dense_16_256_loss: 0.0552 - output_layer_dense_32_16_loss: 0.0714 - output_layer_dense_32_32_loss: 0.0716 - output_layer_dense_32_64_loss: 0.0566 - output_layer_dense_32_128_loss: 0.0528\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.5825173854827881 , TEST :  0.631692111492157\n",
      "output_layer_dense_16_16_loss  :  0.06104275956749916 , TEST :  0.06715882569551468\n",
      "output_layer_dense_16_32_loss  :  0.05963478237390518 , TEST :  0.06382852047681808\n",
      "output_layer_dense_16_64_loss  :  0.06372516602277756 , TEST :  0.06888051331043243\n",
      "output_layer_dense_16_128_loss  :  0.053319983184337616 , TEST :  0.05677112564444542\n",
      "output_layer_dense_16_196_loss  :  0.060566145926713943 , TEST :  0.06640619039535522\n",
      "output_layer_dense_16_256_loss  :  0.05042361840605736 , TEST :  0.05771614611148834\n",
      "output_layer_dense_32_16_loss  :  0.06701524555683136 , TEST :  0.06686490029096603\n",
      "output_layer_dense_32_32_loss  :  0.06677620857954025 , TEST :  0.07184234261512756\n",
      "output_layer_dense_32_64_loss  :  0.051715582609176636 , TEST :  0.0554712638258934\n",
      "output_layer_dense_32_128_loss  :  0.04829796403646469 , TEST :  0.05675232782959938\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 5ms/step - loss: 1.6349 - output_layer_dense_32_196_loss: 0.1488 - output_layer_dense_32_256_loss: 0.1314 - output_layer_dense_64_16_loss: 0.1554 - output_layer_dense_64_32_loss: 0.1377 - output_layer_dense_64_64_loss: 0.1622 - output_layer_dense_64_128_loss: 0.1360 - output_layer_dense_64_196_loss: 0.1997 - output_layer_dense_64_256_loss: 0.2173 - output_layer_dense_128_16_loss: 0.2396 - output_layer_dense_128_32_loss: 0.1068\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8968 - output_layer_dense_32_196_loss: 0.0853 - output_layer_dense_32_256_loss: 0.0760 - output_layer_dense_64_16_loss: 0.0982 - output_layer_dense_64_32_loss: 0.0972 - output_layer_dense_64_64_loss: 0.0976 - output_layer_dense_64_128_loss: 0.0779 - output_layer_dense_64_196_loss: 0.0967 - output_layer_dense_64_256_loss: 0.0933 - output_layer_dense_128_16_loss: 0.1056 - output_layer_dense_128_32_loss: 0.0689\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7285 - output_layer_dense_32_196_loss: 0.0718 - output_layer_dense_32_256_loss: 0.0643 - output_layer_dense_64_16_loss: 0.0766 - output_layer_dense_64_32_loss: 0.0817 - output_layer_dense_64_64_loss: 0.0769 - output_layer_dense_64_128_loss: 0.0639 - output_layer_dense_64_196_loss: 0.0784 - output_layer_dense_64_256_loss: 0.0746 - output_layer_dense_128_16_loss: 0.0829 - output_layer_dense_128_32_loss: 0.0573\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6107 - output_layer_dense_32_196_loss: 0.0592 - output_layer_dense_32_256_loss: 0.0573 - output_layer_dense_64_16_loss: 0.0638 - output_layer_dense_64_32_loss: 0.0720 - output_layer_dense_64_64_loss: 0.0665 - output_layer_dense_64_128_loss: 0.0549 - output_layer_dense_64_196_loss: 0.0627 - output_layer_dense_64_256_loss: 0.0581 - output_layer_dense_128_16_loss: 0.0680 - output_layer_dense_128_32_loss: 0.0483\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5665 - output_layer_dense_32_196_loss: 0.0555 - output_layer_dense_32_256_loss: 0.0545 - output_layer_dense_64_16_loss: 0.0589 - output_layer_dense_64_32_loss: 0.0667 - output_layer_dense_64_64_loss: 0.0584 - output_layer_dense_64_128_loss: 0.0500 - output_layer_dense_64_196_loss: 0.0581 - output_layer_dense_64_256_loss: 0.0520 - output_layer_dense_128_16_loss: 0.0654 - output_layer_dense_128_32_loss: 0.0469\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5445 - output_layer_dense_32_196_loss: 0.0552 - output_layer_dense_32_256_loss: 0.0556 - output_layer_dense_64_16_loss: 0.0550 - output_layer_dense_64_32_loss: 0.0612 - output_layer_dense_64_64_loss: 0.0572 - output_layer_dense_64_128_loss: 0.0496 - output_layer_dense_64_196_loss: 0.0545 - output_layer_dense_64_256_loss: 0.0511 - output_layer_dense_128_16_loss: 0.0592 - output_layer_dense_128_32_loss: 0.0457\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5013 - output_layer_dense_32_196_loss: 0.0503 - output_layer_dense_32_256_loss: 0.0509 - output_layer_dense_64_16_loss: 0.0522 - output_layer_dense_64_32_loss: 0.0559 - output_layer_dense_64_64_loss: 0.0521 - output_layer_dense_64_128_loss: 0.0455 - output_layer_dense_64_196_loss: 0.0491 - output_layer_dense_64_256_loss: 0.0464 - output_layer_dense_128_16_loss: 0.0555 - output_layer_dense_128_32_loss: 0.0436\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4931 - output_layer_dense_32_196_loss: 0.0504 - output_layer_dense_32_256_loss: 0.0458 - output_layer_dense_64_16_loss: 0.0527 - output_layer_dense_64_32_loss: 0.0588 - output_layer_dense_64_64_loss: 0.0482 - output_layer_dense_64_128_loss: 0.0454 - output_layer_dense_64_196_loss: 0.0495 - output_layer_dense_64_256_loss: 0.0460 - output_layer_dense_128_16_loss: 0.0528 - output_layer_dense_128_32_loss: 0.0435\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4358 - output_layer_dense_32_196_loss: 0.0449 - output_layer_dense_32_256_loss: 0.0425 - output_layer_dense_64_16_loss: 0.0451 - output_layer_dense_64_32_loss: 0.0506 - output_layer_dense_64_64_loss: 0.0446 - output_layer_dense_64_128_loss: 0.0373 - output_layer_dense_64_196_loss: 0.0431 - output_layer_dense_64_256_loss: 0.0405 - output_layer_dense_128_16_loss: 0.0475 - output_layer_dense_128_32_loss: 0.0397\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4337 - output_layer_dense_32_196_loss: 0.0448 - output_layer_dense_32_256_loss: 0.0428 - output_layer_dense_64_16_loss: 0.0470 - output_layer_dense_64_32_loss: 0.0482 - output_layer_dense_64_64_loss: 0.0432 - output_layer_dense_64_128_loss: 0.0386 - output_layer_dense_64_196_loss: 0.0436 - output_layer_dense_64_256_loss: 0.0412 - output_layer_dense_128_16_loss: 0.0467 - output_layer_dense_128_32_loss: 0.0376\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4073077440261841 , TEST :  0.5052921175956726\n",
      "output_layer_dense_32_196_loss  :  0.0429038405418396 , TEST :  0.05029304698109627\n",
      "output_layer_dense_32_256_loss  :  0.03923780098557472 , TEST :  0.048710066825151443\n",
      "output_layer_dense_64_16_loss  :  0.04363830387592316 , TEST :  0.05017288774251938\n",
      "output_layer_dense_64_32_loss  :  0.046516843140125275 , TEST :  0.05446711555123329\n",
      "output_layer_dense_64_64_loss  :  0.04010460153222084 , TEST :  0.04989536106586456\n",
      "output_layer_dense_64_128_loss  :  0.03593683987855911 , TEST :  0.05055435001850128\n",
      "output_layer_dense_64_196_loss  :  0.040020011365413666 , TEST :  0.04999876022338867\n",
      "output_layer_dense_64_256_loss  :  0.037210725247859955 , TEST :  0.04603425785899162\n",
      "output_layer_dense_128_16_loss  :  0.04689980298280716 , TEST :  0.05599011853337288\n",
      "output_layer_dense_128_32_loss  :  0.0348389595746994 , TEST :  0.049176175147295\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 4ms/step - loss: 1.8237 - output_layer_dense_128_64_loss: 0.1058 - output_layer_dense_128_128_loss: 0.2681 - output_layer_dense_128_196_loss: 0.1428 - output_layer_dense_128_256_loss: 0.1888 - output_layer_dense_196_16_loss: 0.2107 - output_layer_dense_196_32_loss: 0.1848 - output_layer_dense_196_64_loss: 0.2292 - output_layer_dense_196_128_loss: 0.1297 - output_layer_dense_196_196_loss: 0.1687 - output_layer_dense_196_256_loss: 0.1951\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8514 - output_layer_dense_128_64_loss: 0.0725 - output_layer_dense_128_128_loss: 0.0969 - output_layer_dense_128_196_loss: 0.0753 - output_layer_dense_128_256_loss: 0.0940 - output_layer_dense_196_16_loss: 0.0802 - output_layer_dense_196_32_loss: 0.0785 - output_layer_dense_196_64_loss: 0.1081 - output_layer_dense_196_128_loss: 0.0719 - output_layer_dense_196_196_loss: 0.0848 - output_layer_dense_196_256_loss: 0.0892\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6229 - output_layer_dense_128_64_loss: 0.0563 - output_layer_dense_128_128_loss: 0.0802 - output_layer_dense_128_196_loss: 0.0572 - output_layer_dense_128_256_loss: 0.0621 - output_layer_dense_196_16_loss: 0.0623 - output_layer_dense_196_32_loss: 0.0570 - output_layer_dense_196_64_loss: 0.0651 - output_layer_dense_196_128_loss: 0.0544 - output_layer_dense_196_196_loss: 0.0669 - output_layer_dense_196_256_loss: 0.0613\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5655 - output_layer_dense_128_64_loss: 0.0549 - output_layer_dense_128_128_loss: 0.0638 - output_layer_dense_128_196_loss: 0.0542 - output_layer_dense_128_256_loss: 0.0553 - output_layer_dense_196_16_loss: 0.0608 - output_layer_dense_196_32_loss: 0.0551 - output_layer_dense_196_64_loss: 0.0602 - output_layer_dense_196_128_loss: 0.0506 - output_layer_dense_196_196_loss: 0.0567 - output_layer_dense_196_256_loss: 0.0538\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4756 - output_layer_dense_128_64_loss: 0.0483 - output_layer_dense_128_128_loss: 0.0548 - output_layer_dense_128_196_loss: 0.0446 - output_layer_dense_128_256_loss: 0.0455 - output_layer_dense_196_16_loss: 0.0531 - output_layer_dense_196_32_loss: 0.0455 - output_layer_dense_196_64_loss: 0.0515 - output_layer_dense_196_128_loss: 0.0406 - output_layer_dense_196_196_loss: 0.0460 - output_layer_dense_196_256_loss: 0.0456\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4827 - output_layer_dense_128_64_loss: 0.0516 - output_layer_dense_128_128_loss: 0.0519 - output_layer_dense_128_196_loss: 0.0467 - output_layer_dense_128_256_loss: 0.0476 - output_layer_dense_196_16_loss: 0.0536 - output_layer_dense_196_32_loss: 0.0468 - output_layer_dense_196_64_loss: 0.0490 - output_layer_dense_196_128_loss: 0.0429 - output_layer_dense_196_196_loss: 0.0466 - output_layer_dense_196_256_loss: 0.0460\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4671 - output_layer_dense_128_64_loss: 0.0468 - output_layer_dense_128_128_loss: 0.0501 - output_layer_dense_128_196_loss: 0.0436 - output_layer_dense_128_256_loss: 0.0469 - output_layer_dense_196_16_loss: 0.0518 - output_layer_dense_196_32_loss: 0.0482 - output_layer_dense_196_64_loss: 0.0461 - output_layer_dense_196_128_loss: 0.0428 - output_layer_dense_196_196_loss: 0.0446 - output_layer_dense_196_256_loss: 0.0462\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3894 - output_layer_dense_128_64_loss: 0.0401 - output_layer_dense_128_128_loss: 0.0413 - output_layer_dense_128_196_loss: 0.0351 - output_layer_dense_128_256_loss: 0.0383 - output_layer_dense_196_16_loss: 0.0451 - output_layer_dense_196_32_loss: 0.0397 - output_layer_dense_196_64_loss: 0.0388 - output_layer_dense_196_128_loss: 0.0354 - output_layer_dense_196_196_loss: 0.0387 - output_layer_dense_196_256_loss: 0.0369\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3667 - output_layer_dense_128_64_loss: 0.0373 - output_layer_dense_128_128_loss: 0.0401 - output_layer_dense_128_196_loss: 0.0343 - output_layer_dense_128_256_loss: 0.0358 - output_layer_dense_196_16_loss: 0.0431 - output_layer_dense_196_32_loss: 0.0363 - output_layer_dense_196_64_loss: 0.0367 - output_layer_dense_196_128_loss: 0.0316 - output_layer_dense_196_196_loss: 0.0357 - output_layer_dense_196_256_loss: 0.0357\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3349 - output_layer_dense_128_64_loss: 0.0343 - output_layer_dense_128_128_loss: 0.0369 - output_layer_dense_128_196_loss: 0.0317 - output_layer_dense_128_256_loss: 0.0326 - output_layer_dense_196_16_loss: 0.0398 - output_layer_dense_196_32_loss: 0.0337 - output_layer_dense_196_64_loss: 0.0341 - output_layer_dense_196_128_loss: 0.0292 - output_layer_dense_196_196_loss: 0.0312 - output_layer_dense_196_256_loss: 0.0316\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3312278687953949 , TEST :  0.46273016929626465\n",
      "output_layer_dense_128_64_loss  :  0.03438883274793625 , TEST :  0.04637410491704941\n",
      "output_layer_dense_128_128_loss  :  0.03536302223801613 , TEST :  0.04775115102529526\n",
      "output_layer_dense_128_196_loss  :  0.031034907326102257 , TEST :  0.04581454396247864\n",
      "output_layer_dense_128_256_loss  :  0.03521878272294998 , TEST :  0.0485457219183445\n",
      "output_layer_dense_196_16_loss  :  0.04084620997309685 , TEST :  0.044801294803619385\n",
      "output_layer_dense_196_32_loss  :  0.03371356800198555 , TEST :  0.04522129148244858\n",
      "output_layer_dense_196_64_loss  :  0.032120101153850555 , TEST :  0.0478702187538147\n",
      "output_layer_dense_196_128_loss  :  0.02764703519642353 , TEST :  0.04525889456272125\n",
      "output_layer_dense_196_196_loss  :  0.029985349625349045 , TEST :  0.04656613990664482\n",
      "output_layer_dense_196_256_loss  :  0.03091004304587841 , TEST :  0.0445268340408802\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 3ms/step - loss: 1.0695 - output_layer_dense_256_16_loss: 0.2395 - output_layer_dense_256_32_loss: 0.1345 - output_layer_dense_256_64_loss: 0.1564 - output_layer_dense_256_128_loss: 0.1467 - output_layer_dense_256_196_loss: 0.2260 - output_layer_dense_256_256_loss: 0.1664\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4791 - output_layer_dense_256_16_loss: 0.0802 - output_layer_dense_256_32_loss: 0.0631 - output_layer_dense_256_64_loss: 0.0794 - output_layer_dense_256_128_loss: 0.0800 - output_layer_dense_256_196_loss: 0.0989 - output_layer_dense_256_256_loss: 0.0776\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.3651 - output_layer_dense_256_16_loss: 0.0634 - output_layer_dense_256_32_loss: 0.0558 - output_layer_dense_256_64_loss: 0.0599 - output_layer_dense_256_128_loss: 0.0568 - output_layer_dense_256_196_loss: 0.0779 - output_layer_dense_256_256_loss: 0.0513\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.3098 - output_layer_dense_256_16_loss: 0.0553 - output_layer_dense_256_32_loss: 0.0495 - output_layer_dense_256_64_loss: 0.0499 - output_layer_dense_256_128_loss: 0.0514 - output_layer_dense_256_196_loss: 0.0580 - output_layer_dense_256_256_loss: 0.0456\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2652 - output_layer_dense_256_16_loss: 0.0458 - output_layer_dense_256_32_loss: 0.0452 - output_layer_dense_256_64_loss: 0.0441 - output_layer_dense_256_128_loss: 0.0445 - output_layer_dense_256_196_loss: 0.0466 - output_layer_dense_256_256_loss: 0.0391\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2563 - output_layer_dense_256_16_loss: 0.0458 - output_layer_dense_256_32_loss: 0.0439 - output_layer_dense_256_64_loss: 0.0409 - output_layer_dense_256_128_loss: 0.0448 - output_layer_dense_256_196_loss: 0.0430 - output_layer_dense_256_256_loss: 0.0379\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2458 - output_layer_dense_256_16_loss: 0.0431 - output_layer_dense_256_32_loss: 0.0395 - output_layer_dense_256_64_loss: 0.0410 - output_layer_dense_256_128_loss: 0.0429 - output_layer_dense_256_196_loss: 0.0408 - output_layer_dense_256_256_loss: 0.0386\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2529 - output_layer_dense_256_16_loss: 0.0455 - output_layer_dense_256_32_loss: 0.0408 - output_layer_dense_256_64_loss: 0.0446 - output_layer_dense_256_128_loss: 0.0408 - output_layer_dense_256_196_loss: 0.0415 - output_layer_dense_256_256_loss: 0.0397\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2308 - output_layer_dense_256_16_loss: 0.0417 - output_layer_dense_256_32_loss: 0.0377 - output_layer_dense_256_64_loss: 0.0428 - output_layer_dense_256_128_loss: 0.0363 - output_layer_dense_256_196_loss: 0.0369 - output_layer_dense_256_256_loss: 0.0353\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2064 - output_layer_dense_256_16_loss: 0.0393 - output_layer_dense_256_32_loss: 0.0365 - output_layer_dense_256_64_loss: 0.0361 - output_layer_dense_256_128_loss: 0.0308 - output_layer_dense_256_196_loss: 0.0325 - output_layer_dense_256_256_loss: 0.0311\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.19675560295581818 , TEST :  0.2857978641986847\n",
      "output_layer_dense_256_16_loss  :  0.03463186323642731 , TEST :  0.04411717876791954\n",
      "output_layer_dense_256_32_loss  :  0.031676460057497025 , TEST :  0.04801856726408005\n",
      "output_layer_dense_256_64_loss  :  0.03341391310095787 , TEST :  0.050145406275987625\n",
      "output_layer_dense_256_128_loss  :  0.03261517733335495 , TEST :  0.04996289312839508\n",
      "output_layer_dense_256_196_loss  :  0.03390398249030113 , TEST :  0.04625978693366051\n",
      "output_layer_dense_256_256_loss  :  0.030514216050505638 , TEST :  0.0472940057516098\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 2.6385 - output_layer_dense_16_16_16_loss: 0.1733 - output_layer_dense_16_16_32_loss: 0.4984 - output_layer_dense_16_16_64_loss: 0.1587 - output_layer_dense_16_16_128_loss: 0.2689 - output_layer_dense_16_16_196_loss: 0.1696 - output_layer_dense_16_16_256_loss: 0.2153 - output_layer_dense_16_32_16_loss: 0.2257 - output_layer_dense_16_32_32_loss: 0.3070 - output_layer_dense_16_32_64_loss: 0.4125 - output_layer_dense_16_32_128_loss: 0.2089\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.4209 - output_layer_dense_16_16_16_loss: 0.1050 - output_layer_dense_16_16_32_loss: 0.2921 - output_layer_dense_16_16_64_loss: 0.0978 - output_layer_dense_16_16_128_loss: 0.1224 - output_layer_dense_16_16_196_loss: 0.1002 - output_layer_dense_16_16_256_loss: 0.1067 - output_layer_dense_16_32_16_loss: 0.1343 - output_layer_dense_16_32_32_loss: 0.1281 - output_layer_dense_16_32_64_loss: 0.2153 - output_layer_dense_16_32_128_loss: 0.1192\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.9582 - output_layer_dense_16_16_16_loss: 0.0812 - output_layer_dense_16_16_32_loss: 0.1428 - output_layer_dense_16_16_64_loss: 0.0730 - output_layer_dense_16_16_128_loss: 0.1097 - output_layer_dense_16_16_196_loss: 0.0799 - output_layer_dense_16_16_256_loss: 0.0807 - output_layer_dense_16_32_16_loss: 0.0881 - output_layer_dense_16_32_32_loss: 0.1000 - output_layer_dense_16_32_64_loss: 0.1092 - output_layer_dense_16_32_128_loss: 0.0937\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8404 - output_layer_dense_16_16_16_loss: 0.0747 - output_layer_dense_16_16_32_loss: 0.1108 - output_layer_dense_16_16_64_loss: 0.0666 - output_layer_dense_16_16_128_loss: 0.0907 - output_layer_dense_16_16_196_loss: 0.0737 - output_layer_dense_16_16_256_loss: 0.0692 - output_layer_dense_16_32_16_loss: 0.0857 - output_layer_dense_16_32_32_loss: 0.0855 - output_layer_dense_16_32_64_loss: 0.1021 - output_layer_dense_16_32_128_loss: 0.0816\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8233 - output_layer_dense_16_16_16_loss: 0.0759 - output_layer_dense_16_16_32_loss: 0.0990 - output_layer_dense_16_16_64_loss: 0.0654 - output_layer_dense_16_16_128_loss: 0.0912 - output_layer_dense_16_16_196_loss: 0.0717 - output_layer_dense_16_16_256_loss: 0.0725 - output_layer_dense_16_32_16_loss: 0.0816 - output_layer_dense_16_32_32_loss: 0.0853 - output_layer_dense_16_32_64_loss: 0.0948 - output_layer_dense_16_32_128_loss: 0.0859\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7434 - output_layer_dense_16_16_16_loss: 0.0695 - output_layer_dense_16_16_32_loss: 0.0904 - output_layer_dense_16_16_64_loss: 0.0605 - output_layer_dense_16_16_128_loss: 0.0811 - output_layer_dense_16_16_196_loss: 0.0628 - output_layer_dense_16_16_256_loss: 0.0665 - output_layer_dense_16_32_16_loss: 0.0730 - output_layer_dense_16_32_32_loss: 0.0759 - output_layer_dense_16_32_64_loss: 0.0835 - output_layer_dense_16_32_128_loss: 0.0803\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7500 - output_layer_dense_16_16_16_loss: 0.0716 - output_layer_dense_16_16_32_loss: 0.0911 - output_layer_dense_16_16_64_loss: 0.0604 - output_layer_dense_16_16_128_loss: 0.0786 - output_layer_dense_16_16_196_loss: 0.0670 - output_layer_dense_16_16_256_loss: 0.0664 - output_layer_dense_16_32_16_loss: 0.0743 - output_layer_dense_16_32_32_loss: 0.0777 - output_layer_dense_16_32_64_loss: 0.0828 - output_layer_dense_16_32_128_loss: 0.0801\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6510 - output_layer_dense_16_16_16_loss: 0.0626 - output_layer_dense_16_16_32_loss: 0.0799 - output_layer_dense_16_16_64_loss: 0.0528 - output_layer_dense_16_16_128_loss: 0.0664 - output_layer_dense_16_16_196_loss: 0.0587 - output_layer_dense_16_16_256_loss: 0.0597 - output_layer_dense_16_32_16_loss: 0.0632 - output_layer_dense_16_32_32_loss: 0.0693 - output_layer_dense_16_32_64_loss: 0.0697 - output_layer_dense_16_32_128_loss: 0.0687\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6507 - output_layer_dense_16_16_16_loss: 0.0625 - output_layer_dense_16_16_32_loss: 0.0805 - output_layer_dense_16_16_64_loss: 0.0535 - output_layer_dense_16_16_128_loss: 0.0651 - output_layer_dense_16_16_196_loss: 0.0597 - output_layer_dense_16_16_256_loss: 0.0597 - output_layer_dense_16_32_16_loss: 0.0634 - output_layer_dense_16_32_32_loss: 0.0687 - output_layer_dense_16_32_64_loss: 0.0688 - output_layer_dense_16_32_128_loss: 0.0688\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6310 - output_layer_dense_16_16_16_loss: 0.0609 - output_layer_dense_16_16_32_loss: 0.0758 - output_layer_dense_16_16_64_loss: 0.0526 - output_layer_dense_16_16_128_loss: 0.0622 - output_layer_dense_16_16_196_loss: 0.0577 - output_layer_dense_16_16_256_loss: 0.0580 - output_layer_dense_16_32_16_loss: 0.0617 - output_layer_dense_16_32_32_loss: 0.0677 - output_layer_dense_16_32_64_loss: 0.0662 - output_layer_dense_16_32_128_loss: 0.0682\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.5947926640510559 , TEST :  0.6498615741729736\n",
      "output_layer_dense_16_16_16_loss  :  0.05849874019622803 , TEST :  0.06565108150243759\n",
      "output_layer_dense_16_16_32_loss  :  0.07319194823503494 , TEST :  0.07913503795862198\n",
      "output_layer_dense_16_16_64_loss  :  0.048611514270305634 , TEST :  0.056558702141046524\n",
      "output_layer_dense_16_16_128_loss  :  0.05772826075553894 , TEST :  0.061497773975133896\n",
      "output_layer_dense_16_16_196_loss  :  0.05375155434012413 , TEST :  0.05671123415231705\n",
      "output_layer_dense_16_16_256_loss  :  0.05566897615790367 , TEST :  0.06100941449403763\n",
      "output_layer_dense_16_32_16_loss  :  0.057850562036037445 , TEST :  0.06217927858233452\n",
      "output_layer_dense_16_32_32_loss  :  0.06489894539117813 , TEST :  0.07245378196239471\n",
      "output_layer_dense_16_32_64_loss  :  0.062018197029829025 , TEST :  0.06658098101615906\n",
      "output_layer_dense_16_32_128_loss  :  0.06257389485836029 , TEST :  0.068084217607975\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 2.0426 - output_layer_dense_16_32_196_loss: 0.1720 - output_layer_dense_16_32_256_loss: 0.1517 - output_layer_dense_16_64_16_loss: 0.2121 - output_layer_dense_16_64_32_loss: 0.3025 - output_layer_dense_16_64_64_loss: 0.2778 - output_layer_dense_16_64_128_loss: 0.2276 - output_layer_dense_16_64_196_loss: 0.1507 - output_layer_dense_16_64_256_loss: 0.1459 - output_layer_dense_16_128_16_loss: 0.1607 - output_layer_dense_16_128_32_loss: 0.2416\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.0914 - output_layer_dense_16_32_196_loss: 0.1107 - output_layer_dense_16_32_256_loss: 0.1024 - output_layer_dense_16_64_16_loss: 0.1180 - output_layer_dense_16_64_32_loss: 0.1132 - output_layer_dense_16_64_64_loss: 0.1375 - output_layer_dense_16_64_128_loss: 0.1228 - output_layer_dense_16_64_196_loss: 0.0938 - output_layer_dense_16_64_256_loss: 0.0888 - output_layer_dense_16_128_16_loss: 0.0971 - output_layer_dense_16_128_32_loss: 0.1071\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8800 - output_layer_dense_16_32_196_loss: 0.0967 - output_layer_dense_16_32_256_loss: 0.0818 - output_layer_dense_16_64_16_loss: 0.0912 - output_layer_dense_16_64_32_loss: 0.0978 - output_layer_dense_16_64_64_loss: 0.0944 - output_layer_dense_16_64_128_loss: 0.1016 - output_layer_dense_16_64_196_loss: 0.0785 - output_layer_dense_16_64_256_loss: 0.0710 - output_layer_dense_16_128_16_loss: 0.0841 - output_layer_dense_16_128_32_loss: 0.0830\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8076 - output_layer_dense_16_32_196_loss: 0.0867 - output_layer_dense_16_32_256_loss: 0.0716 - output_layer_dense_16_64_16_loss: 0.0838 - output_layer_dense_16_64_32_loss: 0.0955 - output_layer_dense_16_64_64_loss: 0.0868 - output_layer_dense_16_64_128_loss: 0.0843 - output_layer_dense_16_64_196_loss: 0.0750 - output_layer_dense_16_64_256_loss: 0.0700 - output_layer_dense_16_128_16_loss: 0.0782 - output_layer_dense_16_128_32_loss: 0.0757\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7248 - output_layer_dense_16_32_196_loss: 0.0795 - output_layer_dense_16_32_256_loss: 0.0654 - output_layer_dense_16_64_16_loss: 0.0695 - output_layer_dense_16_64_32_loss: 0.0832 - output_layer_dense_16_64_64_loss: 0.0764 - output_layer_dense_16_64_128_loss: 0.0765 - output_layer_dense_16_64_196_loss: 0.0676 - output_layer_dense_16_64_256_loss: 0.0671 - output_layer_dense_16_128_16_loss: 0.0705 - output_layer_dense_16_128_32_loss: 0.0690\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6541 - output_layer_dense_16_32_196_loss: 0.0697 - output_layer_dense_16_32_256_loss: 0.0587 - output_layer_dense_16_64_16_loss: 0.0619 - output_layer_dense_16_64_32_loss: 0.0734 - output_layer_dense_16_64_64_loss: 0.0690 - output_layer_dense_16_64_128_loss: 0.0681 - output_layer_dense_16_64_196_loss: 0.0622 - output_layer_dense_16_64_256_loss: 0.0636 - output_layer_dense_16_128_16_loss: 0.0646 - output_layer_dense_16_128_32_loss: 0.0630\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6251 - output_layer_dense_16_32_196_loss: 0.0665 - output_layer_dense_16_32_256_loss: 0.0564 - output_layer_dense_16_64_16_loss: 0.0613 - output_layer_dense_16_64_32_loss: 0.0719 - output_layer_dense_16_64_64_loss: 0.0638 - output_layer_dense_16_64_128_loss: 0.0642 - output_layer_dense_16_64_196_loss: 0.0592 - output_layer_dense_16_64_256_loss: 0.0617 - output_layer_dense_16_128_16_loss: 0.0608 - output_layer_dense_16_128_32_loss: 0.0592\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.6038 - output_layer_dense_16_32_196_loss: 0.0639 - output_layer_dense_16_32_256_loss: 0.0537 - output_layer_dense_16_64_16_loss: 0.0591 - output_layer_dense_16_64_32_loss: 0.0693 - output_layer_dense_16_64_64_loss: 0.0613 - output_layer_dense_16_64_128_loss: 0.0625 - output_layer_dense_16_64_196_loss: 0.0568 - output_layer_dense_16_64_256_loss: 0.0594 - output_layer_dense_16_128_16_loss: 0.0600 - output_layer_dense_16_128_32_loss: 0.0579\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5679 - output_layer_dense_16_32_196_loss: 0.0599 - output_layer_dense_16_32_256_loss: 0.0495 - output_layer_dense_16_64_16_loss: 0.0556 - output_layer_dense_16_64_32_loss: 0.0671 - output_layer_dense_16_64_64_loss: 0.0564 - output_layer_dense_16_64_128_loss: 0.0601 - output_layer_dense_16_64_196_loss: 0.0523 - output_layer_dense_16_64_256_loss: 0.0569 - output_layer_dense_16_128_16_loss: 0.0571 - output_layer_dense_16_128_32_loss: 0.0530\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5493 - output_layer_dense_16_32_196_loss: 0.0591 - output_layer_dense_16_32_256_loss: 0.0485 - output_layer_dense_16_64_16_loss: 0.0537 - output_layer_dense_16_64_32_loss: 0.0648 - output_layer_dense_16_64_64_loss: 0.0533 - output_layer_dense_16_64_128_loss: 0.0565 - output_layer_dense_16_64_196_loss: 0.0523 - output_layer_dense_16_64_256_loss: 0.0556 - output_layer_dense_16_128_16_loss: 0.0546 - output_layer_dense_16_128_32_loss: 0.0510\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.518006443977356 , TEST :  0.5725160241127014\n",
      "output_layer_dense_16_32_196_loss  :  0.054057516157627106 , TEST :  0.05872757360339165\n",
      "output_layer_dense_16_32_256_loss  :  0.04551611840724945 , TEST :  0.053211942315101624\n",
      "output_layer_dense_16_64_16_loss  :  0.050822913646698 , TEST :  0.05682189762592316\n",
      "output_layer_dense_16_64_32_loss  :  0.06052260100841522 , TEST :  0.06525822728872299\n",
      "output_layer_dense_16_64_64_loss  :  0.05092586576938629 , TEST :  0.059468816965818405\n",
      "output_layer_dense_16_64_128_loss  :  0.05490156635642052 , TEST :  0.05829678848385811\n",
      "output_layer_dense_16_64_196_loss  :  0.04812039062380791 , TEST :  0.052521608769893646\n",
      "output_layer_dense_16_64_256_loss  :  0.05191957205533981 , TEST :  0.05808037519454956\n",
      "output_layer_dense_16_128_16_loss  :  0.05300799757242203 , TEST :  0.057874977588653564\n",
      "output_layer_dense_16_128_32_loss  :  0.04821188375353813 , TEST :  0.05225381255149841\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2s 5ms/step - loss: 1.6377 - output_layer_dense_16_128_64_loss: 0.1507 - output_layer_dense_16_128_128_loss: 0.1303 - output_layer_dense_16_128_196_loss: 0.2255 - output_layer_dense_16_128_256_loss: 0.1666 - output_layer_dense_16_196_16_loss: 0.1880 - output_layer_dense_16_196_32_loss: 0.1170 - output_layer_dense_16_196_64_loss: 0.2301 - output_layer_dense_16_196_128_loss: 0.1661 - output_layer_dense_16_196_196_loss: 0.1325 - output_layer_dense_16_196_256_loss: 0.1308\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9417 - output_layer_dense_16_128_64_loss: 0.1077 - output_layer_dense_16_128_128_loss: 0.0838 - output_layer_dense_16_128_196_loss: 0.0966 - output_layer_dense_16_128_256_loss: 0.0965 - output_layer_dense_16_196_16_loss: 0.1009 - output_layer_dense_16_196_32_loss: 0.0900 - output_layer_dense_16_196_64_loss: 0.0942 - output_layer_dense_16_196_128_loss: 0.0852 - output_layer_dense_16_196_196_loss: 0.0924 - output_layer_dense_16_196_256_loss: 0.0942\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7765 - output_layer_dense_16_128_64_loss: 0.0881 - output_layer_dense_16_128_128_loss: 0.0698 - output_layer_dense_16_128_196_loss: 0.0857 - output_layer_dense_16_128_256_loss: 0.0783 - output_layer_dense_16_196_16_loss: 0.0751 - output_layer_dense_16_196_32_loss: 0.0763 - output_layer_dense_16_196_64_loss: 0.0770 - output_layer_dense_16_196_128_loss: 0.0729 - output_layer_dense_16_196_196_loss: 0.0774 - output_layer_dense_16_196_256_loss: 0.0761\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7557 - output_layer_dense_16_128_64_loss: 0.0855 - output_layer_dense_16_128_128_loss: 0.0726 - output_layer_dense_16_128_196_loss: 0.0800 - output_layer_dense_16_128_256_loss: 0.0735 - output_layer_dense_16_196_16_loss: 0.0707 - output_layer_dense_16_196_32_loss: 0.0740 - output_layer_dense_16_196_64_loss: 0.0743 - output_layer_dense_16_196_128_loss: 0.0751 - output_layer_dense_16_196_196_loss: 0.0764 - output_layer_dense_16_196_256_loss: 0.0737\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7011 - output_layer_dense_16_128_64_loss: 0.0786 - output_layer_dense_16_128_128_loss: 0.0717 - output_layer_dense_16_128_196_loss: 0.0756 - output_layer_dense_16_128_256_loss: 0.0657 - output_layer_dense_16_196_16_loss: 0.0670 - output_layer_dense_16_196_32_loss: 0.0672 - output_layer_dense_16_196_64_loss: 0.0686 - output_layer_dense_16_196_128_loss: 0.0690 - output_layer_dense_16_196_196_loss: 0.0699 - output_layer_dense_16_196_256_loss: 0.0680\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6385 - output_layer_dense_16_128_64_loss: 0.0727 - output_layer_dense_16_128_128_loss: 0.0632 - output_layer_dense_16_128_196_loss: 0.0694 - output_layer_dense_16_128_256_loss: 0.0613 - output_layer_dense_16_196_16_loss: 0.0597 - output_layer_dense_16_196_32_loss: 0.0622 - output_layer_dense_16_196_64_loss: 0.0627 - output_layer_dense_16_196_128_loss: 0.0639 - output_layer_dense_16_196_196_loss: 0.0621 - output_layer_dense_16_196_256_loss: 0.0615\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6106 - output_layer_dense_16_128_64_loss: 0.0681 - output_layer_dense_16_128_128_loss: 0.0618 - output_layer_dense_16_128_196_loss: 0.0664 - output_layer_dense_16_128_256_loss: 0.0591 - output_layer_dense_16_196_16_loss: 0.0585 - output_layer_dense_16_196_32_loss: 0.0604 - output_layer_dense_16_196_64_loss: 0.0583 - output_layer_dense_16_196_128_loss: 0.0593 - output_layer_dense_16_196_196_loss: 0.0599 - output_layer_dense_16_196_256_loss: 0.0589\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5791 - output_layer_dense_16_128_64_loss: 0.0668 - output_layer_dense_16_128_128_loss: 0.0596 - output_layer_dense_16_128_196_loss: 0.0611 - output_layer_dense_16_128_256_loss: 0.0527 - output_layer_dense_16_196_16_loss: 0.0545 - output_layer_dense_16_196_32_loss: 0.0582 - output_layer_dense_16_196_64_loss: 0.0545 - output_layer_dense_16_196_128_loss: 0.0589 - output_layer_dense_16_196_196_loss: 0.0581 - output_layer_dense_16_196_256_loss: 0.0547\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5390 - output_layer_dense_16_128_64_loss: 0.0636 - output_layer_dense_16_128_128_loss: 0.0566 - output_layer_dense_16_128_196_loss: 0.0553 - output_layer_dense_16_128_256_loss: 0.0471 - output_layer_dense_16_196_16_loss: 0.0492 - output_layer_dense_16_196_32_loss: 0.0530 - output_layer_dense_16_196_64_loss: 0.0518 - output_layer_dense_16_196_128_loss: 0.0561 - output_layer_dense_16_196_196_loss: 0.0550 - output_layer_dense_16_196_256_loss: 0.0513\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5495 - output_layer_dense_16_128_64_loss: 0.0629 - output_layer_dense_16_128_128_loss: 0.0579 - output_layer_dense_16_128_196_loss: 0.0579 - output_layer_dense_16_128_256_loss: 0.0479 - output_layer_dense_16_196_16_loss: 0.0519 - output_layer_dense_16_196_32_loss: 0.0522 - output_layer_dense_16_196_64_loss: 0.0540 - output_layer_dense_16_196_128_loss: 0.0585 - output_layer_dense_16_196_196_loss: 0.0547 - output_layer_dense_16_196_256_loss: 0.0515\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.5008952021598816 , TEST :  0.5694335699081421\n",
      "output_layer_dense_16_128_64_loss  :  0.05588947609066963 , TEST :  0.0597107820212841\n",
      "output_layer_dense_16_128_128_loss  :  0.05306074395775795 , TEST :  0.06187409535050392\n",
      "output_layer_dense_16_128_196_loss  :  0.05359409749507904 , TEST :  0.05775132402777672\n",
      "output_layer_dense_16_128_256_loss  :  0.04319964721798897 , TEST :  0.05075515806674957\n",
      "output_layer_dense_16_196_16_loss  :  0.04742506891489029 , TEST :  0.05419141799211502\n",
      "output_layer_dense_16_196_32_loss  :  0.04979991912841797 , TEST :  0.056790150701999664\n",
      "output_layer_dense_16_196_64_loss  :  0.049953002482652664 , TEST :  0.055862829089164734\n",
      "output_layer_dense_16_196_128_loss  :  0.05223666504025459 , TEST :  0.05935688316822052\n",
      "output_layer_dense_16_196_196_loss  :  0.04922850430011749 , TEST :  0.05694005638360977\n",
      "output_layer_dense_16_196_256_loss  :  0.046508051455020905 , TEST :  0.056200817227363586\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 1.7828 - output_layer_dense_16_256_16_loss: 0.1539 - output_layer_dense_16_256_32_loss: 0.1422 - output_layer_dense_16_256_64_loss: 0.1437 - output_layer_dense_16_256_128_loss: 0.1480 - output_layer_dense_16_256_196_loss: 0.1244 - output_layer_dense_16_256_256_loss: 0.1610 - output_layer_dense_32_16_16_loss: 0.1477 - output_layer_dense_32_32_16_loss: 0.1774 - output_layer_dense_32_32_32_loss: 0.2030 - output_layer_dense_32_32_64_loss: 0.3816\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.0039 - output_layer_dense_16_256_16_loss: 0.0916 - output_layer_dense_16_256_32_loss: 0.0902 - output_layer_dense_16_256_64_loss: 0.0830 - output_layer_dense_16_256_128_loss: 0.0957 - output_layer_dense_16_256_196_loss: 0.0863 - output_layer_dense_16_256_256_loss: 0.1045 - output_layer_dense_32_16_16_loss: 0.0990 - output_layer_dense_32_32_16_loss: 0.1130 - output_layer_dense_32_32_32_loss: 0.1186 - output_layer_dense_32_32_64_loss: 0.1219\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.8220 - output_layer_dense_16_256_16_loss: 0.0753 - output_layer_dense_16_256_32_loss: 0.0776 - output_layer_dense_16_256_64_loss: 0.0749 - output_layer_dense_16_256_128_loss: 0.0779 - output_layer_dense_16_256_196_loss: 0.0722 - output_layer_dense_16_256_256_loss: 0.0861 - output_layer_dense_32_16_16_loss: 0.0794 - output_layer_dense_32_32_16_loss: 0.0888 - output_layer_dense_32_32_32_loss: 0.0934 - output_layer_dense_32_32_64_loss: 0.0963\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6802 - output_layer_dense_16_256_16_loss: 0.0657 - output_layer_dense_16_256_32_loss: 0.0663 - output_layer_dense_16_256_64_loss: 0.0635 - output_layer_dense_16_256_128_loss: 0.0679 - output_layer_dense_16_256_196_loss: 0.0629 - output_layer_dense_16_256_256_loss: 0.0669 - output_layer_dense_32_16_16_loss: 0.0640 - output_layer_dense_32_32_16_loss: 0.0722 - output_layer_dense_32_32_32_loss: 0.0740 - output_layer_dense_32_32_64_loss: 0.0768\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6738 - output_layer_dense_16_256_16_loss: 0.0662 - output_layer_dense_16_256_32_loss: 0.0668 - output_layer_dense_16_256_64_loss: 0.0637 - output_layer_dense_16_256_128_loss: 0.0696 - output_layer_dense_16_256_196_loss: 0.0642 - output_layer_dense_16_256_256_loss: 0.0644 - output_layer_dense_32_16_16_loss: 0.0648 - output_layer_dense_32_32_16_loss: 0.0719 - output_layer_dense_32_32_32_loss: 0.0704 - output_layer_dense_32_32_64_loss: 0.0718\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5864 - output_layer_dense_16_256_16_loss: 0.0579 - output_layer_dense_16_256_32_loss: 0.0577 - output_layer_dense_16_256_64_loss: 0.0534 - output_layer_dense_16_256_128_loss: 0.0634 - output_layer_dense_16_256_196_loss: 0.0600 - output_layer_dense_16_256_256_loss: 0.0575 - output_layer_dense_32_16_16_loss: 0.0545 - output_layer_dense_32_32_16_loss: 0.0628 - output_layer_dense_32_32_32_loss: 0.0588 - output_layer_dense_32_32_64_loss: 0.0605\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5741 - output_layer_dense_16_256_16_loss: 0.0573 - output_layer_dense_16_256_32_loss: 0.0565 - output_layer_dense_16_256_64_loss: 0.0532 - output_layer_dense_16_256_128_loss: 0.0634 - output_layer_dense_16_256_196_loss: 0.0571 - output_layer_dense_16_256_256_loss: 0.0557 - output_layer_dense_32_16_16_loss: 0.0545 - output_layer_dense_32_32_16_loss: 0.0612 - output_layer_dense_32_32_32_loss: 0.0560 - output_layer_dense_32_32_64_loss: 0.0592\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5448 - output_layer_dense_16_256_16_loss: 0.0563 - output_layer_dense_16_256_32_loss: 0.0535 - output_layer_dense_16_256_64_loss: 0.0527 - output_layer_dense_16_256_128_loss: 0.0595 - output_layer_dense_16_256_196_loss: 0.0517 - output_layer_dense_16_256_256_loss: 0.0506 - output_layer_dense_32_16_16_loss: 0.0522 - output_layer_dense_32_32_16_loss: 0.0594 - output_layer_dense_32_32_32_loss: 0.0532 - output_layer_dense_32_32_64_loss: 0.0558\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5314 - output_layer_dense_16_256_16_loss: 0.0565 - output_layer_dense_16_256_32_loss: 0.0521 - output_layer_dense_16_256_64_loss: 0.0513 - output_layer_dense_16_256_128_loss: 0.0564 - output_layer_dense_16_256_196_loss: 0.0496 - output_layer_dense_16_256_256_loss: 0.0479 - output_layer_dense_32_16_16_loss: 0.0509 - output_layer_dense_32_32_16_loss: 0.0612 - output_layer_dense_32_32_32_loss: 0.0528 - output_layer_dense_32_32_64_loss: 0.0526\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4949 - output_layer_dense_16_256_16_loss: 0.0499 - output_layer_dense_16_256_32_loss: 0.0492 - output_layer_dense_16_256_64_loss: 0.0465 - output_layer_dense_16_256_128_loss: 0.0553 - output_layer_dense_16_256_196_loss: 0.0480 - output_layer_dense_16_256_256_loss: 0.0472 - output_layer_dense_32_16_16_loss: 0.0474 - output_layer_dense_32_32_16_loss: 0.0550 - output_layer_dense_32_32_32_loss: 0.0477 - output_layer_dense_32_32_64_loss: 0.0486\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4811845123767853 , TEST :  0.547502338886261\n",
      "output_layer_dense_16_256_16_loss  :  0.04907290264964104 , TEST :  0.05202162265777588\n",
      "output_layer_dense_16_256_32_loss  :  0.04761505872011185 , TEST :  0.05478836968541145\n",
      "output_layer_dense_16_256_64_loss  :  0.0457475371658802 , TEST :  0.05367974564433098\n",
      "output_layer_dense_16_256_128_loss  :  0.05227769538760185 , TEST :  0.0629083588719368\n",
      "output_layer_dense_16_256_196_loss  :  0.046332985162734985 , TEST :  0.05364943668246269\n",
      "output_layer_dense_16_256_256_loss  :  0.045827530324459076 , TEST :  0.05892384052276611\n",
      "output_layer_dense_32_16_16_loss  :  0.04810895398259163 , TEST :  0.05098330229520798\n",
      "output_layer_dense_32_32_16_loss  :  0.05222559720277786 , TEST :  0.052636269479990005\n",
      "output_layer_dense_32_32_32_loss  :  0.046105559915304184 , TEST :  0.05258426442742348\n",
      "output_layer_dense_32_32_64_loss  :  0.04787059128284454 , TEST :  0.05532703176140785\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 2.0045 - output_layer_dense_32_32_128_loss: 0.1703 - output_layer_dense_32_32_196_loss: 0.1665 - output_layer_dense_32_32_256_loss: 0.3034 - output_layer_dense_32_64_16_loss: 0.1364 - output_layer_dense_32_64_32_loss: 0.1787 - output_layer_dense_32_64_64_loss: 0.2467 - output_layer_dense_32_64_128_loss: 0.2225 - output_layer_dense_32_64_196_loss: 0.2546 - output_layer_dense_32_64_256_loss: 0.1347 - output_layer_dense_32_128_16_loss: 0.1907\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 1.0747 - output_layer_dense_32_32_128_loss: 0.1162 - output_layer_dense_32_32_196_loss: 0.0957 - output_layer_dense_32_32_256_loss: 0.1339 - output_layer_dense_32_64_16_loss: 0.0867 - output_layer_dense_32_64_32_loss: 0.1046 - output_layer_dense_32_64_64_loss: 0.1189 - output_layer_dense_32_64_128_loss: 0.1120 - output_layer_dense_32_64_196_loss: 0.1176 - output_layer_dense_32_64_256_loss: 0.0914 - output_layer_dense_32_128_16_loss: 0.0977\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7815 - output_layer_dense_32_32_128_loss: 0.0859 - output_layer_dense_32_32_196_loss: 0.0675 - output_layer_dense_32_32_256_loss: 0.0903 - output_layer_dense_32_64_16_loss: 0.0696 - output_layer_dense_32_64_32_loss: 0.0802 - output_layer_dense_32_64_64_loss: 0.0893 - output_layer_dense_32_64_128_loss: 0.0761 - output_layer_dense_32_64_196_loss: 0.0813 - output_layer_dense_32_64_256_loss: 0.0688 - output_layer_dense_32_128_16_loss: 0.0725\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7233 - output_layer_dense_32_32_128_loss: 0.0785 - output_layer_dense_32_32_196_loss: 0.0609 - output_layer_dense_32_32_256_loss: 0.0787 - output_layer_dense_32_64_16_loss: 0.0677 - output_layer_dense_32_64_32_loss: 0.0779 - output_layer_dense_32_64_64_loss: 0.0812 - output_layer_dense_32_64_128_loss: 0.0731 - output_layer_dense_32_64_196_loss: 0.0720 - output_layer_dense_32_64_256_loss: 0.0658 - output_layer_dense_32_128_16_loss: 0.0676\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6230 - output_layer_dense_32_32_128_loss: 0.0661 - output_layer_dense_32_32_196_loss: 0.0550 - output_layer_dense_32_32_256_loss: 0.0654 - output_layer_dense_32_64_16_loss: 0.0598 - output_layer_dense_32_64_32_loss: 0.0681 - output_layer_dense_32_64_64_loss: 0.0728 - output_layer_dense_32_64_128_loss: 0.0625 - output_layer_dense_32_64_196_loss: 0.0604 - output_layer_dense_32_64_256_loss: 0.0552 - output_layer_dense_32_128_16_loss: 0.0575\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5623 - output_layer_dense_32_32_128_loss: 0.0584 - output_layer_dense_32_32_196_loss: 0.0512 - output_layer_dense_32_32_256_loss: 0.0585 - output_layer_dense_32_64_16_loss: 0.0559 - output_layer_dense_32_64_32_loss: 0.0600 - output_layer_dense_32_64_64_loss: 0.0671 - output_layer_dense_32_64_128_loss: 0.0545 - output_layer_dense_32_64_196_loss: 0.0542 - output_layer_dense_32_64_256_loss: 0.0512 - output_layer_dense_32_128_16_loss: 0.0512\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5839 - output_layer_dense_32_32_128_loss: 0.0608 - output_layer_dense_32_32_196_loss: 0.0539 - output_layer_dense_32_32_256_loss: 0.0626 - output_layer_dense_32_64_16_loss: 0.0575 - output_layer_dense_32_64_32_loss: 0.0620 - output_layer_dense_32_64_64_loss: 0.0684 - output_layer_dense_32_64_128_loss: 0.0582 - output_layer_dense_32_64_196_loss: 0.0542 - output_layer_dense_32_64_256_loss: 0.0532 - output_layer_dense_32_128_16_loss: 0.0532\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5263 - output_layer_dense_32_32_128_loss: 0.0539 - output_layer_dense_32_32_196_loss: 0.0491 - output_layer_dense_32_32_256_loss: 0.0571 - output_layer_dense_32_64_16_loss: 0.0532 - output_layer_dense_32_64_32_loss: 0.0556 - output_layer_dense_32_64_64_loss: 0.0625 - output_layer_dense_32_64_128_loss: 0.0531 - output_layer_dense_32_64_196_loss: 0.0492 - output_layer_dense_32_64_256_loss: 0.0458 - output_layer_dense_32_128_16_loss: 0.0467\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5485 - output_layer_dense_32_32_128_loss: 0.0566 - output_layer_dense_32_32_196_loss: 0.0514 - output_layer_dense_32_32_256_loss: 0.0582 - output_layer_dense_32_64_16_loss: 0.0567 - output_layer_dense_32_64_32_loss: 0.0578 - output_layer_dense_32_64_64_loss: 0.0629 - output_layer_dense_32_64_128_loss: 0.0546 - output_layer_dense_32_64_196_loss: 0.0519 - output_layer_dense_32_64_256_loss: 0.0492 - output_layer_dense_32_128_16_loss: 0.0493\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4609 - output_layer_dense_32_32_128_loss: 0.0477 - output_layer_dense_32_32_196_loss: 0.0426 - output_layer_dense_32_32_256_loss: 0.0487 - output_layer_dense_32_64_16_loss: 0.0478 - output_layer_dense_32_64_32_loss: 0.0484 - output_layer_dense_32_64_64_loss: 0.0540 - output_layer_dense_32_64_128_loss: 0.0447 - output_layer_dense_32_64_196_loss: 0.0435 - output_layer_dense_32_64_256_loss: 0.0422 - output_layer_dense_32_128_16_loss: 0.0413\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4619881808757782 , TEST :  0.5362822413444519\n",
      "output_layer_dense_32_32_128_loss  :  0.04654741659760475 , TEST :  0.055026695132255554\n",
      "output_layer_dense_32_32_196_loss  :  0.04381820932030678 , TEST :  0.04968879371881485\n",
      "output_layer_dense_32_32_256_loss  :  0.04826335608959198 , TEST :  0.0567677803337574\n",
      "output_layer_dense_32_64_16_loss  :  0.04922983795404434 , TEST :  0.055474985390901566\n",
      "output_layer_dense_32_64_32_loss  :  0.04840901866555214 , TEST :  0.05655737966299057\n",
      "output_layer_dense_32_64_64_loss  :  0.053330712020397186 , TEST :  0.06090082600712776\n",
      "output_layer_dense_32_64_128_loss  :  0.04501723870635033 , TEST :  0.049646247178316116\n",
      "output_layer_dense_32_64_196_loss  :  0.04534746706485748 , TEST :  0.050325214862823486\n",
      "output_layer_dense_32_64_256_loss  :  0.04177970811724663 , TEST :  0.05184580758213997\n",
      "output_layer_dense_32_128_16_loss  :  0.040245171636343 , TEST :  0.05004854127764702\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 4ms/step - loss: 1.6513 - output_layer_dense_32_128_32_loss: 0.2133 - output_layer_dense_32_128_64_loss: 0.1460 - output_layer_dense_32_128_128_loss: 0.2078 - output_layer_dense_32_128_196_loss: 0.1837 - output_layer_dense_32_128_256_loss: 0.1495 - output_layer_dense_32_196_16_loss: 0.0922 - output_layer_dense_32_196_32_loss: 0.2060 - output_layer_dense_32_196_64_loss: 0.1595 - output_layer_dense_32_196_128_loss: 0.1550 - output_layer_dense_32_196_196_loss: 0.1382\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8614 - output_layer_dense_32_128_32_loss: 0.1026 - output_layer_dense_32_128_64_loss: 0.0872 - output_layer_dense_32_128_128_loss: 0.0896 - output_layer_dense_32_128_196_loss: 0.0874 - output_layer_dense_32_128_256_loss: 0.0703 - output_layer_dense_32_196_16_loss: 0.0660 - output_layer_dense_32_196_32_loss: 0.1012 - output_layer_dense_32_196_64_loss: 0.0928 - output_layer_dense_32_196_128_loss: 0.0889 - output_layer_dense_32_196_196_loss: 0.0753\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7130 - output_layer_dense_32_128_32_loss: 0.0794 - output_layer_dense_32_128_64_loss: 0.0735 - output_layer_dense_32_128_128_loss: 0.0690 - output_layer_dense_32_128_196_loss: 0.0721 - output_layer_dense_32_128_256_loss: 0.0581 - output_layer_dense_32_196_16_loss: 0.0587 - output_layer_dense_32_196_32_loss: 0.0841 - output_layer_dense_32_196_64_loss: 0.0784 - output_layer_dense_32_196_128_loss: 0.0736 - output_layer_dense_32_196_196_loss: 0.0662\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6252 - output_layer_dense_32_128_32_loss: 0.0669 - output_layer_dense_32_128_64_loss: 0.0658 - output_layer_dense_32_128_128_loss: 0.0605 - output_layer_dense_32_128_196_loss: 0.0598 - output_layer_dense_32_128_256_loss: 0.0501 - output_layer_dense_32_196_16_loss: 0.0537 - output_layer_dense_32_196_32_loss: 0.0713 - output_layer_dense_32_196_64_loss: 0.0724 - output_layer_dense_32_196_128_loss: 0.0658 - output_layer_dense_32_196_196_loss: 0.0588\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5677 - output_layer_dense_32_128_32_loss: 0.0610 - output_layer_dense_32_128_64_loss: 0.0599 - output_layer_dense_32_128_128_loss: 0.0552 - output_layer_dense_32_128_196_loss: 0.0532 - output_layer_dense_32_128_256_loss: 0.0484 - output_layer_dense_32_196_16_loss: 0.0493 - output_layer_dense_32_196_32_loss: 0.0634 - output_layer_dense_32_196_64_loss: 0.0658 - output_layer_dense_32_196_128_loss: 0.0588 - output_layer_dense_32_196_196_loss: 0.0528\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5381 - output_layer_dense_32_128_32_loss: 0.0589 - output_layer_dense_32_128_64_loss: 0.0573 - output_layer_dense_32_128_128_loss: 0.0515 - output_layer_dense_32_128_196_loss: 0.0518 - output_layer_dense_32_128_256_loss: 0.0439 - output_layer_dense_32_196_16_loss: 0.0469 - output_layer_dense_32_196_32_loss: 0.0610 - output_layer_dense_32_196_64_loss: 0.0615 - output_layer_dense_32_196_128_loss: 0.0539 - output_layer_dense_32_196_196_loss: 0.0514\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5243 - output_layer_dense_32_128_32_loss: 0.0552 - output_layer_dense_32_128_64_loss: 0.0570 - output_layer_dense_32_128_128_loss: 0.0508 - output_layer_dense_32_128_196_loss: 0.0512 - output_layer_dense_32_128_256_loss: 0.0448 - output_layer_dense_32_196_16_loss: 0.0466 - output_layer_dense_32_196_32_loss: 0.0578 - output_layer_dense_32_196_64_loss: 0.0583 - output_layer_dense_32_196_128_loss: 0.0569 - output_layer_dense_32_196_196_loss: 0.0457\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4462 - output_layer_dense_32_128_32_loss: 0.0481 - output_layer_dense_32_128_64_loss: 0.0477 - output_layer_dense_32_128_128_loss: 0.0422 - output_layer_dense_32_128_196_loss: 0.0442 - output_layer_dense_32_128_256_loss: 0.0389 - output_layer_dense_32_196_16_loss: 0.0394 - output_layer_dense_32_196_32_loss: 0.0483 - output_layer_dense_32_196_64_loss: 0.0496 - output_layer_dense_32_196_128_loss: 0.0465 - output_layer_dense_32_196_196_loss: 0.0411\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4400 - output_layer_dense_32_128_32_loss: 0.0474 - output_layer_dense_32_128_64_loss: 0.0463 - output_layer_dense_32_128_128_loss: 0.0417 - output_layer_dense_32_128_196_loss: 0.0432 - output_layer_dense_32_128_256_loss: 0.0397 - output_layer_dense_32_196_16_loss: 0.0401 - output_layer_dense_32_196_32_loss: 0.0488 - output_layer_dense_32_196_64_loss: 0.0492 - output_layer_dense_32_196_128_loss: 0.0434 - output_layer_dense_32_196_196_loss: 0.0402\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4512 - output_layer_dense_32_128_32_loss: 0.0495 - output_layer_dense_32_128_64_loss: 0.0491 - output_layer_dense_32_128_128_loss: 0.0424 - output_layer_dense_32_128_196_loss: 0.0457 - output_layer_dense_32_128_256_loss: 0.0395 - output_layer_dense_32_196_16_loss: 0.0429 - output_layer_dense_32_196_32_loss: 0.0494 - output_layer_dense_32_196_64_loss: 0.0501 - output_layer_dense_32_196_128_loss: 0.0436 - output_layer_dense_32_196_196_loss: 0.0389\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.40661880373954773 , TEST :  0.5020964741706848\n",
      "output_layer_dense_32_128_32_loss  :  0.044999755918979645 , TEST :  0.05249598249793053\n",
      "output_layer_dense_32_128_64_loss  :  0.04388817399740219 , TEST :  0.05203082412481308\n",
      "output_layer_dense_32_128_128_loss  :  0.03802543133497238 , TEST :  0.048492349684238434\n",
      "output_layer_dense_32_128_196_loss  :  0.04012145474553108 , TEST :  0.04870876297354698\n",
      "output_layer_dense_32_128_256_loss  :  0.03699571266770363 , TEST :  0.04848872125148773\n",
      "output_layer_dense_32_196_16_loss  :  0.03682394325733185 , TEST :  0.04546153545379639\n",
      "output_layer_dense_32_196_32_loss  :  0.044521331787109375 , TEST :  0.0543777197599411\n",
      "output_layer_dense_32_196_64_loss  :  0.04799909144639969 , TEST :  0.053021498024463654\n",
      "output_layer_dense_32_196_128_loss  :  0.03864464536309242 , TEST :  0.05174023285508156\n",
      "output_layer_dense_32_196_196_loss  :  0.03459930792450905 , TEST :  0.04727887362241745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 1.7538 - output_layer_dense_32_196_256_loss: 0.1675 - output_layer_dense_32_256_16_loss: 0.1714 - output_layer_dense_32_256_32_loss: 0.2007 - output_layer_dense_32_256_64_loss: 0.1505 - output_layer_dense_32_256_128_loss: 0.1831 - output_layer_dense_32_256_196_loss: 0.1343 - output_layer_dense_32_256_256_loss: 0.0873 - output_layer_dense_64_16_16_loss: 0.2080 - output_layer_dense_64_32_16_loss: 0.2182 - output_layer_dense_64_32_32_loss: 0.2327\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8731 - output_layer_dense_32_196_256_loss: 0.0737 - output_layer_dense_32_256_16_loss: 0.0748 - output_layer_dense_32_256_32_loss: 0.0907 - output_layer_dense_32_256_64_loss: 0.0809 - output_layer_dense_32_256_128_loss: 0.0943 - output_layer_dense_32_256_196_loss: 0.0702 - output_layer_dense_32_256_256_loss: 0.0668 - output_layer_dense_64_16_16_loss: 0.1154 - output_layer_dense_64_32_16_loss: 0.0945 - output_layer_dense_64_32_32_loss: 0.1118\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7551 - output_layer_dense_32_196_256_loss: 0.0668 - output_layer_dense_32_256_16_loss: 0.0672 - output_layer_dense_32_256_32_loss: 0.0744 - output_layer_dense_32_256_64_loss: 0.0691 - output_layer_dense_32_256_128_loss: 0.0786 - output_layer_dense_32_256_196_loss: 0.0619 - output_layer_dense_32_256_256_loss: 0.0624 - output_layer_dense_64_16_16_loss: 0.1013 - output_layer_dense_64_32_16_loss: 0.0823 - output_layer_dense_64_32_32_loss: 0.0909\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7017 - output_layer_dense_32_196_256_loss: 0.0655 - output_layer_dense_32_256_16_loss: 0.0666 - output_layer_dense_32_256_32_loss: 0.0694 - output_layer_dense_32_256_64_loss: 0.0639 - output_layer_dense_32_256_128_loss: 0.0726 - output_layer_dense_32_256_196_loss: 0.0611 - output_layer_dense_32_256_256_loss: 0.0601 - output_layer_dense_64_16_16_loss: 0.0853 - output_layer_dense_64_32_16_loss: 0.0744 - output_layer_dense_64_32_32_loss: 0.0828\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6027 - output_layer_dense_32_196_256_loss: 0.0585 - output_layer_dense_32_256_16_loss: 0.0551 - output_layer_dense_32_256_32_loss: 0.0593 - output_layer_dense_32_256_64_loss: 0.0543 - output_layer_dense_32_256_128_loss: 0.0610 - output_layer_dense_32_256_196_loss: 0.0530 - output_layer_dense_32_256_256_loss: 0.0550 - output_layer_dense_64_16_16_loss: 0.0728 - output_layer_dense_64_32_16_loss: 0.0635 - output_layer_dense_64_32_32_loss: 0.0701\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5780 - output_layer_dense_32_196_256_loss: 0.0532 - output_layer_dense_32_256_16_loss: 0.0546 - output_layer_dense_32_256_32_loss: 0.0580 - output_layer_dense_32_256_64_loss: 0.0524 - output_layer_dense_32_256_128_loss: 0.0586 - output_layer_dense_32_256_196_loss: 0.0519 - output_layer_dense_32_256_256_loss: 0.0506 - output_layer_dense_64_16_16_loss: 0.0703 - output_layer_dense_64_32_16_loss: 0.0609 - output_layer_dense_64_32_32_loss: 0.0673\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5487 - output_layer_dense_32_196_256_loss: 0.0514 - output_layer_dense_32_256_16_loss: 0.0553 - output_layer_dense_32_256_32_loss: 0.0548 - output_layer_dense_32_256_64_loss: 0.0496 - output_layer_dense_32_256_128_loss: 0.0550 - output_layer_dense_32_256_196_loss: 0.0484 - output_layer_dense_32_256_256_loss: 0.0497 - output_layer_dense_64_16_16_loss: 0.0640 - output_layer_dense_64_32_16_loss: 0.0585 - output_layer_dense_64_32_32_loss: 0.0620\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5010 - output_layer_dense_32_196_256_loss: 0.0482 - output_layer_dense_32_256_16_loss: 0.0502 - output_layer_dense_32_256_32_loss: 0.0492 - output_layer_dense_32_256_64_loss: 0.0447 - output_layer_dense_32_256_128_loss: 0.0485 - output_layer_dense_32_256_196_loss: 0.0441 - output_layer_dense_32_256_256_loss: 0.0464 - output_layer_dense_64_16_16_loss: 0.0597 - output_layer_dense_64_32_16_loss: 0.0527 - output_layer_dense_64_32_32_loss: 0.0573\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4561 - output_layer_dense_32_196_256_loss: 0.0435 - output_layer_dense_32_256_16_loss: 0.0459 - output_layer_dense_32_256_32_loss: 0.0451 - output_layer_dense_32_256_64_loss: 0.0415 - output_layer_dense_32_256_128_loss: 0.0449 - output_layer_dense_32_256_196_loss: 0.0406 - output_layer_dense_32_256_256_loss: 0.0394 - output_layer_dense_64_16_16_loss: 0.0549 - output_layer_dense_64_32_16_loss: 0.0494 - output_layer_dense_64_32_32_loss: 0.0509\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4166 - output_layer_dense_32_196_256_loss: 0.0389 - output_layer_dense_32_256_16_loss: 0.0431 - output_layer_dense_32_256_32_loss: 0.0412 - output_layer_dense_32_256_64_loss: 0.0373 - output_layer_dense_32_256_128_loss: 0.0416 - output_layer_dense_32_256_196_loss: 0.0368 - output_layer_dense_32_256_256_loss: 0.0366 - output_layer_dense_64_16_16_loss: 0.0508 - output_layer_dense_64_32_16_loss: 0.0444 - output_layer_dense_64_32_32_loss: 0.0461\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4189283847808838 , TEST :  0.5149016976356506\n",
      "output_layer_dense_32_196_256_loss  :  0.038336414843797684 , TEST :  0.0482715405523777\n",
      "output_layer_dense_32_256_16_loss  :  0.04318028688430786 , TEST :  0.05079242214560509\n",
      "output_layer_dense_32_256_32_loss  :  0.0407860204577446 , TEST :  0.050079237669706345\n",
      "output_layer_dense_32_256_64_loss  :  0.03750448673963547 , TEST :  0.05012613534927368\n",
      "output_layer_dense_32_256_128_loss  :  0.038892194628715515 , TEST :  0.05081164091825485\n",
      "output_layer_dense_32_256_196_loss  :  0.03664165735244751 , TEST :  0.049947917461395264\n",
      "output_layer_dense_32_256_256_loss  :  0.04095374047756195 , TEST :  0.05276333540678024\n",
      "output_layer_dense_64_16_16_loss  :  0.050565846264362335 , TEST :  0.05691969022154808\n",
      "output_layer_dense_64_32_16_loss  :  0.04525136947631836 , TEST :  0.05322994664311409\n",
      "output_layer_dense_64_32_32_loss  :  0.04681635648012161 , TEST :  0.05195986106991768\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 1.8505 - output_layer_dense_64_64_16_loss: 0.1461 - output_layer_dense_64_64_32_loss: 0.1623 - output_layer_dense_64_64_64_loss: 0.1996 - output_layer_dense_64_64_128_loss: 0.2996 - output_layer_dense_64_64_196_loss: 0.1100 - output_layer_dense_64_64_256_loss: 0.1771 - output_layer_dense_64_128_16_loss: 0.1615 - output_layer_dense_64_128_32_loss: 0.2867 - output_layer_dense_64_128_64_loss: 0.1096 - output_layer_dense_64_128_128_loss: 0.1979\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8860 - output_layer_dense_64_64_16_loss: 0.0738 - output_layer_dense_64_64_32_loss: 0.0974 - output_layer_dense_64_64_64_loss: 0.0852 - output_layer_dense_64_64_128_loss: 0.1004 - output_layer_dense_64_64_196_loss: 0.0752 - output_layer_dense_64_64_256_loss: 0.0952 - output_layer_dense_64_128_16_loss: 0.0828 - output_layer_dense_64_128_32_loss: 0.1062 - output_layer_dense_64_128_64_loss: 0.0732 - output_layer_dense_64_128_128_loss: 0.0966\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6657 - output_layer_dense_64_64_16_loss: 0.0591 - output_layer_dense_64_64_32_loss: 0.0711 - output_layer_dense_64_64_64_loss: 0.0686 - output_layer_dense_64_64_128_loss: 0.0705 - output_layer_dense_64_64_196_loss: 0.0628 - output_layer_dense_64_64_256_loss: 0.0673 - output_layer_dense_64_128_16_loss: 0.0633 - output_layer_dense_64_128_32_loss: 0.0729 - output_layer_dense_64_128_64_loss: 0.0659 - output_layer_dense_64_128_128_loss: 0.0643\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6145 - output_layer_dense_64_64_16_loss: 0.0563 - output_layer_dense_64_64_32_loss: 0.0638 - output_layer_dense_64_64_64_loss: 0.0650 - output_layer_dense_64_64_128_loss: 0.0663 - output_layer_dense_64_64_196_loss: 0.0585 - output_layer_dense_64_64_256_loss: 0.0621 - output_layer_dense_64_128_16_loss: 0.0593 - output_layer_dense_64_128_32_loss: 0.0628 - output_layer_dense_64_128_64_loss: 0.0584 - output_layer_dense_64_128_128_loss: 0.0622\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5184 - output_layer_dense_64_64_16_loss: 0.0487 - output_layer_dense_64_64_32_loss: 0.0525 - output_layer_dense_64_64_64_loss: 0.0530 - output_layer_dense_64_64_128_loss: 0.0546 - output_layer_dense_64_64_196_loss: 0.0485 - output_layer_dense_64_64_256_loss: 0.0524 - output_layer_dense_64_128_16_loss: 0.0537 - output_layer_dense_64_128_32_loss: 0.0529 - output_layer_dense_64_128_64_loss: 0.0512 - output_layer_dense_64_128_128_loss: 0.0510\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5349 - output_layer_dense_64_64_16_loss: 0.0515 - output_layer_dense_64_64_32_loss: 0.0546 - output_layer_dense_64_64_64_loss: 0.0562 - output_layer_dense_64_64_128_loss: 0.0548 - output_layer_dense_64_64_196_loss: 0.0503 - output_layer_dense_64_64_256_loss: 0.0518 - output_layer_dense_64_128_16_loss: 0.0525 - output_layer_dense_64_128_32_loss: 0.0545 - output_layer_dense_64_128_64_loss: 0.0535 - output_layer_dense_64_128_128_loss: 0.0552\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5003 - output_layer_dense_64_64_16_loss: 0.0491 - output_layer_dense_64_64_32_loss: 0.0484 - output_layer_dense_64_64_64_loss: 0.0512 - output_layer_dense_64_64_128_loss: 0.0523 - output_layer_dense_64_64_196_loss: 0.0488 - output_layer_dense_64_64_256_loss: 0.0480 - output_layer_dense_64_128_16_loss: 0.0513 - output_layer_dense_64_128_32_loss: 0.0511 - output_layer_dense_64_128_64_loss: 0.0486 - output_layer_dense_64_128_128_loss: 0.0515\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4588 - output_layer_dense_64_64_16_loss: 0.0443 - output_layer_dense_64_64_32_loss: 0.0467 - output_layer_dense_64_64_64_loss: 0.0470 - output_layer_dense_64_64_128_loss: 0.0453 - output_layer_dense_64_64_196_loss: 0.0452 - output_layer_dense_64_64_256_loss: 0.0454 - output_layer_dense_64_128_16_loss: 0.0478 - output_layer_dense_64_128_32_loss: 0.0453 - output_layer_dense_64_128_64_loss: 0.0441 - output_layer_dense_64_128_128_loss: 0.0477\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4132 - output_layer_dense_64_64_16_loss: 0.0404 - output_layer_dense_64_64_32_loss: 0.0438 - output_layer_dense_64_64_64_loss: 0.0425 - output_layer_dense_64_64_128_loss: 0.0405 - output_layer_dense_64_64_196_loss: 0.0414 - output_layer_dense_64_64_256_loss: 0.0400 - output_layer_dense_64_128_16_loss: 0.0434 - output_layer_dense_64_128_32_loss: 0.0407 - output_layer_dense_64_128_64_loss: 0.0391 - output_layer_dense_64_128_128_loss: 0.0415\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3872 - output_layer_dense_64_64_16_loss: 0.0402 - output_layer_dense_64_64_32_loss: 0.0413 - output_layer_dense_64_64_64_loss: 0.0381 - output_layer_dense_64_64_128_loss: 0.0397 - output_layer_dense_64_64_196_loss: 0.0384 - output_layer_dense_64_64_256_loss: 0.0379 - output_layer_dense_64_128_16_loss: 0.0422 - output_layer_dense_64_128_32_loss: 0.0373 - output_layer_dense_64_128_64_loss: 0.0354 - output_layer_dense_64_128_128_loss: 0.0367\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3824821710586548 , TEST :  0.4835933744907379\n",
      "output_layer_dense_64_64_16_loss  :  0.03874542936682701 , TEST :  0.04693657159805298\n",
      "output_layer_dense_64_64_32_loss  :  0.03998637944459915 , TEST :  0.051265884190797806\n",
      "output_layer_dense_64_64_64_loss  :  0.0393412783741951 , TEST :  0.047923047095537186\n",
      "output_layer_dense_64_64_128_loss  :  0.03778120502829552 , TEST :  0.05059802904725075\n",
      "output_layer_dense_64_64_196_loss  :  0.0376470610499382 , TEST :  0.050405777990818024\n",
      "output_layer_dense_64_64_256_loss  :  0.039093099534511566 , TEST :  0.04891142249107361\n",
      "output_layer_dense_64_128_16_loss  :  0.040749043226242065 , TEST :  0.049312375485897064\n",
      "output_layer_dense_64_128_32_loss  :  0.037321433424949646 , TEST :  0.04417867958545685\n",
      "output_layer_dense_64_128_64_loss  :  0.03446793556213379 , TEST :  0.049419742077589035\n",
      "output_layer_dense_64_128_128_loss  :  0.0373493991792202 , TEST :  0.04464191943407059\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 2.0129 - output_layer_dense_64_128_196_loss: 0.1775 - output_layer_dense_64_128_256_loss: 0.1132 - output_layer_dense_64_196_16_loss: 0.3150 - output_layer_dense_64_196_32_loss: 0.1963 - output_layer_dense_64_196_64_loss: 0.2185 - output_layer_dense_64_196_128_loss: 0.2613 - output_layer_dense_64_196_196_loss: 0.2281 - output_layer_dense_64_196_256_loss: 0.1721 - output_layer_dense_64_256_16_loss: 0.1318 - output_layer_dense_64_256_32_loss: 0.1990\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.9102 - output_layer_dense_64_128_196_loss: 0.0957 - output_layer_dense_64_128_256_loss: 0.0706 - output_layer_dense_64_196_16_loss: 0.0994 - output_layer_dense_64_196_32_loss: 0.0825 - output_layer_dense_64_196_64_loss: 0.1018 - output_layer_dense_64_196_128_loss: 0.1033 - output_layer_dense_64_196_196_loss: 0.1079 - output_layer_dense_64_196_256_loss: 0.0903 - output_layer_dense_64_256_16_loss: 0.0696 - output_layer_dense_64_256_32_loss: 0.0890\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6871 - output_layer_dense_64_128_196_loss: 0.0663 - output_layer_dense_64_128_256_loss: 0.0573 - output_layer_dense_64_196_16_loss: 0.0858 - output_layer_dense_64_196_32_loss: 0.0683 - output_layer_dense_64_196_64_loss: 0.0697 - output_layer_dense_64_196_128_loss: 0.0691 - output_layer_dense_64_196_196_loss: 0.0758 - output_layer_dense_64_196_256_loss: 0.0695 - output_layer_dense_64_256_16_loss: 0.0602 - output_layer_dense_64_256_32_loss: 0.0650\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5819 - output_layer_dense_64_128_196_loss: 0.0569 - output_layer_dense_64_128_256_loss: 0.0501 - output_layer_dense_64_196_16_loss: 0.0685 - output_layer_dense_64_196_32_loss: 0.0600 - output_layer_dense_64_196_64_loss: 0.0583 - output_layer_dense_64_196_128_loss: 0.0543 - output_layer_dense_64_196_196_loss: 0.0606 - output_layer_dense_64_196_256_loss: 0.0585 - output_layer_dense_64_256_16_loss: 0.0557 - output_layer_dense_64_256_32_loss: 0.0590\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5246 - output_layer_dense_64_128_196_loss: 0.0497 - output_layer_dense_64_128_256_loss: 0.0449 - output_layer_dense_64_196_16_loss: 0.0635 - output_layer_dense_64_196_32_loss: 0.0539 - output_layer_dense_64_196_64_loss: 0.0536 - output_layer_dense_64_196_128_loss: 0.0487 - output_layer_dense_64_196_196_loss: 0.0541 - output_layer_dense_64_196_256_loss: 0.0533 - output_layer_dense_64_256_16_loss: 0.0501 - output_layer_dense_64_256_32_loss: 0.0530\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4600 - output_layer_dense_64_128_196_loss: 0.0434 - output_layer_dense_64_128_256_loss: 0.0393 - output_layer_dense_64_196_16_loss: 0.0569 - output_layer_dense_64_196_32_loss: 0.0492 - output_layer_dense_64_196_64_loss: 0.0456 - output_layer_dense_64_196_128_loss: 0.0423 - output_layer_dense_64_196_196_loss: 0.0453 - output_layer_dense_64_196_256_loss: 0.0460 - output_layer_dense_64_256_16_loss: 0.0438 - output_layer_dense_64_256_32_loss: 0.0482\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4514 - output_layer_dense_64_128_196_loss: 0.0433 - output_layer_dense_64_128_256_loss: 0.0401 - output_layer_dense_64_196_16_loss: 0.0535 - output_layer_dense_64_196_32_loss: 0.0495 - output_layer_dense_64_196_64_loss: 0.0445 - output_layer_dense_64_196_128_loss: 0.0425 - output_layer_dense_64_196_196_loss: 0.0430 - output_layer_dense_64_196_256_loss: 0.0453 - output_layer_dense_64_256_16_loss: 0.0430 - output_layer_dense_64_256_32_loss: 0.0468\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4093 - output_layer_dense_64_128_196_loss: 0.0387 - output_layer_dense_64_128_256_loss: 0.0361 - output_layer_dense_64_196_16_loss: 0.0508 - output_layer_dense_64_196_32_loss: 0.0449 - output_layer_dense_64_196_64_loss: 0.0409 - output_layer_dense_64_196_128_loss: 0.0383 - output_layer_dense_64_196_196_loss: 0.0391 - output_layer_dense_64_196_256_loss: 0.0382 - output_layer_dense_64_256_16_loss: 0.0386 - output_layer_dense_64_256_32_loss: 0.0438\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4184 - output_layer_dense_64_128_196_loss: 0.0412 - output_layer_dense_64_128_256_loss: 0.0367 - output_layer_dense_64_196_16_loss: 0.0513 - output_layer_dense_64_196_32_loss: 0.0461 - output_layer_dense_64_196_64_loss: 0.0410 - output_layer_dense_64_196_128_loss: 0.0388 - output_layer_dense_64_196_196_loss: 0.0401 - output_layer_dense_64_196_256_loss: 0.0388 - output_layer_dense_64_256_16_loss: 0.0401 - output_layer_dense_64_256_32_loss: 0.0443\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3712 - output_layer_dense_64_128_196_loss: 0.0361 - output_layer_dense_64_128_256_loss: 0.0341 - output_layer_dense_64_196_16_loss: 0.0447 - output_layer_dense_64_196_32_loss: 0.0397 - output_layer_dense_64_196_64_loss: 0.0368 - output_layer_dense_64_196_128_loss: 0.0355 - output_layer_dense_64_196_196_loss: 0.0356 - output_layer_dense_64_196_256_loss: 0.0347 - output_layer_dense_64_256_16_loss: 0.0348 - output_layer_dense_64_256_32_loss: 0.0391\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3532230257987976 , TEST :  0.4685649275779724\n",
      "output_layer_dense_64_128_196_loss  :  0.03276011347770691 , TEST :  0.04665340110659599\n",
      "output_layer_dense_64_128_256_loss  :  0.0346832349896431 , TEST :  0.048896074295043945\n",
      "output_layer_dense_64_196_16_loss  :  0.044677965342998505 , TEST :  0.050136033445596695\n",
      "output_layer_dense_64_196_32_loss  :  0.03845130279660225 , TEST :  0.04750746488571167\n",
      "output_layer_dense_64_196_64_loss  :  0.034162651747465134 , TEST :  0.04743272811174393\n",
      "output_layer_dense_64_196_128_loss  :  0.03249301016330719 , TEST :  0.04496851935982704\n",
      "output_layer_dense_64_196_196_loss  :  0.03249625489115715 , TEST :  0.04605681449174881\n",
      "output_layer_dense_64_196_256_loss  :  0.03193824365735054 , TEST :  0.044936228543519974\n",
      "output_layer_dense_64_256_16_loss  :  0.032486993819475174 , TEST :  0.04321091249585152\n",
      "output_layer_dense_64_256_32_loss  :  0.03907323256134987 , TEST :  0.04876670241355896\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 1.7438 - output_layer_dense_64_256_64_loss: 0.2766 - output_layer_dense_64_256_128_loss: 0.1616 - output_layer_dense_64_256_196_loss: 0.1835 - output_layer_dense_64_256_256_loss: 0.1852 - output_layer_dense_128_16_16_loss: 0.1117 - output_layer_dense_128_32_16_loss: 0.1164 - output_layer_dense_128_32_32_loss: 0.2281 - output_layer_dense_128_64_16_loss: 0.1905 - output_layer_dense_128_64_32_loss: 0.1643 - output_layer_dense_128_64_64_loss: 0.1259\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8655 - output_layer_dense_64_256_64_loss: 0.1069 - output_layer_dense_64_256_128_loss: 0.0916 - output_layer_dense_64_256_196_loss: 0.0954 - output_layer_dense_64_256_256_loss: 0.0864 - output_layer_dense_128_16_16_loss: 0.0736 - output_layer_dense_128_32_16_loss: 0.0785 - output_layer_dense_128_32_32_loss: 0.0959 - output_layer_dense_128_64_16_loss: 0.0878 - output_layer_dense_128_64_32_loss: 0.0797 - output_layer_dense_128_64_64_loss: 0.0698\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7398 - output_layer_dense_64_256_64_loss: 0.0707 - output_layer_dense_64_256_128_loss: 0.0696 - output_layer_dense_64_256_196_loss: 0.0836 - output_layer_dense_64_256_256_loss: 0.0836 - output_layer_dense_128_16_16_loss: 0.0749 - output_layer_dense_128_32_16_loss: 0.0693 - output_layer_dense_128_32_32_loss: 0.0817 - output_layer_dense_128_64_16_loss: 0.0678 - output_layer_dense_128_64_32_loss: 0.0693 - output_layer_dense_128_64_64_loss: 0.0694\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5925 - output_layer_dense_64_256_64_loss: 0.0605 - output_layer_dense_64_256_128_loss: 0.0532 - output_layer_dense_64_256_196_loss: 0.0652 - output_layer_dense_64_256_256_loss: 0.0592 - output_layer_dense_128_16_16_loss: 0.0587 - output_layer_dense_128_32_16_loss: 0.0582 - output_layer_dense_128_32_32_loss: 0.0656 - output_layer_dense_128_64_16_loss: 0.0545 - output_layer_dense_128_64_32_loss: 0.0577 - output_layer_dense_128_64_64_loss: 0.0597\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5502 - output_layer_dense_64_256_64_loss: 0.0556 - output_layer_dense_64_256_128_loss: 0.0517 - output_layer_dense_64_256_196_loss: 0.0605 - output_layer_dense_64_256_256_loss: 0.0558 - output_layer_dense_128_16_16_loss: 0.0554 - output_layer_dense_128_32_16_loss: 0.0527 - output_layer_dense_128_32_32_loss: 0.0615 - output_layer_dense_128_64_16_loss: 0.0513 - output_layer_dense_128_64_32_loss: 0.0532 - output_layer_dense_128_64_64_loss: 0.0524\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4870 - output_layer_dense_64_256_64_loss: 0.0495 - output_layer_dense_64_256_128_loss: 0.0449 - output_layer_dense_64_256_196_loss: 0.0523 - output_layer_dense_64_256_256_loss: 0.0480 - output_layer_dense_128_16_16_loss: 0.0491 - output_layer_dense_128_32_16_loss: 0.0462 - output_layer_dense_128_32_32_loss: 0.0568 - output_layer_dense_128_64_16_loss: 0.0453 - output_layer_dense_128_64_32_loss: 0.0471 - output_layer_dense_128_64_64_loss: 0.0479\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4357 - output_layer_dense_64_256_64_loss: 0.0428 - output_layer_dense_64_256_128_loss: 0.0420 - output_layer_dense_64_256_196_loss: 0.0457 - output_layer_dense_64_256_256_loss: 0.0430 - output_layer_dense_128_16_16_loss: 0.0441 - output_layer_dense_128_32_16_loss: 0.0419 - output_layer_dense_128_32_32_loss: 0.0488 - output_layer_dense_128_64_16_loss: 0.0417 - output_layer_dense_128_64_32_loss: 0.0425 - output_layer_dense_128_64_64_loss: 0.0432\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4175 - output_layer_dense_64_256_64_loss: 0.0412 - output_layer_dense_64_256_128_loss: 0.0401 - output_layer_dense_64_256_196_loss: 0.0424 - output_layer_dense_64_256_256_loss: 0.0420 - output_layer_dense_128_16_16_loss: 0.0426 - output_layer_dense_128_32_16_loss: 0.0406 - output_layer_dense_128_32_32_loss: 0.0471 - output_layer_dense_128_64_16_loss: 0.0397 - output_layer_dense_128_64_32_loss: 0.0406 - output_layer_dense_128_64_64_loss: 0.0413\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3958 - output_layer_dense_64_256_64_loss: 0.0387 - output_layer_dense_64_256_128_loss: 0.0373 - output_layer_dense_64_256_196_loss: 0.0398 - output_layer_dense_64_256_256_loss: 0.0387 - output_layer_dense_128_16_16_loss: 0.0410 - output_layer_dense_128_32_16_loss: 0.0384 - output_layer_dense_128_32_32_loss: 0.0450 - output_layer_dense_128_64_16_loss: 0.0386 - output_layer_dense_128_64_32_loss: 0.0380 - output_layer_dense_128_64_64_loss: 0.0402\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3918 - output_layer_dense_64_256_64_loss: 0.0391 - output_layer_dense_64_256_128_loss: 0.0369 - output_layer_dense_64_256_196_loss: 0.0389 - output_layer_dense_64_256_256_loss: 0.0381 - output_layer_dense_128_16_16_loss: 0.0406 - output_layer_dense_128_32_16_loss: 0.0379 - output_layer_dense_128_32_32_loss: 0.0435 - output_layer_dense_128_64_16_loss: 0.0384 - output_layer_dense_128_64_32_loss: 0.0379 - output_layer_dense_128_64_64_loss: 0.0405\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.34651312232017517 , TEST :  0.47366634011268616\n",
      "output_layer_dense_64_256_64_loss  :  0.038184672594070435 , TEST :  0.05141528323292732\n",
      "output_layer_dense_64_256_128_loss  :  0.03139301761984825 , TEST :  0.0489344447851181\n",
      "output_layer_dense_64_256_196_loss  :  0.03373643010854721 , TEST :  0.04745854437351227\n",
      "output_layer_dense_64_256_256_loss  :  0.031714797019958496 , TEST :  0.04850337281823158\n",
      "output_layer_dense_128_16_16_loss  :  0.0370025560259819 , TEST :  0.04865502566099167\n",
      "output_layer_dense_128_32_16_loss  :  0.034207478165626526 , TEST :  0.0445869080722332\n",
      "output_layer_dense_128_32_32_loss  :  0.03958302363753319 , TEST :  0.04808393493294716\n",
      "output_layer_dense_128_64_16_loss  :  0.033641278743743896 , TEST :  0.04664139822125435\n",
      "output_layer_dense_128_64_32_loss  :  0.03258528187870979 , TEST :  0.04446748271584511\n",
      "output_layer_dense_128_64_64_loss  :  0.0344645231962204 , TEST :  0.04491998255252838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 1.8971 - output_layer_dense_128_128_16_loss: 0.1397 - output_layer_dense_128_128_32_loss: 0.2379 - output_layer_dense_128_128_64_loss: 0.2365 - output_layer_dense_128_128_128_loss: 0.1404 - output_layer_dense_128_128_196_loss: 0.1353 - output_layer_dense_128_128_256_loss: 0.1519 - output_layer_dense_128_196_16_loss: 0.2254 - output_layer_dense_128_196_32_loss: 0.2158 - output_layer_dense_128_196_64_loss: 0.1602 - output_layer_dense_128_196_128_loss: 0.2540\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.8740 - output_layer_dense_128_128_16_loss: 0.0763 - output_layer_dense_128_128_32_loss: 0.0983 - output_layer_dense_128_128_64_loss: 0.0906 - output_layer_dense_128_128_128_loss: 0.0728 - output_layer_dense_128_128_196_loss: 0.0762 - output_layer_dense_128_128_256_loss: 0.0818 - output_layer_dense_128_196_16_loss: 0.0911 - output_layer_dense_128_196_32_loss: 0.0917 - output_layer_dense_128_196_64_loss: 0.0917 - output_layer_dense_128_196_128_loss: 0.1035\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6378 - output_layer_dense_128_128_16_loss: 0.0568 - output_layer_dense_128_128_32_loss: 0.0724 - output_layer_dense_128_128_64_loss: 0.0699 - output_layer_dense_128_128_128_loss: 0.0562 - output_layer_dense_128_128_196_loss: 0.0566 - output_layer_dense_128_128_256_loss: 0.0650 - output_layer_dense_128_196_16_loss: 0.0650 - output_layer_dense_128_196_32_loss: 0.0674 - output_layer_dense_128_196_64_loss: 0.0626 - output_layer_dense_128_196_128_loss: 0.0660\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5678 - output_layer_dense_128_128_16_loss: 0.0515 - output_layer_dense_128_128_32_loss: 0.0648 - output_layer_dense_128_128_64_loss: 0.0636 - output_layer_dense_128_128_128_loss: 0.0517 - output_layer_dense_128_128_196_loss: 0.0524 - output_layer_dense_128_128_256_loss: 0.0518 - output_layer_dense_128_196_16_loss: 0.0560 - output_layer_dense_128_196_32_loss: 0.0613 - output_layer_dense_128_196_64_loss: 0.0556 - output_layer_dense_128_196_128_loss: 0.0592\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4758 - output_layer_dense_128_128_16_loss: 0.0431 - output_layer_dense_128_128_32_loss: 0.0540 - output_layer_dense_128_128_64_loss: 0.0515 - output_layer_dense_128_128_128_loss: 0.0444 - output_layer_dense_128_128_196_loss: 0.0440 - output_layer_dense_128_128_256_loss: 0.0439 - output_layer_dense_128_196_16_loss: 0.0464 - output_layer_dense_128_196_32_loss: 0.0510 - output_layer_dense_128_196_64_loss: 0.0472 - output_layer_dense_128_196_128_loss: 0.0503\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4537 - output_layer_dense_128_128_16_loss: 0.0432 - output_layer_dense_128_128_32_loss: 0.0519 - output_layer_dense_128_128_64_loss: 0.0485 - output_layer_dense_128_128_128_loss: 0.0426 - output_layer_dense_128_128_196_loss: 0.0429 - output_layer_dense_128_128_256_loss: 0.0410 - output_layer_dense_128_196_16_loss: 0.0434 - output_layer_dense_128_196_32_loss: 0.0484 - output_layer_dense_128_196_64_loss: 0.0450 - output_layer_dense_128_196_128_loss: 0.0469\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4060 - output_layer_dense_128_128_16_loss: 0.0386 - output_layer_dense_128_128_32_loss: 0.0465 - output_layer_dense_128_128_64_loss: 0.0430 - output_layer_dense_128_128_128_loss: 0.0380 - output_layer_dense_128_128_196_loss: 0.0388 - output_layer_dense_128_128_256_loss: 0.0370 - output_layer_dense_128_196_16_loss: 0.0393 - output_layer_dense_128_196_32_loss: 0.0432 - output_layer_dense_128_196_64_loss: 0.0395 - output_layer_dense_128_196_128_loss: 0.0422\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4208 - output_layer_dense_128_128_16_loss: 0.0411 - output_layer_dense_128_128_32_loss: 0.0452 - output_layer_dense_128_128_64_loss: 0.0436 - output_layer_dense_128_128_128_loss: 0.0401 - output_layer_dense_128_128_196_loss: 0.0416 - output_layer_dense_128_128_256_loss: 0.0374 - output_layer_dense_128_196_16_loss: 0.0435 - output_layer_dense_128_196_32_loss: 0.0453 - output_layer_dense_128_196_64_loss: 0.0406 - output_layer_dense_128_196_128_loss: 0.0425\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4028 - output_layer_dense_128_128_16_loss: 0.0392 - output_layer_dense_128_128_32_loss: 0.0444 - output_layer_dense_128_128_64_loss: 0.0404 - output_layer_dense_128_128_128_loss: 0.0413 - output_layer_dense_128_128_196_loss: 0.0359 - output_layer_dense_128_128_256_loss: 0.0392 - output_layer_dense_128_196_16_loss: 0.0388 - output_layer_dense_128_196_32_loss: 0.0437 - output_layer_dense_128_196_64_loss: 0.0415 - output_layer_dense_128_196_128_loss: 0.0384\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3696 - output_layer_dense_128_128_16_loss: 0.0361 - output_layer_dense_128_128_32_loss: 0.0417 - output_layer_dense_128_128_64_loss: 0.0377 - output_layer_dense_128_128_128_loss: 0.0353 - output_layer_dense_128_128_196_loss: 0.0343 - output_layer_dense_128_128_256_loss: 0.0332 - output_layer_dense_128_196_16_loss: 0.0365 - output_layer_dense_128_196_32_loss: 0.0413 - output_layer_dense_128_196_64_loss: 0.0355 - output_layer_dense_128_196_128_loss: 0.0379\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3380661904811859 , TEST :  0.4625638425350189\n",
      "output_layer_dense_128_128_16_loss  :  0.034131404012441635 , TEST :  0.04758075997233391\n",
      "output_layer_dense_128_128_32_loss  :  0.03751549497246742 , TEST :  0.047773126512765884\n",
      "output_layer_dense_128_128_64_loss  :  0.034965064376592636 , TEST :  0.047611482441425323\n",
      "output_layer_dense_128_128_128_loss  :  0.030130697414278984 , TEST :  0.04300394654273987\n",
      "output_layer_dense_128_128_196_loss  :  0.032075025141239166 , TEST :  0.0483773835003376\n",
      "output_layer_dense_128_128_256_loss  :  0.027211304754018784 , TEST :  0.04224119707942009\n",
      "output_layer_dense_128_196_16_loss  :  0.034806594252586365 , TEST :  0.04522523656487465\n",
      "output_layer_dense_128_196_32_loss  :  0.03761420026421547 , TEST :  0.04630104452371597\n",
      "output_layer_dense_128_196_64_loss  :  0.03486218303442001 , TEST :  0.04748019203543663\n",
      "output_layer_dense_128_196_128_loss  :  0.03475420922040939 , TEST :  0.0469694547355175\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 1.6559 - output_layer_dense_128_196_196_loss: 0.2276 - output_layer_dense_128_196_256_loss: 0.1412 - output_layer_dense_128_256_16_loss: 0.1275 - output_layer_dense_128_256_32_loss: 0.1778 - output_layer_dense_128_256_64_loss: 0.2093 - output_layer_dense_128_256_128_loss: 0.1220 - output_layer_dense_128_256_196_loss: 0.1466 - output_layer_dense_128_256_256_loss: 0.1307 - output_layer_dense_196_16_16_loss: 0.1435 - output_layer_dense_196_32_16_loss: 0.2297\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7154 - output_layer_dense_128_196_196_loss: 0.0750 - output_layer_dense_128_196_256_loss: 0.0690 - output_layer_dense_128_256_16_loss: 0.0606 - output_layer_dense_128_256_32_loss: 0.0732 - output_layer_dense_128_256_64_loss: 0.0718 - output_layer_dense_128_256_128_loss: 0.0647 - output_layer_dense_128_256_196_loss: 0.0706 - output_layer_dense_128_256_256_loss: 0.0635 - output_layer_dense_196_16_16_loss: 0.0669 - output_layer_dense_196_32_16_loss: 0.1002\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5615 - output_layer_dense_128_196_196_loss: 0.0594 - output_layer_dense_128_196_256_loss: 0.0519 - output_layer_dense_128_256_16_loss: 0.0477 - output_layer_dense_128_256_32_loss: 0.0578 - output_layer_dense_128_256_64_loss: 0.0568 - output_layer_dense_128_256_128_loss: 0.0528 - output_layer_dense_128_256_196_loss: 0.0594 - output_layer_dense_128_256_256_loss: 0.0497 - output_layer_dense_196_16_16_loss: 0.0550 - output_layer_dense_196_32_16_loss: 0.0711\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4774 - output_layer_dense_128_196_196_loss: 0.0508 - output_layer_dense_128_196_256_loss: 0.0471 - output_layer_dense_128_256_16_loss: 0.0406 - output_layer_dense_128_256_32_loss: 0.0483 - output_layer_dense_128_256_64_loss: 0.0470 - output_layer_dense_128_256_128_loss: 0.0438 - output_layer_dense_128_256_196_loss: 0.0452 - output_layer_dense_128_256_256_loss: 0.0439 - output_layer_dense_196_16_16_loss: 0.0484 - output_layer_dense_196_32_16_loss: 0.0624\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4510 - output_layer_dense_128_196_196_loss: 0.0493 - output_layer_dense_128_196_256_loss: 0.0429 - output_layer_dense_128_256_16_loss: 0.0409 - output_layer_dense_128_256_32_loss: 0.0460 - output_layer_dense_128_256_64_loss: 0.0449 - output_layer_dense_128_256_128_loss: 0.0401 - output_layer_dense_128_256_196_loss: 0.0419 - output_layer_dense_128_256_256_loss: 0.0426 - output_layer_dense_196_16_16_loss: 0.0466 - output_layer_dense_196_32_16_loss: 0.0557\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4189 - output_layer_dense_128_196_196_loss: 0.0453 - output_layer_dense_128_196_256_loss: 0.0379 - output_layer_dense_128_256_16_loss: 0.0372 - output_layer_dense_128_256_32_loss: 0.0424 - output_layer_dense_128_256_64_loss: 0.0406 - output_layer_dense_128_256_128_loss: 0.0387 - output_layer_dense_128_256_196_loss: 0.0392 - output_layer_dense_128_256_256_loss: 0.0391 - output_layer_dense_196_16_16_loss: 0.0437 - output_layer_dense_196_32_16_loss: 0.0548\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4497 - output_layer_dense_128_196_196_loss: 0.0489 - output_layer_dense_128_196_256_loss: 0.0403 - output_layer_dense_128_256_16_loss: 0.0427 - output_layer_dense_128_256_32_loss: 0.0519 - output_layer_dense_128_256_64_loss: 0.0436 - output_layer_dense_128_256_128_loss: 0.0412 - output_layer_dense_128_256_196_loss: 0.0409 - output_layer_dense_128_256_256_loss: 0.0398 - output_layer_dense_196_16_16_loss: 0.0488 - output_layer_dense_196_32_16_loss: 0.0516\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3968 - output_layer_dense_128_196_196_loss: 0.0404 - output_layer_dense_128_196_256_loss: 0.0372 - output_layer_dense_128_256_16_loss: 0.0359 - output_layer_dense_128_256_32_loss: 0.0436 - output_layer_dense_128_256_64_loss: 0.0413 - output_layer_dense_128_256_128_loss: 0.0365 - output_layer_dense_128_256_196_loss: 0.0364 - output_layer_dense_128_256_256_loss: 0.0360 - output_layer_dense_196_16_16_loss: 0.0429 - output_layer_dense_196_32_16_loss: 0.0466\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3830 - output_layer_dense_128_196_196_loss: 0.0393 - output_layer_dense_128_196_256_loss: 0.0364 - output_layer_dense_128_256_16_loss: 0.0342 - output_layer_dense_128_256_32_loss: 0.0401 - output_layer_dense_128_256_64_loss: 0.0381 - output_layer_dense_128_256_128_loss: 0.0354 - output_layer_dense_128_256_196_loss: 0.0369 - output_layer_dense_128_256_256_loss: 0.0334 - output_layer_dense_196_16_16_loss: 0.0434 - output_layer_dense_196_32_16_loss: 0.0457\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3615 - output_layer_dense_128_196_196_loss: 0.0366 - output_layer_dense_128_196_256_loss: 0.0341 - output_layer_dense_128_256_16_loss: 0.0352 - output_layer_dense_128_256_32_loss: 0.0395 - output_layer_dense_128_256_64_loss: 0.0362 - output_layer_dense_128_256_128_loss: 0.0308 - output_layer_dense_128_256_196_loss: 0.0306 - output_layer_dense_128_256_256_loss: 0.0315 - output_layer_dense_196_16_16_loss: 0.0415 - output_layer_dense_196_32_16_loss: 0.0457\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3153823912143707 , TEST :  0.44615742564201355\n",
      "output_layer_dense_128_196_196_loss  :  0.03284333273768425 , TEST :  0.04595412686467171\n",
      "output_layer_dense_128_196_256_loss  :  0.02822653017938137 , TEST :  0.044492773711681366\n",
      "output_layer_dense_128_256_16_loss  :  0.031432345509529114 , TEST :  0.041853226721286774\n",
      "output_layer_dense_128_256_32_loss  :  0.03443623706698418 , TEST :  0.04398351162672043\n",
      "output_layer_dense_128_256_64_loss  :  0.02931872196495533 , TEST :  0.04574117809534073\n",
      "output_layer_dense_128_256_128_loss  :  0.02660238742828369 , TEST :  0.04253145679831505\n",
      "output_layer_dense_128_256_196_loss  :  0.029457764700055122 , TEST :  0.046081699430942535\n",
      "output_layer_dense_128_256_256_loss  :  0.026423195376992226 , TEST :  0.0444013848900795\n",
      "output_layer_dense_196_16_16_loss  :  0.03523987904191017 , TEST :  0.04349614679813385\n",
      "output_layer_dense_196_32_16_loss  :  0.04140206053853035 , TEST :  0.0476219542324543\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 1.4280 - output_layer_dense_196_32_32_loss: 0.1754 - output_layer_dense_196_64_16_loss: 0.1356 - output_layer_dense_196_64_32_loss: 0.1316 - output_layer_dense_196_64_64_loss: 0.1285 - output_layer_dense_196_128_16_loss: 0.1109 - output_layer_dense_196_128_32_loss: 0.1108 - output_layer_dense_196_128_64_loss: 0.2094 - output_layer_dense_196_128_128_loss: 0.1298 - output_layer_dense_196_196_16_loss: 0.1374 - output_layer_dense_196_196_32_loss: 0.1587\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7305 - output_layer_dense_196_32_32_loss: 0.0858 - output_layer_dense_196_64_16_loss: 0.0729 - output_layer_dense_196_64_32_loss: 0.0687 - output_layer_dense_196_64_64_loss: 0.0673 - output_layer_dense_196_128_16_loss: 0.0751 - output_layer_dense_196_128_32_loss: 0.0733 - output_layer_dense_196_128_64_loss: 0.0814 - output_layer_dense_196_128_128_loss: 0.0680 - output_layer_dense_196_196_16_loss: 0.0657 - output_layer_dense_196_196_32_loss: 0.0723\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5944 - output_layer_dense_196_32_32_loss: 0.0676 - output_layer_dense_196_64_16_loss: 0.0625 - output_layer_dense_196_64_32_loss: 0.0567 - output_layer_dense_196_64_64_loss: 0.0577 - output_layer_dense_196_128_16_loss: 0.0604 - output_layer_dense_196_128_32_loss: 0.0560 - output_layer_dense_196_128_64_loss: 0.0600 - output_layer_dense_196_128_128_loss: 0.0598 - output_layer_dense_196_196_16_loss: 0.0558 - output_layer_dense_196_196_32_loss: 0.0578\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4787 - output_layer_dense_196_32_32_loss: 0.0526 - output_layer_dense_196_64_16_loss: 0.0500 - output_layer_dense_196_64_32_loss: 0.0452 - output_layer_dense_196_64_64_loss: 0.0481 - output_layer_dense_196_128_16_loss: 0.0489 - output_layer_dense_196_128_32_loss: 0.0477 - output_layer_dense_196_128_64_loss: 0.0477 - output_layer_dense_196_128_128_loss: 0.0463 - output_layer_dense_196_196_16_loss: 0.0441 - output_layer_dense_196_196_32_loss: 0.0481\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4704 - output_layer_dense_196_32_32_loss: 0.0522 - output_layer_dense_196_64_16_loss: 0.0494 - output_layer_dense_196_64_32_loss: 0.0447 - output_layer_dense_196_64_64_loss: 0.0466 - output_layer_dense_196_128_16_loss: 0.0494 - output_layer_dense_196_128_32_loss: 0.0466 - output_layer_dense_196_128_64_loss: 0.0477 - output_layer_dense_196_128_128_loss: 0.0456 - output_layer_dense_196_196_16_loss: 0.0432 - output_layer_dense_196_196_32_loss: 0.0449\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3945 - output_layer_dense_196_32_32_loss: 0.0415 - output_layer_dense_196_64_16_loss: 0.0412 - output_layer_dense_196_64_32_loss: 0.0384 - output_layer_dense_196_64_64_loss: 0.0412 - output_layer_dense_196_128_16_loss: 0.0399 - output_layer_dense_196_128_32_loss: 0.0405 - output_layer_dense_196_128_64_loss: 0.0388 - output_layer_dense_196_128_128_loss: 0.0384 - output_layer_dense_196_196_16_loss: 0.0361 - output_layer_dense_196_196_32_loss: 0.0384\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4177 - output_layer_dense_196_32_32_loss: 0.0445 - output_layer_dense_196_64_16_loss: 0.0442 - output_layer_dense_196_64_32_loss: 0.0403 - output_layer_dense_196_64_64_loss: 0.0436 - output_layer_dense_196_128_16_loss: 0.0421 - output_layer_dense_196_128_32_loss: 0.0421 - output_layer_dense_196_128_64_loss: 0.0417 - output_layer_dense_196_128_128_loss: 0.0404 - output_layer_dense_196_196_16_loss: 0.0403 - output_layer_dense_196_196_32_loss: 0.0382\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3689 - output_layer_dense_196_32_32_loss: 0.0399 - output_layer_dense_196_64_16_loss: 0.0387 - output_layer_dense_196_64_32_loss: 0.0364 - output_layer_dense_196_64_64_loss: 0.0378 - output_layer_dense_196_128_16_loss: 0.0377 - output_layer_dense_196_128_32_loss: 0.0359 - output_layer_dense_196_128_64_loss: 0.0375 - output_layer_dense_196_128_128_loss: 0.0363 - output_layer_dense_196_196_16_loss: 0.0357 - output_layer_dense_196_196_32_loss: 0.0329\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4046 - output_layer_dense_196_32_32_loss: 0.0427 - output_layer_dense_196_64_16_loss: 0.0434 - output_layer_dense_196_64_32_loss: 0.0382 - output_layer_dense_196_64_64_loss: 0.0417 - output_layer_dense_196_128_16_loss: 0.0425 - output_layer_dense_196_128_32_loss: 0.0395 - output_layer_dense_196_128_64_loss: 0.0402 - output_layer_dense_196_128_128_loss: 0.0427 - output_layer_dense_196_196_16_loss: 0.0373 - output_layer_dense_196_196_32_loss: 0.0363\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3283 - output_layer_dense_196_32_32_loss: 0.0347 - output_layer_dense_196_64_16_loss: 0.0356 - output_layer_dense_196_64_32_loss: 0.0310 - output_layer_dense_196_64_64_loss: 0.0332 - output_layer_dense_196_128_16_loss: 0.0351 - output_layer_dense_196_128_32_loss: 0.0314 - output_layer_dense_196_128_64_loss: 0.0329 - output_layer_dense_196_128_128_loss: 0.0331 - output_layer_dense_196_196_16_loss: 0.0308 - output_layer_dense_196_196_32_loss: 0.0305\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.32356157898902893 , TEST :  0.4532594084739685\n",
      "output_layer_dense_196_32_32_loss  :  0.03435273841023445 , TEST :  0.0457865409553051\n",
      "output_layer_dense_196_64_16_loss  :  0.03256920352578163 , TEST :  0.042453791946172714\n",
      "output_layer_dense_196_64_32_loss  :  0.03165220469236374 , TEST :  0.04560796543955803\n",
      "output_layer_dense_196_64_64_loss  :  0.03219079226255417 , TEST :  0.043554071336984634\n",
      "output_layer_dense_196_128_16_loss  :  0.035482119768857956 , TEST :  0.04847521334886551\n",
      "output_layer_dense_196_128_32_loss  :  0.03105178289115429 , TEST :  0.04645233228802681\n",
      "output_layer_dense_196_128_64_loss  :  0.030909951776266098 , TEST :  0.04335595667362213\n",
      "output_layer_dense_196_128_128_loss  :  0.03876218572258949 , TEST :  0.05177119001746178\n",
      "output_layer_dense_196_196_16_loss  :  0.029683060944080353 , TEST :  0.04278557002544403\n",
      "output_layer_dense_196_196_32_loss  :  0.026907533407211304 , TEST :  0.04301679506897926\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 1.6773 - output_layer_dense_196_196_64_loss: 0.1577 - output_layer_dense_196_196_128_loss: 0.2507 - output_layer_dense_196_196_196_loss: 0.1445 - output_layer_dense_196_196_256_loss: 0.1716 - output_layer_dense_196_256_16_loss: 0.1980 - output_layer_dense_196_256_32_loss: 0.1943 - output_layer_dense_196_256_64_loss: 0.1277 - output_layer_dense_196_256_128_loss: 0.1601 - output_layer_dense_196_256_196_loss: 0.1192 - output_layer_dense_196_256_256_loss: 0.1534\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7379 - output_layer_dense_196_196_64_loss: 0.0703 - output_layer_dense_196_196_128_loss: 0.0897 - output_layer_dense_196_196_196_loss: 0.0698 - output_layer_dense_196_196_256_loss: 0.0708 - output_layer_dense_196_256_16_loss: 0.0777 - output_layer_dense_196_256_32_loss: 0.0762 - output_layer_dense_196_256_64_loss: 0.0650 - output_layer_dense_196_256_128_loss: 0.0849 - output_layer_dense_196_256_196_loss: 0.0655 - output_layer_dense_196_256_256_loss: 0.0681\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5928 - output_layer_dense_196_196_64_loss: 0.0564 - output_layer_dense_196_196_128_loss: 0.0682 - output_layer_dense_196_196_196_loss: 0.0527 - output_layer_dense_196_196_256_loss: 0.0626 - output_layer_dense_196_256_16_loss: 0.0673 - output_layer_dense_196_256_32_loss: 0.0637 - output_layer_dense_196_256_64_loss: 0.0521 - output_layer_dense_196_256_128_loss: 0.0582 - output_layer_dense_196_256_196_loss: 0.0546 - output_layer_dense_196_256_256_loss: 0.0569\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4774 - output_layer_dense_196_196_64_loss: 0.0462 - output_layer_dense_196_196_128_loss: 0.0533 - output_layer_dense_196_196_196_loss: 0.0438 - output_layer_dense_196_196_256_loss: 0.0493 - output_layer_dense_196_256_16_loss: 0.0534 - output_layer_dense_196_256_32_loss: 0.0530 - output_layer_dense_196_256_64_loss: 0.0433 - output_layer_dense_196_256_128_loss: 0.0481 - output_layer_dense_196_256_196_loss: 0.0437 - output_layer_dense_196_256_256_loss: 0.0433\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4246 - output_layer_dense_196_196_64_loss: 0.0434 - output_layer_dense_196_196_128_loss: 0.0485 - output_layer_dense_196_196_196_loss: 0.0383 - output_layer_dense_196_196_256_loss: 0.0441 - output_layer_dense_196_256_16_loss: 0.0447 - output_layer_dense_196_256_32_loss: 0.0451 - output_layer_dense_196_256_64_loss: 0.0384 - output_layer_dense_196_256_128_loss: 0.0422 - output_layer_dense_196_256_196_loss: 0.0384 - output_layer_dense_196_256_256_loss: 0.0417\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3832 - output_layer_dense_196_196_64_loss: 0.0388 - output_layer_dense_196_196_128_loss: 0.0420 - output_layer_dense_196_196_196_loss: 0.0351 - output_layer_dense_196_196_256_loss: 0.0392 - output_layer_dense_196_256_16_loss: 0.0396 - output_layer_dense_196_256_32_loss: 0.0433 - output_layer_dense_196_256_64_loss: 0.0352 - output_layer_dense_196_256_128_loss: 0.0386 - output_layer_dense_196_256_196_loss: 0.0356 - output_layer_dense_196_256_256_loss: 0.0358\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3620 - output_layer_dense_196_196_64_loss: 0.0363 - output_layer_dense_196_196_128_loss: 0.0373 - output_layer_dense_196_196_196_loss: 0.0332 - output_layer_dense_196_196_256_loss: 0.0401 - output_layer_dense_196_256_16_loss: 0.0363 - output_layer_dense_196_256_32_loss: 0.0419 - output_layer_dense_196_256_64_loss: 0.0335 - output_layer_dense_196_256_128_loss: 0.0375 - output_layer_dense_196_256_196_loss: 0.0329 - output_layer_dense_196_256_256_loss: 0.0330\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3308 - output_layer_dense_196_196_64_loss: 0.0341 - output_layer_dense_196_196_128_loss: 0.0353 - output_layer_dense_196_196_196_loss: 0.0310 - output_layer_dense_196_196_256_loss: 0.0357 - output_layer_dense_196_256_16_loss: 0.0349 - output_layer_dense_196_256_32_loss: 0.0361 - output_layer_dense_196_256_64_loss: 0.0306 - output_layer_dense_196_256_128_loss: 0.0339 - output_layer_dense_196_256_196_loss: 0.0293 - output_layer_dense_196_256_256_loss: 0.0299\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3356 - output_layer_dense_196_196_64_loss: 0.0347 - output_layer_dense_196_196_128_loss: 0.0347 - output_layer_dense_196_196_196_loss: 0.0313 - output_layer_dense_196_196_256_loss: 0.0365 - output_layer_dense_196_256_16_loss: 0.0351 - output_layer_dense_196_256_32_loss: 0.0366 - output_layer_dense_196_256_64_loss: 0.0295 - output_layer_dense_196_256_128_loss: 0.0351 - output_layer_dense_196_256_196_loss: 0.0320 - output_layer_dense_196_256_256_loss: 0.0301\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3116 - output_layer_dense_196_196_64_loss: 0.0328 - output_layer_dense_196_196_128_loss: 0.0323 - output_layer_dense_196_196_196_loss: 0.0285 - output_layer_dense_196_196_256_loss: 0.0329 - output_layer_dense_196_256_16_loss: 0.0326 - output_layer_dense_196_256_32_loss: 0.0345 - output_layer_dense_196_256_64_loss: 0.0271 - output_layer_dense_196_256_128_loss: 0.0326 - output_layer_dense_196_256_196_loss: 0.0300 - output_layer_dense_196_256_256_loss: 0.0283\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3176022469997406 , TEST :  0.45928698778152466\n",
      "output_layer_dense_196_196_64_loss  :  0.03231947496533394 , TEST :  0.046657975763082504\n",
      "output_layer_dense_196_196_128_loss  :  0.03041069768369198 , TEST :  0.04485555738210678\n",
      "output_layer_dense_196_196_196_loss  :  0.033842284232378006 , TEST :  0.04863782972097397\n",
      "output_layer_dense_196_196_256_loss  :  0.02892419882118702 , TEST :  0.04227440059185028\n",
      "output_layer_dense_196_256_16_loss  :  0.03185722231864929 , TEST :  0.04698823392391205\n",
      "output_layer_dense_196_256_32_loss  :  0.032115012407302856 , TEST :  0.042804352939128876\n",
      "output_layer_dense_196_256_64_loss  :  0.027621479704976082 , TEST :  0.043863482773303986\n",
      "output_layer_dense_196_256_128_loss  :  0.03528190031647682 , TEST :  0.04696359112858772\n",
      "output_layer_dense_196_256_196_loss  :  0.03402616083621979 , TEST :  0.04802102968096733\n",
      "output_layer_dense_196_256_256_loss  :  0.03120383620262146 , TEST :  0.04822051525115967\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 5ms/step - loss: 1.5643 - output_layer_dense_256_16_16_loss: 0.1828 - output_layer_dense_256_32_16_loss: 0.2013 - output_layer_dense_256_32_32_loss: 0.1782 - output_layer_dense_256_64_16_loss: 0.1950 - output_layer_dense_256_64_32_loss: 0.0942 - output_layer_dense_256_64_64_loss: 0.1615 - output_layer_dense_256_128_16_loss: 0.1274 - output_layer_dense_256_128_32_loss: 0.1182 - output_layer_dense_256_128_64_loss: 0.1850 - output_layer_dense_256_128_128_loss: 0.1207\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7335 - output_layer_dense_256_16_16_loss: 0.0846 - output_layer_dense_256_32_16_loss: 0.0821 - output_layer_dense_256_32_32_loss: 0.0749 - output_layer_dense_256_64_16_loss: 0.0808 - output_layer_dense_256_64_32_loss: 0.0588 - output_layer_dense_256_64_64_loss: 0.0771 - output_layer_dense_256_128_16_loss: 0.0642 - output_layer_dense_256_128_32_loss: 0.0638 - output_layer_dense_256_128_64_loss: 0.0827 - output_layer_dense_256_128_128_loss: 0.0646\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5804 - output_layer_dense_256_16_16_loss: 0.0665 - output_layer_dense_256_32_16_loss: 0.0607 - output_layer_dense_256_32_32_loss: 0.0586 - output_layer_dense_256_64_16_loss: 0.0644 - output_layer_dense_256_64_32_loss: 0.0500 - output_layer_dense_256_64_64_loss: 0.0589 - output_layer_dense_256_128_16_loss: 0.0567 - output_layer_dense_256_128_32_loss: 0.0509 - output_layer_dense_256_128_64_loss: 0.0619 - output_layer_dense_256_128_128_loss: 0.0519\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5237 - output_layer_dense_256_16_16_loss: 0.0587 - output_layer_dense_256_32_16_loss: 0.0558 - output_layer_dense_256_32_32_loss: 0.0538 - output_layer_dense_256_64_16_loss: 0.0588 - output_layer_dense_256_64_32_loss: 0.0468 - output_layer_dense_256_64_64_loss: 0.0541 - output_layer_dense_256_128_16_loss: 0.0498 - output_layer_dense_256_128_32_loss: 0.0467 - output_layer_dense_256_128_64_loss: 0.0524 - output_layer_dense_256_128_128_loss: 0.0468\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4725 - output_layer_dense_256_16_16_loss: 0.0514 - output_layer_dense_256_32_16_loss: 0.0504 - output_layer_dense_256_32_32_loss: 0.0497 - output_layer_dense_256_64_16_loss: 0.0496 - output_layer_dense_256_64_32_loss: 0.0431 - output_layer_dense_256_64_64_loss: 0.0486 - output_layer_dense_256_128_16_loss: 0.0447 - output_layer_dense_256_128_32_loss: 0.0433 - output_layer_dense_256_128_64_loss: 0.0476 - output_layer_dense_256_128_128_loss: 0.0442\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4339 - output_layer_dense_256_16_16_loss: 0.0487 - output_layer_dense_256_32_16_loss: 0.0466 - output_layer_dense_256_32_32_loss: 0.0470 - output_layer_dense_256_64_16_loss: 0.0481 - output_layer_dense_256_64_32_loss: 0.0391 - output_layer_dense_256_64_64_loss: 0.0453 - output_layer_dense_256_128_16_loss: 0.0399 - output_layer_dense_256_128_32_loss: 0.0380 - output_layer_dense_256_128_64_loss: 0.0422 - output_layer_dense_256_128_128_loss: 0.0389\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3921 - output_layer_dense_256_16_16_loss: 0.0442 - output_layer_dense_256_32_16_loss: 0.0423 - output_layer_dense_256_32_32_loss: 0.0428 - output_layer_dense_256_64_16_loss: 0.0438 - output_layer_dense_256_64_32_loss: 0.0355 - output_layer_dense_256_64_64_loss: 0.0415 - output_layer_dense_256_128_16_loss: 0.0365 - output_layer_dense_256_128_32_loss: 0.0351 - output_layer_dense_256_128_64_loss: 0.0368 - output_layer_dense_256_128_128_loss: 0.0337\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3678 - output_layer_dense_256_16_16_loss: 0.0418 - output_layer_dense_256_32_16_loss: 0.0397 - output_layer_dense_256_32_32_loss: 0.0388 - output_layer_dense_256_64_16_loss: 0.0398 - output_layer_dense_256_64_32_loss: 0.0336 - output_layer_dense_256_64_64_loss: 0.0380 - output_layer_dense_256_128_16_loss: 0.0355 - output_layer_dense_256_128_32_loss: 0.0325 - output_layer_dense_256_128_64_loss: 0.0352 - output_layer_dense_256_128_128_loss: 0.0329\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3560 - output_layer_dense_256_16_16_loss: 0.0401 - output_layer_dense_256_32_16_loss: 0.0383 - output_layer_dense_256_32_32_loss: 0.0377 - output_layer_dense_256_64_16_loss: 0.0387 - output_layer_dense_256_64_32_loss: 0.0339 - output_layer_dense_256_64_64_loss: 0.0377 - output_layer_dense_256_128_16_loss: 0.0321 - output_layer_dense_256_128_32_loss: 0.0336 - output_layer_dense_256_128_64_loss: 0.0307 - output_layer_dense_256_128_128_loss: 0.0334\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3545 - output_layer_dense_256_16_16_loss: 0.0400 - output_layer_dense_256_32_16_loss: 0.0373 - output_layer_dense_256_32_32_loss: 0.0372 - output_layer_dense_256_64_16_loss: 0.0373 - output_layer_dense_256_64_32_loss: 0.0325 - output_layer_dense_256_64_64_loss: 0.0370 - output_layer_dense_256_128_16_loss: 0.0305 - output_layer_dense_256_128_32_loss: 0.0331 - output_layer_dense_256_128_64_loss: 0.0315 - output_layer_dense_256_128_128_loss: 0.0381\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.31344497203826904 , TEST :  0.43364420533180237\n",
      "output_layer_dense_256_16_16_loss  :  0.03661911189556122 , TEST :  0.04395588859915733\n",
      "output_layer_dense_256_32_16_loss  :  0.03435276448726654 , TEST :  0.04503606632351875\n",
      "output_layer_dense_256_32_32_loss  :  0.03341418504714966 , TEST :  0.04528430849313736\n",
      "output_layer_dense_256_64_16_loss  :  0.0345260351896286 , TEST :  0.04318155720829964\n",
      "output_layer_dense_256_64_32_loss  :  0.029372837394475937 , TEST :  0.04261355102062225\n",
      "output_layer_dense_256_64_64_loss  :  0.032586608082056046 , TEST :  0.04383254423737526\n",
      "output_layer_dense_256_128_16_loss  :  0.02864544838666916 , TEST :  0.04196344316005707\n",
      "output_layer_dense_256_128_32_loss  :  0.02893843874335289 , TEST :  0.042248956859111786\n",
      "output_layer_dense_256_128_64_loss  :  0.027733253315091133 , TEST :  0.044270846992731094\n",
      "output_layer_dense_256_128_128_loss  :  0.02725631557404995 , TEST :  0.04125702753663063\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 4ms/step - loss: 1.3231 - output_layer_dense_256_196_16_loss: 0.1570 - output_layer_dense_256_196_32_loss: 0.0843 - output_layer_dense_256_196_64_loss: 0.1199 - output_layer_dense_256_196_128_loss: 0.1355 - output_layer_dense_256_196_196_loss: 0.1217 - output_layer_dense_256_256_16_loss: 0.1341 - output_layer_dense_256_256_32_loss: 0.1300 - output_layer_dense_256_256_64_loss: 0.1441 - output_layer_dense_256_256_128_loss: 0.1597 - output_layer_dense_256_256_196_loss: 0.1368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7075 - output_layer_dense_256_196_16_loss: 0.0721 - output_layer_dense_256_196_32_loss: 0.0617 - output_layer_dense_256_196_64_loss: 0.0634 - output_layer_dense_256_196_128_loss: 0.0642 - output_layer_dense_256_196_196_loss: 0.0744 - output_layer_dense_256_256_16_loss: 0.0702 - output_layer_dense_256_256_32_loss: 0.0680 - output_layer_dense_256_256_64_loss: 0.0758 - output_layer_dense_256_256_128_loss: 0.0810 - output_layer_dense_256_256_196_loss: 0.0767\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.5168 - output_layer_dense_256_196_16_loss: 0.0523 - output_layer_dense_256_196_32_loss: 0.0458 - output_layer_dense_256_196_64_loss: 0.0527 - output_layer_dense_256_196_128_loss: 0.0510 - output_layer_dense_256_196_196_loss: 0.0541 - output_layer_dense_256_256_16_loss: 0.0530 - output_layer_dense_256_256_32_loss: 0.0499 - output_layer_dense_256_256_64_loss: 0.0523 - output_layer_dense_256_256_128_loss: 0.0529 - output_layer_dense_256_256_196_loss: 0.0527\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4688 - output_layer_dense_256_196_16_loss: 0.0464 - output_layer_dense_256_196_32_loss: 0.0430 - output_layer_dense_256_196_64_loss: 0.0474 - output_layer_dense_256_196_128_loss: 0.0458 - output_layer_dense_256_196_196_loss: 0.0481 - output_layer_dense_256_256_16_loss: 0.0497 - output_layer_dense_256_256_32_loss: 0.0486 - output_layer_dense_256_256_64_loss: 0.0471 - output_layer_dense_256_256_128_loss: 0.0459 - output_layer_dense_256_256_196_loss: 0.0468\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.4258 - output_layer_dense_256_196_16_loss: 0.0428 - output_layer_dense_256_196_32_loss: 0.0414 - output_layer_dense_256_196_64_loss: 0.0424 - output_layer_dense_256_196_128_loss: 0.0403 - output_layer_dense_256_196_196_loss: 0.0424 - output_layer_dense_256_256_16_loss: 0.0454 - output_layer_dense_256_256_32_loss: 0.0434 - output_layer_dense_256_256_64_loss: 0.0424 - output_layer_dense_256_256_128_loss: 0.0419 - output_layer_dense_256_256_196_loss: 0.0436\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3934 - output_layer_dense_256_196_16_loss: 0.0382 - output_layer_dense_256_196_32_loss: 0.0387 - output_layer_dense_256_196_64_loss: 0.0391 - output_layer_dense_256_196_128_loss: 0.0375 - output_layer_dense_256_196_196_loss: 0.0392 - output_layer_dense_256_256_16_loss: 0.0424 - output_layer_dense_256_256_32_loss: 0.0400 - output_layer_dense_256_256_64_loss: 0.0391 - output_layer_dense_256_256_128_loss: 0.0384 - output_layer_dense_256_256_196_loss: 0.0408\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3822 - output_layer_dense_256_196_16_loss: 0.0351 - output_layer_dense_256_196_32_loss: 0.0387 - output_layer_dense_256_196_64_loss: 0.0374 - output_layer_dense_256_196_128_loss: 0.0379 - output_layer_dense_256_196_196_loss: 0.0353 - output_layer_dense_256_256_16_loss: 0.0413 - output_layer_dense_256_256_32_loss: 0.0386 - output_layer_dense_256_256_64_loss: 0.0411 - output_layer_dense_256_256_128_loss: 0.0377 - output_layer_dense_256_256_196_loss: 0.0392\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3405 - output_layer_dense_256_196_16_loss: 0.0333 - output_layer_dense_256_196_32_loss: 0.0322 - output_layer_dense_256_196_64_loss: 0.0340 - output_layer_dense_256_196_128_loss: 0.0340 - output_layer_dense_256_196_196_loss: 0.0315 - output_layer_dense_256_256_16_loss: 0.0363 - output_layer_dense_256_256_32_loss: 0.0357 - output_layer_dense_256_256_64_loss: 0.0363 - output_layer_dense_256_256_128_loss: 0.0340 - output_layer_dense_256_256_196_loss: 0.0332\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.3258 - output_layer_dense_256_196_16_loss: 0.0334 - output_layer_dense_256_196_32_loss: 0.0294 - output_layer_dense_256_196_64_loss: 0.0338 - output_layer_dense_256_196_128_loss: 0.0348 - output_layer_dense_256_196_196_loss: 0.0296 - output_layer_dense_256_256_16_loss: 0.0339 - output_layer_dense_256_256_32_loss: 0.0323 - output_layer_dense_256_256_64_loss: 0.0346 - output_layer_dense_256_256_128_loss: 0.0331 - output_layer_dense_256_256_196_loss: 0.0308\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3067 - output_layer_dense_256_196_16_loss: 0.0313 - output_layer_dense_256_196_32_loss: 0.0271 - output_layer_dense_256_196_64_loss: 0.0310 - output_layer_dense_256_196_128_loss: 0.0340 - output_layer_dense_256_196_196_loss: 0.0277 - output_layer_dense_256_256_16_loss: 0.0338 - output_layer_dense_256_256_32_loss: 0.0302 - output_layer_dense_256_256_64_loss: 0.0321 - output_layer_dense_256_256_128_loss: 0.0294 - output_layer_dense_256_256_196_loss: 0.0300\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.26225772500038147 , TEST :  0.43459054827690125\n",
      "output_layer_dense_256_196_16_loss  :  0.028002683073282242 , TEST :  0.04690176993608475\n",
      "output_layer_dense_256_196_32_loss  :  0.024285905063152313 , TEST :  0.04471362754702568\n",
      "output_layer_dense_256_196_64_loss  :  0.027351703494787216 , TEST :  0.04262879118323326\n",
      "output_layer_dense_256_196_128_loss  :  0.026055162772536278 , TEST :  0.04309355467557907\n",
      "output_layer_dense_256_196_196_loss  :  0.026088345795869827 , TEST :  0.04482203349471092\n",
      "output_layer_dense_256_256_16_loss  :  0.029476217925548553 , TEST :  0.04043841361999512\n",
      "output_layer_dense_256_256_32_loss  :  0.02496623620390892 , TEST :  0.04140935838222504\n",
      "output_layer_dense_256_256_64_loss  :  0.026263566687703133 , TEST :  0.043278567492961884\n",
      "output_layer_dense_256_256_128_loss  :  0.022877873852849007 , TEST :  0.042927954345941544\n",
      "output_layer_dense_256_256_196_loss  :  0.02689000964164734 , TEST :  0.04437645152211189\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1313\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0653\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0518\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 934us/step - loss: 0.0406\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0418\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0376\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0393\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0331\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0315\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 945us/step - loss: 0.0289\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.023727908730506897 , TEST :  0.04246122017502785\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0829\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0670\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0377\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0363\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0283\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 929us/step - loss: 0.0249\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.014897795394062996 , TEST :  0.04211791604757309\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0458\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0276\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0223\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 998us/step - loss: 0.0184\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 947us/step - loss: 0.0173\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 978us/step - loss: 0.0172\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 897us/step - loss: 0.0142\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.01630372740328312 , TEST :  0.042362313717603683\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0416\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0123\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0134\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0106\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0108\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0115\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.010257869958877563 , TEST :  0.04373817890882492\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0498\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 941us/step - loss: 0.0137\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0115\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 959us/step - loss: 0.0100\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.008445482701063156 , TEST :  0.043358609080314636\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0432\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0242\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0131\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0104\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 990us/step - loss: 0.0080\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0084\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0075\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.008606836199760437 , TEST :  0.043388742953538895\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0234\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 940us/step - loss: 0.0191\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0104\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0103\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0081\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0100\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0084\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0093\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.009469985030591488 , TEST :  0.04500555619597435\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0373\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0224\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0114\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 973us/step - loss: 0.0098\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0079\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 873us/step - loss: 0.0062\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0053\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0061\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 907us/step - loss: 0.0074\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0075\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.006979535799473524 , TEST :  0.043405622243881226\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0340\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0254\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 912us/step - loss: 0.0095\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 864us/step - loss: 0.0072\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0069\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 862us/step - loss: 0.0086\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.0073\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0080\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 856us/step - loss: 0.0088\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.008884860202670097 , TEST :  0.04446643218398094\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0356\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0209\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0162\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 931us/step - loss: 0.0097\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 990us/step - loss: 0.0069\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0084\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 882us/step - loss: 0.0072\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0061\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 901us/step - loss: 0.0052\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 904us/step - loss: 0.0055\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.0062834396958351135 , TEST :  0.04449515789747238\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 951us/step - loss: 0.0167\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0121\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 929us/step - loss: 0.0109\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 922us/step - loss: 0.0093\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0081\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 919us/step - loss: 0.0060\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0080\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 924us/step - loss: 0.0062\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.0080\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.006269477307796478 , TEST :  0.043330684304237366\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0183\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0085\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0069\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 964us/step - loss: 0.0056\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0072\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 983us/step - loss: 0.0065\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0076\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 932us/step - loss: 0.0081\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.00938407238572836 , TEST :  0.04308982193470001\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0278\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0228\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0151\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0065\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0059\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 993us/step - loss: 0.0059\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0069\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.005741485394537449 , TEST :  0.0437917485833168\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0249\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 973us/step - loss: 0.0075\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0070\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0075\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 958us/step - loss: 0.0065\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.005156864877790213 , TEST :  0.04366402328014374\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0149\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0118\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0099\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0064\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 936us/step - loss: 0.0058\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0060\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0064\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 941us/step - loss: 0.0050\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0071\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.005498857237398624 , TEST :  0.044414833188056946\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0091\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0075\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 953us/step - loss: 0.0068\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0052\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0059\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 980us/step - loss: 0.0078\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0083\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.0054709953255951405 , TEST :  0.04454716295003891\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0129\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0107\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 972us/step - loss: 0.0083\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0062\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 946us/step - loss: 0.0060\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0045\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 989us/step - loss: 0.0062\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 996us/step - loss: 0.0067\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.00482168747112155 , TEST :  0.04320220276713371\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 954us/step - loss: 0.0128\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0072\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 991us/step - loss: 0.0056\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0046\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 934us/step - loss: 0.0047\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 949us/step - loss: 0.0049\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 918us/step - loss: 0.0054\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.005567452870309353 , TEST :  0.04455665871500969\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0118\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0078\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0057\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0046\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0048\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0041\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0052\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.004247662145644426 , TEST :  0.04326396435499191\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0229\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 945us/step - loss: 0.0180\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0095\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 983us/step - loss: 0.0066\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0057\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 952us/step - loss: 0.0058\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0070\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 988us/step - loss: 0.0059\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0045\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0044\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.0035506989806890488 , TEST :  0.04393627867102623\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0212\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0132\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 911us/step - loss: 0.0078\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0046\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 972us/step - loss: 0.0042\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0043\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 954us/step - loss: 0.0047\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.00620407285168767 , TEST :  0.0437103733420372\n",
      "Time Taken :  66.57470488548279\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(trainX, trainY, testX, testY, 10, 128, input_shape = 58, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models()\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9682172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'dense_256_256_128',\n",
       "  'score': 0.022877873852849007,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_256_128',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b386df2e0>},\n",
       " {'model_name': 'dense_256_196_32',\n",
       "  'score': 0.024285905063152313,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_196_32',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b5c562910>},\n",
       " {'model_name': 'dense_256_256_32',\n",
       "  'score': 0.02496623620390892,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_256_32',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b386da790>},\n",
       " {'model_name': 'dense_256_196_128',\n",
       "  'score': 0.026055162772536278,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_196_128',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b386d1670>},\n",
       " {'model_name': 'dense_256_196_196',\n",
       "  'score': 0.026088345795869827,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_196_196',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b386d1a00>},\n",
       " {'model_name': 'dense_256_256_64',\n",
       "  'score': 0.026263566687703133,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_256_64',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b386d1f10>},\n",
       " {'model_name': 'dense_128_256_256',\n",
       "  'score': 0.026423195376992226,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_256_256',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b3864f070>},\n",
       " {'model_name': 'dense_128_256_128',\n",
       "  'score': 0.02660238742828369,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_256_128',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b384b70d0>},\n",
       " {'model_name': 'dense_256_256_196',\n",
       "  'score': 0.02689000964164734,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_256_196',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b386df670>},\n",
       " {'model_name': 'dense_196_196_32',\n",
       "  'score': 0.026907533407211304,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_196_196_32',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4bbc626e80>},\n",
       " {'model_name': 'dense_128_128_256',\n",
       "  'score': 0.027211304754018784,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_128_256',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4bc803de80>},\n",
       " {'model_name': 'dense_256_128_128',\n",
       "  'score': 0.02725631557404995,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_128_128',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b383c7ac0>},\n",
       " {'model_name': 'dense_256_196_64',\n",
       "  'score': 0.027351703494787216,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_196_64',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b386da4c0>},\n",
       " {'model_name': 'dense_196_256_64',\n",
       "  'score': 0.027621479704976082,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_196_256_64',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4bbc44e6d0>},\n",
       " {'model_name': 'dense_196_128',\n",
       "  'score': 0.02764703519642353,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_196_128',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4bd2269c70>},\n",
       " {'model_name': 'dense_256_128_64',\n",
       "  'score': 0.027733253315091133,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_128_64',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b5c123370>},\n",
       " {'model_name': 'dense_256_196_16',\n",
       "  'score': 0.028002683073282242,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_196_16',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b5c522fd0>},\n",
       " {'model_name': 'dense_128_196_256',\n",
       "  'score': 0.02822653017938137,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_196_256',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b38643250>},\n",
       " {'model_name': 'dense_256_128_16',\n",
       "  'score': 0.02864544838666916,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_128_16',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b5c1236d0>},\n",
       " {'model_name': 'dense_256_256_16',\n",
       "  'score': 0.029476217925548553,\n",
       "  'path_weights': '/home/anish/ASC_ML_test_weights/dense_256_256_16',\n",
       "  'model': <tensorflow.python.keras.engine.functional.Functional at 0x7f4b386da3a0>}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34552a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea74334b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m]\n\u001b[1;32m      3\u001b[0m c \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m c[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m      5\u001b[0m c[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m b\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(c)\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "b = [5,6,7,8]\n",
    "c = []\n",
    "c[0] = a\n",
    "c[1] = b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f40e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce5f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
