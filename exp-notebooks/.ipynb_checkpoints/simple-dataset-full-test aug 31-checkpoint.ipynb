{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SVyZBHaE6zqD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:57:45.712104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import plotly.express as px\n",
    "# from autokeras import StructuredDataRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from IPython.display import HTML\n",
    "import os\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.insert(0, '/home/anish/ASC_ML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ASC_ML.networkbuilding import multiple_model_gen_v3 as multiple\n",
    "from ASC_ML.networkbuilding import dataframe_extractor as de\n",
    "from ASC_ML.networkbuilding import model_generation as model_gen\n",
    "from ASC_ML.networkbuilding import model_optimization as model_opt\n",
    "from ASC_ML.networkbuilding import model_stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Bi5A13BZ6_17"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/anish/Downloads/autokeras-regression-master/Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "n9heEDsL7VRF",
    "outputId": "08d5989f-cd83-4bf3-bcb0-8622664384fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "xj63U7al-28H",
    "outputId": "74713606-0aba-4d27-9639-091b601b7e27"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"TV\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "6JNLdc67Jsz8",
    "outputId": "52abc809-f857-4243-d3a8-b3468b72843d"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"radio\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "HhyWxbnSJ0pX",
    "outputId": "f680d6b6-b482-471a-e09f-ed5cbee67653"
   },
   "outputs": [],
   "source": [
    "# fig = px.scatter(df, x= \"newspaper\", y=\"sales\")\n",
    "# HTML(fig.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y_T3s3Yj7jRk"
   },
   "outputs": [],
   "source": [
    "target_col = \"sales\"\n",
    "X = df.loc[:, df.columns != target_col]\n",
    "y = df.loc[:, target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DAJC0VIH7ptP"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((y_train.shape[0],1))\n",
    "y_test = y_test.reshape((y_test.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:57:51.063977: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-31 20:57:51.064677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-31 20:57:51.118778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:57:51.118905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-31 20:57:51.118926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 20:57:51.120170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-31 20:57:51.120203: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-31 20:57:51.121315: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-31 20:57:51.121509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-31 20:57:51.122784: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-31 20:57:51.123509: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-31 20:57:51.126163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-31 20:57:51.126269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:57:51.126431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:57:51.126520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-31 20:57:51.126795: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-31 20:57:51.126994: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-31 20:57:51.127072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:57:51.127177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5\n",
      "coreClock: 1.695GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s\n",
      "2022-08-31 20:57:51.127204: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-31 20:57:51.127222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-31 20:57:51.127237: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-31 20:57:51.127252: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-31 20:57:51.127266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-31 20:57:51.127281: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-31 20:57:51.127297: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-31 20:57:51.127312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-31 20:57:51.127358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:57:51.127485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-31 20:57:51.127927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-31 20:57:51.127966: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m m \u001b[38;5;241m=\u001b[39m multiple\u001b[38;5;241m.\u001b[39mMultiple_Model_Gen_V3(X_train, y_train, X_test, y_test, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m64\u001b[39m, input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m      3\u001b[0m                                    max_no_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, model_per_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, \n\u001b[1;32m      4\u001b[0m                                    save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/anish/ASC_ML_test_weights/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m m\u001b[38;5;241m.\u001b[39mget_model_confs()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m opt \u001b[38;5;241m=\u001b[39m model_opt\u001b[38;5;241m.\u001b[39mModel_Optimization(X_train, y_train, X_test, y_test, \u001b[38;5;241m200\u001b[39m, m\u001b[38;5;241m.\u001b[39mevaluate_dict_list, save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/anish/ASC_ML_test_weights/candidate_models/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m opt\u001b[38;5;241m.\u001b[39moptimize_models(save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/multiple_model_gen_v3.py:74\u001b[0m, in \u001b[0;36mMultiple_Model_Gen_V3.get_best_models\u001b[0;34m(self, save)\u001b[0m\n\u001b[1;32m     71\u001b[0m parallel_model_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parallel_model_generator()\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# 1st Loop, Get best model architectures\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parallelModel, n, model_conf_batch_list \u001b[38;5;129;01min\u001b[39;00m parallel_model_generator:\n\u001b[1;32m     75\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_lists(n)\n\u001b[1;32m     76\u001b[0m     Pmodel, metrics_names, scores, scores_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_model(input_data \u001b[38;5;241m=\u001b[39m input_data, Pmodel \u001b[38;5;241m=\u001b[39m parallelModel, \n\u001b[1;32m     77\u001b[0m                                                                     epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epochs, n_model \u001b[38;5;241m=\u001b[39m n, loss_fn \u001b[38;5;241m=\u001b[39m loss_fn)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/multiple_model_gen_v3.py:158\u001b[0m, in \u001b[0;36mMultiple_Model_Gen_V3._parallel_model_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parallel_model_generator\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_confs:\n\u001b[0;32m--> 158\u001b[0m         input_layer_list, output_layer_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_input_output_layer_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m         n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_layer_list)\n\u001b[1;32m    160\u001b[0m         parallelModel \u001b[38;5;241m=\u001b[39m Model(inputs \u001b[38;5;241m=\u001b[39m input_layer_list, outputs \u001b[38;5;241m=\u001b[39m output_layer_list)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/multiple_model_gen_v3.py:209\u001b[0m, in \u001b[0;36mMultiple_Model_Gen_V3._get_input_output_layer_list\u001b[0;34m(model_list)\u001b[0m\n\u001b[1;32m    207\u001b[0m output_layer_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nn_model_conf \u001b[38;5;129;01min\u001b[39;00m model_list:\n\u001b[0;32m--> 209\u001b[0m     nn_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNN_ModelGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnn_model_conf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m     input_layer_list\u001b[38;5;241m.\u001b[39mappend(nn_model\u001b[38;5;241m.\u001b[39minput_layer)\n\u001b[1;32m    211\u001b[0m     output_layer_list\u001b[38;5;241m.\u001b[39mappend(nn_model\u001b[38;5;241m.\u001b[39moutput_layer)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/model_generation.py:18\u001b[0m, in \u001b[0;36mNN_ModelGeneration.__init__\u001b[0;34m(self, model_name, input_shape, init_no_layers, init_activation_fn, init_layer_conf, output_layer_conf)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layer_conf \u001b[38;5;241m=\u001b[39m {k \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_name: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layer_conf\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_layer_conf \u001b[38;5;241m=\u001b[39m output_layer_conf\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_penultimate_layer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/model_generation.py:64\u001b[0m, in \u001b[0;36mNN_ModelGeneration.generate_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m x \u001b[38;5;241m=\u001b[39m input_layer\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layer_conf:\n\u001b[0;32m---> 64\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_layer_conf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_activation_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m output_layer \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_layer_conf[\u001b[38;5;241m0\u001b[39m], activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_layer_conf[\u001b[38;5;241m1\u001b[39m], name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_name)(x)\n\u001b[1;32m     68\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs \u001b[38;5;241m=\u001b[39m input_layer, outputs \u001b[38;5;241m=\u001b[39m [output_layer], name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:951\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 951\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1090\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keras_tensor\u001b[38;5;241m.\u001b[39mkeras_tensors_enabled():\n\u001b[1;32m   1087\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   1088\u001b[0m       layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1090\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1095\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1096\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:822\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:862\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_scope()):\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    858\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# overridden).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2710\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_default\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   2706\u001b[0m   \u001b[38;5;66;03m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[1;32m   2707\u001b[0m   \u001b[38;5;66;03m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[1;32m   2708\u001b[0m   \u001b[38;5;66;03m# operations.\u001b[39;00m\n\u001b[1;32m   2709\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39mmaybe_init_scope(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2710\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint:disable=not-callable\u001b[39;00m\n\u001b[1;32m   2711\u001b[0m \u001b[38;5;66;03m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[1;32m   2712\u001b[0m \u001b[38;5;66;03m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[1;32m   2713\u001b[0m \u001b[38;5;66;03m# `super.build()`\u001b[39;00m\n\u001b[1;32m   2714\u001b[0m Layer\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m, input_shapes)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/layers/core.py:1185\u001b[0m, in \u001b[0;36mDense.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1182\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe last dimension of the inputs to `Dense` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1183\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould be defined. Found `None`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m InputSpec(min_ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: last_dim})\n\u001b[0;32m-> 1185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlast_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m   1194\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m   1195\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1196\u001b[0m       shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits,],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1200\u001b[0m       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m   1201\u001b[0m       trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:623\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m     tf_logging\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`caching_device` does not work with mixed precision \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    620\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI. Ignoring user specified `caching_device`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    621\u001b[0m     caching_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_variable_with_custom_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# `Trackable` method.\u001b[39;49;00m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgetter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgetter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regularizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m   \u001b[38;5;66;03m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;66;03m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[1;32m    643\u001b[0m   \u001b[38;5;66;03m# should be variable attributes.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m   name_in_scope \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mname[:variable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:805\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    795\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (checkpoint_initializer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    796\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    797\u001b[0m            (initializer\u001b[38;5;241m.\u001b[39mrestore_uid \u001b[38;5;241m>\u001b[39m checkpoint_initializer\u001b[38;5;241m.\u001b[39mrestore_uid))):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;66;03m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m     initializer \u001b[38;5;241m=\u001b[39m checkpoint_initializer\n\u001b[0;32m--> 805\u001b[0m new_variable \u001b[38;5;241m=\u001b[39m \u001b[43mgetter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_for_getter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;66;03m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;66;03m# handles slot variables.\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_utils.py:130\u001b[0m, in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# TODO(apassos,rohanj) figure out how to remove collections from here so we\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# can remove the V1.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m variable_shape \u001b[38;5;241m=\u001b[39m tensor_shape\u001b[38;5;241m.\u001b[39mTensorShape(shape)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_variables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariableV1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:260\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m VariableV1:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_v1_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Variable:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_v2_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:206\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m   aggregation \u001b[38;5;241m=\u001b[39m VariableAggregation\u001b[38;5;241m.\u001b[39mNONE\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprevious_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:199\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_variable_v1_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    183\u001b[0m                       initial_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    184\u001b[0m                       trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m                       aggregation\u001b[38;5;241m=\u001b[39mVariableAggregation\u001b[38;5;241m.\u001b[39mNONE,\n\u001b[1;32m    197\u001b[0m                       shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;124;03m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m   previous_getter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mdefault_variable_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m _, getter \u001b[38;5;129;01min\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_variable_creator_stack:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     previous_getter \u001b[38;5;241m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py:2604\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_resource:\n\u001b[1;32m   2603\u001b[0m   distribute_strategy \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribute_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2604\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2608\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m      \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m      \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m      \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2620\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mRefVariable(\n\u001b[1;32m   2621\u001b[0m       initial_value\u001b[38;5;241m=\u001b[39minitial_value,\n\u001b[1;32m   2622\u001b[0m       trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2633\u001b[0m       aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[1;32m   2634\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:264\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_v2_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVariableMetaclass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1574\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[38;5;241m=\u001b[39mimport_scope)\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1574\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_from_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m      \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m      \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1712\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializer\u001b[39m\u001b[38;5;124m\"\u001b[39m), device_context_manager(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1711\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m init_from_fn:\n\u001b[0;32m-> 1712\u001b[0m     initial_value \u001b[38;5;241m=\u001b[39m \u001b[43minitial_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1713\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(initial_value, trackable\u001b[38;5;241m.\u001b[39mCheckpointInitialValue):\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/initializers/initializers_v2.py:409\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    399\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a tensor object initialized as specified by the initializer.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    **kwargs: Additional keyword arguments.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVarianceScaling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py:600\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    599\u001b[0m   limit \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m \u001b[38;5;241m*\u001b[39m scale)\n\u001b[0;32m--> 600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_uniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py:1081\u001b[0m, in \u001b[0;36m_RandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1080\u001b[0m   op \u001b[38;5;241m=\u001b[39m random_ops\u001b[38;5;241m.\u001b[39mrandom_uniform\n\u001b[0;32m-> 1081\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/ops/random_ops.py:289\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m   maxval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_uniform\u001b[39m\u001b[38;5;124m\"\u001b[39m, [shape, minval, maxval]) \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[0;32m--> 289\u001b[0m   shape \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m   \u001b[38;5;66;03m# In case of [0,1) floating results, minval and maxval is unused. We do an\u001b[39;00m\n\u001b[1;32m    291\u001b[0m   \u001b[38;5;66;03m# `is` comparison here since this is cheaper than isinstance or  __eq__.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m   minval_is_zero \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(minval, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m minval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py:1035\u001b[0m, in \u001b[0;36mshape_tensor\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1029\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;66;03m# If there are Dimension objects in the shape, unwrap them. This can be a\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;66;03m# problem if v1 and v2 TensorShape objects get mixed up in partial\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;66;03m# conversions, leading to shapes such as (1, 2, Dimension(5)), which are\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;66;03m# not convertible to Tensors because of mixed content.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(tensor_shape\u001b[38;5;241m.\u001b[39mdimension_value, shape))\n\u001b[0;32m-> 1035\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1540\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1535\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1536\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1537\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1540\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1543\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:339\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    338\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:264\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    275\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    279\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    300\u001b[0m   \u001b[38;5;124;03m\"\"\"Implementation of eager constant.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:97\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m---> 97\u001b[0m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/eager/context.py:526\u001b[0m, in \u001b[0;36mContext.ensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_tfrt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_ContextOptionsSetTfrt(opts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_tfrt)\n\u001b[0;32m--> 526\u001b[0m   context_handle \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_NewContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    528\u001b[0m   pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_DeleteContextOptions(opts)\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 3, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = False)\n",
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list, save_dir = \"/home/anish/ASC_ML_test_weights/candidate_models/\")\n",
    "opt.optimize_models(save=True)\n",
    "stacked_models = Model_Stacking2(X_train, y_train, X_test, y_test, opt.saved_paths, opt.model_confs, save_dir = \"/home/anish/ASC_ML_test_weights/stacked_models/\")\n",
    "stacked_models.optimize_stacked_models()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list, save_dir = \"/home/anish/ASC_ML_test_weights/candidate_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_64_32\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7f834ca439d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.25836920738220215, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00158, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.23953723907470703 , TEST :  0.3918216824531555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 20:27:31.472929: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_64_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2682299017906189, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00126, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4576481878757477 , TEST :  0.45119571685791016\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_64_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.28047266602516174, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00079, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4161660075187683 , TEST :  0.4442753791809082\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_64_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_128_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2530515789985657, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00032, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.20749564468860626 , TEST :  0.34467601776123047\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_128_64/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.29894933104515076, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0005, BEST_BATCHSIZE : 32\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.33626192808151245 , TEST :  0.5402534008026123\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_128_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_128_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.24240973591804504, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0005, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.3718816339969635 , TEST :  0.5487875938415527\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_128_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.28277572989463806, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00158, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.2970237135887146 , TEST :  0.40036001801490784\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_64_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.30428752303123474, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00126, BEST_BATCHSIZE : 64\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.42149239778518677 , TEST :  0.5804237127304077\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_64_128/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.288043737411499, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00158, BEST_BATCHSIZE : 64\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4906516671180725 , TEST :  0.532824695110321\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_128_32/assets\n",
      "--------------------------------------------------------------------------------\n",
      "Model Name : dense_64_32_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2707439959049225, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00079, BEST_BATCHSIZE : 16\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  0.4825219213962555 , TEST :  0.5347640514373779\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/candidate_models/dense_64_32_32/assets\n"
     ]
    }
   ],
   "source": [
    "opt.optimize_models(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.model_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_hyp_permodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_models = model_stacking.Model_Stacking(opt.saved_paths, opt.model_confs)\n",
    "stacked_models = Model_Stacking2(X_train, y_train, X_test, y_test, opt.saved_paths, opt.model_confs, save_dir = \"/home/anish/ASC_ML_test_weights/stacked_models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_64_128_32_st_dense_64_128_32\n",
      "Model: \"dense_64_128_32_st_dense_64_128_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32_2nd ( (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32_2nd ( (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_128_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 27,297\n",
      "Trainable params: 27,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2102661430835724, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00126, BEST_BATCHSIZE : 64\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.18974287807941437, TEST_LOSS = 0.3626607358455658\n",
      "dense_64_128_32_st_dense_64_128_64\n",
      "Model: \"dense_64_128_32_st_dense_64_128_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_64_2nd ( (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_64_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_64_2nd ( (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_128_64 (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 31,457\n",
      "Trainable params: 31,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2152978628873825, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00063, BEST_BATCHSIZE : 16\n",
      "GlorotNormal\n",
      "DROPOUT RATES : [0, 0.2]\n",
      "TRAIN_LOSS = 0.2746140658855438, TEST_LOSS = 0.395169198513031\n",
      "dense_64_128_32_st_dense_64_64_128\n",
      "Model: \"dense_64_128_32_st_dense_64_64_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_64_128_2nd ( (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_64_128_2nd ( (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_64_128_2nd ( (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_64_64_128 (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 27,425\n",
      "Trainable params: 27,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2167428433895111, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 32\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0.2]\n",
      "TRAIN_LOSS = 0.46205559372901917, TEST_LOSS = 0.5042843818664551\n",
      "dense_64_128_32_st_dense_128_64_32\n",
      "Model: \"dense_64_128_32_st_dense_128_64_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_64_32_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_64_32_2nd ( (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_64_32_2nd ( (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_64_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 27,297\n",
      "Trainable params: 27,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.20106205344200134, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.20413604378700256, TEST_LOSS = 0.3925964832305908\n",
      "dense_64_128_32_st_dense_32_128\n",
      "Model: \"dense_64_128_32_st_dense_32_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_128_2nd (Den (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_128_2nd (Den (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_32_128 (D (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 18,113\n",
      "Trainable params: 18,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.19186227023601532, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.00032, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.17292746901512146, TEST_LOSS = 0.3159737288951874\n",
      "dense_64_128_32_st_dense_32_32_128\n",
      "Model: \"dense_64_128_32_st_dense_32_32_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_32_32_128_2nd ( (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer2_dense_32_32_128_2nd ( (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "layer3_dense_32_32_128_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_32_32_128 (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 19,169\n",
      "Trainable params: 19,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.2549762725830078, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotNormal\n",
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.1746048629283905, TEST_LOSS = 0.3850560188293457\n",
      "dense_64_128_32_st_dense_128_64_64\n",
      "Model: \"dense_64_128_32_st_dense_128_64_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_64_64_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_64_64_2nd ( (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_64_64_2nd ( (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_64_64 (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 29,409\n",
      "Trainable params: 29,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.26172542572021484, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.0004, BEST_BATCHSIZE : 16\n",
      "GlorotUniform\n",
      "DROPOUT RATES : [0, 0.2]\n",
      "TRAIN_LOSS = 0.4665142893791199, TEST_LOSS = 0.6047951579093933\n",
      "dense_64_128_32_st_dense_128_32_32\n",
      "Model: \"dense_64_128_32_st_dense_128_32_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_32_32_2nd ( (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_32_32_2nd ( (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_32_32_2nd ( (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_32_32 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 22,145\n",
      "Trainable params: 22,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 0.25475889444351196, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00251, BEST_BATCHSIZE : 64\n",
      "GlorotNormal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROPOUT RATES : [0, 0]\n",
      "TRAIN_LOSS = 0.3202672004699707, TEST_LOSS = 0.47966986894607544\n",
      "dense_64_128_32_st_dense_128_128_32\n",
      "Model: \"dense_64_128_32_st_dense_128_128_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer_dense_64_128_32  [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_64_128_32 (Dens (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "layer2_dense_64_128_32 (Dens (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "layer3_dense_64_128_32 (Dens (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "layer1_dense_128_128_32_2nd  (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "layer2_dense_128_128_32_2nd  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "layer3_dense_128_128_32_2nd  (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output_layer_dense_128_128_3 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 37,601\n",
      "Trainable params: 37,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstacked_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_stacked_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mModel_Stacking2.optimize_stacked_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     53\u001b[0m h \u001b[38;5;241m=\u001b[39m hyp_opt\u001b[38;5;241m.\u001b[39mHyperparameter_Optimization([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_x], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_y], model, loss_fn, activation_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, initializer_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 54\u001b[0m best_lr, best_batch_size, _, best_initializer \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_initializer)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(model, best_initializer)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:120\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.get_best_hyperparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m initializer \u001b[38;5;129;01min\u001b[39;00m intializer_list[i]:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(initializer_str\u001b[38;5;241m=\u001b[39minitializer)\n\u001b[0;32m--> 120\u001b[0m     lr, batch_size, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_batch_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitializer_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(best_loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m loss\u001b[38;5;241m<\u001b[39mbest_loss):\n\u001b[1;32m    122\u001b[0m         best_loss \u001b[38;5;241m=\u001b[39m loss\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:147\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.lr_batch_optimization\u001b[0;34m(self, initializer_str)\u001b[0m\n\u001b[1;32m    145\u001b[0m     best_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lr_opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     best_lr, best_batch_size, best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_batch_size_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitializer_str\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitializer_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_lr, best_batch_size, best_loss\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:90\u001b[0m, in \u001b[0;36mHyperparameter_Optimization.get_best_batch_size_lr\u001b[0;34m(self, initializer_str)\u001b[0m\n\u001b[1;32m     87\u001b[0m best_lr_batch, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_best_lr(batch_size)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reinitialize_model(initializer_str\u001b[38;5;241m=\u001b[39minitializer_str)\n\u001b[0;32m---> 90\u001b[0m best_loss_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_lr_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m best_lr_list\u001b[38;5;241m.\u001b[39mappend(best_lr_batch)\n\u001b[1;32m     93\u001b[0m best_loss_list\u001b[38;5;241m.\u001b[39mappend(best_loss_batch)\n",
      "File \u001b[0;32m~/ASC_ML/ASC_ML/networkbuilding/hyperparameter_optimization.py:75\u001b[0m, in \u001b[0;36mHyperparameter_Optimization._train_model\u001b[0;34m(self, lr, batch_size)\u001b[0m\n\u001b[1;32m     73\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss_fn, optimizer \u001b[38;5;241m=\u001b[39m optimizer)\n\u001b[0;32m---> 75\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_Y, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1077\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n\u001b[1;32m   1068\u001b[0m   callbacks \u001b[38;5;241m=\u001b[39m callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList(\n\u001b[1;32m   1069\u001b[0m       callbacks,\n\u001b[1;32m   1070\u001b[0m       add_history\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1074\u001b[0m       epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m   1075\u001b[0m       steps\u001b[38;5;241m=\u001b[39mdata_handler\u001b[38;5;241m.\u001b[39minferred_steps)\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_counter\u001b[38;5;241m.\u001b[39massign(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:324\u001b[0m, in \u001b[0;36mModel.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    317\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# six.raise_from supresses the original AttributeError from being raised\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIt looks like you are subclassing `Model` and you \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforgot to call `super(YourClass, self).__init__()`.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    322\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Always start with this line.\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2847\u001b[0m, in \u001b[0;36mLayer.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;66;03m# Clean out the old attribute, which clears _layers and _trainable_weights\u001b[39;00m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;66;03m# if necessary.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2847\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__delattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   2849\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2797\u001b[0m, in \u001b[0;36mLayer.__delattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2794\u001b[0m   \u001b[38;5;28msuper\u001b[39m(tracking\u001b[38;5;241m.\u001b[39mAutoTrackable, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__delattr__\u001b[39m(name)\n\u001b[1;32m   2795\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 2797\u001b[0m reference_count \u001b[38;5;241m=\u001b[39m \u001b[43mreference_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexisting_value\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reference_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2799\u001b[0m   \u001b[38;5;66;03m# There are other remaining references. We can't remove this object from\u001b[39;00m\n\u001b[1;32m   2800\u001b[0m   \u001b[38;5;66;03m# _layers etc.\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m   reference_counts[existing_value] \u001b[38;5;241m=\u001b[39m reference_count \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/util/object_identity.py:138\u001b[0m, in \u001b[0;36mObjectIdentityDictionary.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 138\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/tensorflow/python/util/object_identity.py:67\u001b[0m, in \u001b[0;36m_ObjectIdentityWrapper.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;66;03m# Wrapper id() is also fine for weakrefs. In fact, we rely on\u001b[39;00m\n\u001b[1;32m     65\u001b[0m   \u001b[38;5;66;03m# id(weakref.ref(a)) == id(weakref.ref(a)) and weakref.ref(a) is\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   \u001b[38;5;66;03m# weakref.ref(a) in _WeakObjectIdentityWrapper.\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stacked_models.optimize_stacked_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 2)\n",
      "(63, 1) (63,)\n",
      "(42, 1) (21, 1) (42,) (21,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load the sonar dataset\n",
    "from pandas import read_csv\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "print(dataframe.shape)\n",
    "# split into input and output elements\n",
    "data = dataframe.values\n",
    "data = data.astype('float32')\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# separate into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  564.4772338867188 , TEST :  696.4302978515625\n",
      "output_layer_dense_32_32_loss  :  77.97647094726562 , TEST :  102.96764373779297\n",
      "output_layer_dense_32_64_loss  :  72.4428939819336 , TEST :  94.78680419921875\n",
      "output_layer_dense_32_128_loss  :  43.49039840698242 , TEST :  50.427490234375\n",
      "output_layer_dense_32_1024_loss  :  32.640380859375 , TEST :  31.093881607055664\n",
      "output_layer_dense_64_32_loss  :  68.5215072631836 , TEST :  88.98941802978516\n",
      "output_layer_dense_64_64_loss  :  67.38311004638672 , TEST :  87.2926254272461\n",
      "output_layer_dense_64_128_loss  :  41.06880569458008 , TEST :  45.563011169433594\n",
      "output_layer_dense_64_1024_loss  :  32.03666687011719 , TEST :  28.78836441040039\n",
      "output_layer_dense_128_32_loss  :  72.19493103027344 , TEST :  94.40507507324219\n",
      "output_layer_dense_128_64_loss  :  56.72202682495117 , TEST :  72.11593627929688\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  204.6041717529297 , TEST :  193.50648498535156\n",
      "output_layer_dense_128_128_loss  :  43.74370574951172 , TEST :  50.91599655151367\n",
      "output_layer_dense_128_1024_loss  :  31.940673828125 , TEST :  27.309024810791016\n",
      "output_layer_dense_1024_32_loss  :  31.918380737304688 , TEST :  27.996408462524414\n",
      "output_layer_dense_1024_64_loss  :  33.159645080566406 , TEST :  34.39208984375\n",
      "output_layer_dense_1024_128_loss  :  31.97357177734375 , TEST :  25.20755386352539\n",
      "output_layer_dense_1024_1024_loss  :  31.868175506591797 , TEST :  27.685407638549805\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  396.1885681152344 , TEST :  412.23150634765625\n",
      "output_layer_dense_32_32_32_loss  :  67.75357818603516 , TEST :  87.86875915527344\n",
      "output_layer_dense_32_32_64_loss  :  55.70736312866211 , TEST :  70.67930603027344\n",
      "output_layer_dense_32_32_128_loss  :  33.16255569458008 , TEST :  25.683181762695312\n",
      "output_layer_dense_32_32_1024_loss  :  32.28651809692383 , TEST :  29.9041805267334\n",
      "output_layer_dense_32_64_32_loss  :  35.29856872558594 , TEST :  32.24654006958008\n",
      "output_layer_dense_32_64_64_loss  :  43.165130615234375 , TEST :  49.84916305541992\n",
      "output_layer_dense_32_64_128_loss  :  32.039371490478516 , TEST :  28.813858032226562\n",
      "output_layer_dense_32_64_1024_loss  :  31.844669342041016 , TEST :  27.289440155029297\n",
      "output_layer_dense_32_128_32_loss  :  31.92618179321289 , TEST :  27.147016525268555\n",
      "output_layer_dense_32_128_64_loss  :  33.00459671020508 , TEST :  32.75004959106445\n",
      "WARNING:tensorflow:5 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0a203ec700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  400.072998046875 , TEST :  415.59356689453125\n",
      "output_layer_dense_32_128_128_loss  :  33.348819732666016 , TEST :  35.67073440551758\n",
      "output_layer_dense_32_128_1024_loss  :  31.862337112426758 , TEST :  26.892961502075195\n",
      "output_layer_dense_32_1024_32_loss  :  32.63373565673828 , TEST :  31.09195327758789\n",
      "output_layer_dense_32_1024_64_loss  :  31.856761932373047 , TEST :  26.121145248413086\n",
      "output_layer_dense_32_1024_128_loss  :  31.77286148071289 , TEST :  26.318124771118164\n",
      "output_layer_dense_32_1024_1024_loss  :  31.885509490966797 , TEST :  25.188533782958984\n",
      "output_layer_dense_64_32_32_loss  :  63.9492301940918 , TEST :  82.36168670654297\n",
      "output_layer_dense_64_64_32_loss  :  72.885009765625 , TEST :  95.42500305175781\n",
      "output_layer_dense_64_64_64_loss  :  37.93951416015625 , TEST :  38.811222076416016\n",
      "output_layer_dense_64_64_128_loss  :  31.939241409301758 , TEST :  27.71219825744629\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d9f280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  327.50689697265625 , TEST :  299.78814697265625\n",
      "output_layer_dense_64_64_1024_loss  :  31.8554630279541 , TEST :  25.88766098022461\n",
      "output_layer_dense_64_128_32_loss  :  31.906051635742188 , TEST :  25.64059066772461\n",
      "output_layer_dense_64_128_64_loss  :  33.201045989990234 , TEST :  34.193389892578125\n",
      "output_layer_dense_64_128_128_loss  :  32.75349426269531 , TEST :  31.522672653198242\n",
      "output_layer_dense_64_128_1024_loss  :  31.98941421508789 , TEST :  28.798473358154297\n",
      "output_layer_dense_64_1024_32_loss  :  33.3077278137207 , TEST :  35.31038284301758\n",
      "output_layer_dense_64_1024_64_loss  :  31.882036209106445 , TEST :  26.396068572998047\n",
      "output_layer_dense_64_1024_128_loss  :  32.024383544921875 , TEST :  28.8597354888916\n",
      "output_layer_dense_64_1024_1024_loss  :  31.849613189697266 , TEST :  27.19002914428711\n",
      "output_layer_dense_128_32_32_loss  :  36.737648010253906 , TEST :  35.98911666870117\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09813ad0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  342.26483154296875 , TEST :  328.2178039550781\n",
      "output_layer_dense_128_64_32_loss  :  48.028038024902344 , TEST :  58.27384567260742\n",
      "output_layer_dense_128_64_64_loss  :  35.14159393310547 , TEST :  31.83365821838379\n",
      "output_layer_dense_128_128_32_loss  :  33.40260696411133 , TEST :  35.939876556396484\n",
      "output_layer_dense_128_128_64_loss  :  33.0523796081543 , TEST :  33.2486572265625\n",
      "output_layer_dense_128_128_128_loss  :  32.45167922973633 , TEST :  30.385448455810547\n",
      "output_layer_dense_128_128_1024_loss  :  32.060020446777344 , TEST :  29.12714195251465\n",
      "output_layer_dense_128_1024_32_loss  :  32.3466796875 , TEST :  25.076053619384766\n",
      "output_layer_dense_128_1024_64_loss  :  31.98933982849121 , TEST :  28.839698791503906\n",
      "output_layer_dense_128_1024_128_loss  :  31.976551055908203 , TEST :  28.71439552307129\n",
      "output_layer_dense_128_1024_1024_loss  :  31.815929412841797 , TEST :  26.779003143310547\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  333.677490234375 , TEST :  306.97418212890625\n",
      "output_layer_dense_1024_32_32_loss  :  44.59679412841797 , TEST :  52.55773162841797\n",
      "output_layer_dense_1024_64_32_loss  :  33.508392333984375 , TEST :  36.54766082763672\n",
      "output_layer_dense_1024_64_64_loss  :  31.81412124633789 , TEST :  26.398746490478516\n",
      "output_layer_dense_1024_128_32_loss  :  32.89533233642578 , TEST :  32.505619049072266\n",
      "output_layer_dense_1024_128_64_loss  :  31.82064437866211 , TEST :  26.59869384765625\n",
      "output_layer_dense_1024_128_128_loss  :  31.81867027282715 , TEST :  26.49064064025879\n",
      "output_layer_dense_1024_1024_32_loss  :  31.895700454711914 , TEST :  27.852462768554688\n",
      "output_layer_dense_1024_1024_64_loss  :  31.739051818847656 , TEST :  26.053115844726562\n",
      "output_layer_dense_1024_1024_128_loss  :  31.811500549316406 , TEST :  26.66451072692871\n",
      "output_layer_dense_1024_1024_1024_loss  :  31.777271270751953 , TEST :  25.304996490478516\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "[{'model_name': 'dense_128_1024_32', 'score': 25.076053619384766, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_128_1024_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 128, 'layer2': 1024, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d1a7f0>}, {'model_name': 'dense_32_1024_1024', 'score': 25.188533782958984, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0988425a60>}, {'model_name': 'dense_1024_128', 'score': 25.20755386352539, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_128', 'model_conf': ['', 1, 2, 'relu', {'layer1': 1024, 'layer2': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983d68220>}, {'model_name': 'dense_1024_1024_1024', 'score': 25.304996490478516, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f09807cc700>}, {'model_name': 'dense_64_128_32', 'score': 25.64059066772461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_128_32', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 128, 'layer3': 32}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f098195ac70>}, {'model_name': 'dense_32_32_128', 'score': 25.683181762695312, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_32_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 32, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0980615580>}, {'model_name': 'dense_64_64_1024', 'score': 25.88766098022461, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_64_64_1024', 'model_conf': ['', 1, 3, 'relu', {'layer1': 64, 'layer2': 64, 'layer3': 1024}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983a2b160>}, {'model_name': 'dense_1024_1024_64', 'score': 26.053115844726562, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_1024_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 1024, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0983c1efa0>}, {'model_name': 'dense_32_1024_64', 'score': 26.121145248413086, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_64', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 64}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad7550>}, {'model_name': 'dense_32_1024_128', 'score': 26.318124771118164, 'path_weights': '/home/anish/ASC_ML_test_weights/dense_32_1024_128', 'model_conf': ['', 1, 3, 'relu', {'layer1': 32, 'layer2': 1024, 'layer3': 128}, [1, None]], 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x7f0981ad70a0>}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_128_1024_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_128_32/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_32_128/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_64_64_1024/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_1024_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_64/assets\n",
      "INFO:tensorflow:Assets written to: /home/anish/ASC_ML_test_weights/dense_32_1024_128/assets\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "Time Taken :  20.406763076782227\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "m = multiple.Multiple_Model_Gen_V3(X_train, y_train, X_test, y_test, 50, 64, input_shape = 1, \n",
    "                                   max_no_layers = 3, model_per_batch = 10, \n",
    "                                   save_dir = \"/home/anish/ASC_ML_test_weights/\")\n",
    "m.get_model_confs()\n",
    "m.get_best_models(save = True)\n",
    "end = time.time()\n",
    "print(\"Time Taken : \", (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name : dense_128_1024_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.345319747924805, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.02512, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981bbd700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.84622573852539, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00158, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0983e43d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.873470306396484 , TEST :  24.018808364868164\n",
      "Model Name : dense_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.384897232055664, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098847c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  32.86589050292969 , TEST :  32.15849685668945\n",
      "Model Name : dense_1024_1024_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.181747436523438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.001, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f098167b550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.778873443603516 , TEST :  28.295467376708984\n",
      "Model Name : dense_64_128_32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.6921329498291, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.00398, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09838ab790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.848989486694336 , TEST :  24.678855895996094\n",
      "Model Name : dense_32_32_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.34592628479004, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotNormal, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882fd4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.671247482299805 , TEST :  28.42959213256836\n",
      "Model Name : dense_64_64_1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.222423553466797, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01995, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09882c7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.99043846130371 , TEST :  26.99068832397461\n",
      "Model Name : dense_1024_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 27.45450210571289, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01585, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981d19a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  90.03191375732422 , TEST :  119.77239227294922\n",
      "Model Name : dense_32_1024_64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.205533981323242, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.01259, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f0981f60b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  29.2604923248291 , TEST :  26.66190528869629\n",
      "Model Name : dense_32_1024_128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "BEST HYPERPARAMETERS : BEST_LOSS : 29.960067749023438, BEST_ACTIVATION : selu, BEST_INITIALIZER : GlorotUniform, BEST_LEARINING_RATE : 0.002, BEST_BATCHSIZE : 16\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f09884280d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      " \n",
      " \n",
      "\n",
      "loss  :  28.737110137939453 , TEST :  25.75638198852539\n"
     ]
    }
   ],
   "source": [
    "opt = model_opt.Model_Optimization(X_train, y_train, X_test, y_test, 200, m.evaluate_dict_list)\n",
    "opt.optimize_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-GljDEx7Q8i"
   },
   "outputs": [],
   "source": [
    "search = StructuredDataRegressor(max_trials=15, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CF1WqFSj7TAN",
    "outputId": "022c0fdf-8cfd-45ed-ddce-e183911b0e99"
   },
   "outputs": [],
   "source": [
    "search.fit(x=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pJvdP_eb7vYp",
    "outputId": "15a9315a-a61d-4a11-ba0e-467eaafd7415"
   },
   "outputs": [],
   "source": [
    "train_mae, _ = search.evaluate(X_train, y_train, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(train_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ESltODdC8AO0",
    "outputId": "30d0352d-1ed0-40ca-bbe0-cfe17fe836cb"
   },
   "outputs": [],
   "source": [
    "test_mae, _ = search.evaluate(X_test, y_test, verbose=0)\n",
    "print('Mean Absolute Error is {}'.format(test_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vi_KQC2K8pzs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autokeras-regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
